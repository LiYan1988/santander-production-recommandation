{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering in RAM-Limited Data, Part 2\n",
    "\n",
    "#### CV@2015-12-28:\n",
    "- benchmark: val = 1.62857\n",
    "- with only `ind_actividad_client_combine`, `tiprel_1mes_combine`, `target_combine`, mlogloss=1.57141\n",
    "- with `ind_actividad_client_combine`, `tiprel_1mes_combine`, `target_combine`, `n_products` and patterns: val = 1.31122\n",
    "- Private score: 0.0302475, public score: 0.0299266"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if os.name=='nt':\n",
    "    try:\n",
    "        mingw_path = 'C:\\\\Program Files\\\\mingw-w64\\\\x86_64-8.1.0-posix-seh-rt_v6-rev0\\\\mingw64\\\\bin'\n",
    "        os.environ['PATH'] = mingw_path + ';' + os.environ['PATH']\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "import gc\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import copy\n",
    "import time\n",
    "\n",
    "tqdm.tqdm.pandas()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['ncodpers',\n",
    " 'canal_entrada',\n",
    " 'conyuemp',\n",
    " 'ind_actividad_cliente',\n",
    " 'ind_empleado',\n",
    " 'ind_nuevo',\n",
    " 'indext',\n",
    " 'indfall',\n",
    " 'indrel',\n",
    " 'indrel_1mes',\n",
    " 'indresi',\n",
    " 'pais_residencia',\n",
    " 'segmento',\n",
    " 'sexo',\n",
    " 'tipodom',\n",
    " 'tiprel_1mes',\n",
    " 'age',\n",
    " 'antiguedad',\n",
    " 'renta']\n",
    "\n",
    "target_cols = ['ind_cco_fin_ult1',\n",
    " 'ind_cder_fin_ult1',\n",
    " 'ind_cno_fin_ult1',\n",
    " 'ind_ctju_fin_ult1',\n",
    " 'ind_ctma_fin_ult1',\n",
    " 'ind_ctop_fin_ult1',\n",
    " 'ind_ctpp_fin_ult1',\n",
    " #'ind_deco_fin_ult1',\n",
    " 'ind_dela_fin_ult1',\n",
    " #'ind_deme_fin_ult1',\n",
    " 'ind_ecue_fin_ult1',\n",
    " 'ind_fond_fin_ult1',\n",
    " 'ind_hip_fin_ult1',\n",
    " 'ind_nom_pens_ult1',\n",
    " 'ind_nomina_ult1',\n",
    " 'ind_plan_fin_ult1',\n",
    " 'ind_pres_fin_ult1',\n",
    " 'ind_reca_fin_ult1',\n",
    " 'ind_recibo_ult1',\n",
    " 'ind_tjcr_fin_ult1',\n",
    " 'ind_valo_fin_ult1']\n",
    " #'ind_viv_fin_ult1']\n",
    "    \n",
    "month_list = ['2015-01-28', '2015-02-28', '2015-03-28', '2015-04-28', '2015-05-28', '2015-06-28', \n",
    "              '2015-07-28', '2015-08-28', '2015-09-28', '2015-10-28', '2015-11-28', '2015-12-28', \n",
    "              '2016-01-28', '2016-02-28', '2016-03-28', '2016-04-28', '2016-05-28', '2016-06-28']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding(x):\n",
    "    '''\n",
    "    Encoding the pattern in one product for one customer\n",
    "    (previous, this):\n",
    "    (0, 0): 0\n",
    "    (0, 1): 2\n",
    "    (1, 0): 1\n",
    "    (1, 1): 3\n",
    "    '''\n",
    "    a, b = x.values[:-1, :], x.values[1:, :]\n",
    "    c = a+b*2\n",
    "    c = pd.DataFrame(c, index=x.index[0:-1], columns=x.columns)\n",
    "    return c\n",
    "\n",
    "def count_changes(dt):\n",
    "    '''Process for the whole dataframe'''\n",
    "\n",
    "    # group by customer\n",
    "    group = dt.groupby('ncodpers')[target_cols]\n",
    "    # encode patterns\n",
    "    print('Encoding pattern...')\n",
    "    dt_changes = group.progress_apply(encoding)\n",
    "    \n",
    "    # find appearance each patterns\n",
    "    print('Finding pattern...')\n",
    "    a3 = (dt_changes==3.0).astype(int)\n",
    "    a3.columns = [k+'_p3' for k in a3.columns]\n",
    "    a2 = (dt_changes==2.0).astype(int)\n",
    "    a2.columns = [k+'_p2' for k in a2.columns]\n",
    "    a1 = (dt_changes==1.0).astype(int)\n",
    "    a1.columns = [k+'_p1' for k in a1.columns]\n",
    "    a0 = (dt_changes==0.0).astype(int)\n",
    "    a0.columns = [k+'_p0' for k in a0.columns]\n",
    "    a = pd.concat((a3, a2, a1, a0), axis=1)\n",
    "    \n",
    "    # count number of patterns\n",
    "    print('Counting pattern...')\n",
    "    dt_count = a.groupby('ncodpers').progress_apply(np.sum, axis=0)\n",
    "    \n",
    "    return dt_count\n",
    "\n",
    "def count_pattern(month1, max_lag):\n",
    "    '''\n",
    "    Encoding the pattern in one product for one customer\n",
    "    (previous, this):\n",
    "    (0, 0): 0\n",
    "    (0, 1): 2\n",
    "    (1, 0): 1\n",
    "    (1, 1): 3\n",
    "    '''\n",
    "        \n",
    "    month_end = month_list.index(month1)\n",
    "    month_start = month_end-max_lag+1\n",
    "    \n",
    "    # Create a DataFrame containing all the previous months up to the month_index month\n",
    "    df = []\n",
    "    for m in range(month_start, month_end+1):\n",
    "        df.append(pd.read_hdf('../input/data_month_{}.hdf'.format(month_list[m]), 'data_month'))\n",
    "\n",
    "    ncodpers_list = df[-1].ncodpers.unique().tolist()\n",
    "\n",
    "    df = pd.concat(df, ignore_index=True)\n",
    "    \n",
    "    # count patterns for customers with at least two months records\n",
    "    dt = count_changes(df)\n",
    "    \n",
    "    # create patterns for all customers, fillna with 0.0 if less than two months records\n",
    "    pattern_count = df.loc[df.fecha_dato==month_list[month_end], ['ncodpers']]\n",
    "    pattern_count.set_index('ncodpers', drop=False, inplace=True)\n",
    "    pattern_count = pattern_count.join(dt)\n",
    "    pattern_count.drop('ncodpers', axis=1, inplace=True)\n",
    "    pattern_count.fillna(0.0, inplace=True)\n",
    "       \n",
    "    return pattern_count\n",
    "\n",
    "def create_train_test(month, max_lag=5, target_flag=True):\n",
    "    '''Create train and test data for month'''\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    month2 = month # the second month\n",
    "    month1 = month_list[month_list.index(month2)-1] # the first month\n",
    "    \n",
    "    print('Loading {} data'.format(month1))\n",
    "    # first/early month\n",
    "    df1 = pd.read_hdf('../input/data_month_{}.hdf'.format(month1), 'data_month')\n",
    "    print('Loading {} data'.format(month2))\n",
    "    # second/later month\n",
    "    df2 = pd.read_hdf('../input/data_month_{}.hdf'.format(month2), 'data_month')\n",
    "    \n",
    "    print('Products in {}...'.format(month2))\n",
    "    # second month products\n",
    "    df2_target = df2.loc[:, ['ncodpers']+target_cols].copy()\n",
    "    df2_target.set_index('ncodpers', inplace=True, drop=False) # initially keep ncodpers as a column and drop it later\n",
    "    # a dataframe containing the ncodpers only\n",
    "    df2_ncodpers = pd.DataFrame(df2_target.ncodpers)\n",
    "    # drop ncodpers from df2_target\n",
    "    df2_target.drop('ncodpers', axis=1, inplace=True)\n",
    "    \n",
    "    print('Products in {}...'.format(month1))\n",
    "    # first month products for all the customers in the second month\n",
    "    df1_target = df1.loc[:, ['ncodpers']+target_cols].copy()\n",
    "    df1_target.set_index('ncodpers', inplace=True, drop=True) # do not keep ncodpers as column\n",
    "    # obtain the products purchased by all the customers in the second month\n",
    "    # by joining df1_target to df2_ncodpers, NAN filled by 0.0\n",
    "    df1_target = df2_ncodpers.join(df1_target, how='left')\n",
    "    df1_target.fillna(0.0, inplace=True)\n",
    "    df1_target.drop('ncodpers', axis=1, inplace=True)\n",
    "    \n",
    "    print('New products added in {}...'.format(month2))\n",
    "    # new products from the first to second month\n",
    "    target = df2_target.subtract(df1_target)\n",
    "    target[target<0] = 0\n",
    "    target.fillna(0.0, inplace=True)\n",
    "    \n",
    "    print('Join customer features and previous month products for {}...'.format(month2))\n",
    "    # feature of the second month: \n",
    "    # 1. customer features in the second month\n",
    "    # 2. products in the first month\n",
    "    x_vars = df2[cat_cols].copy() # cat_cols already includes ncodpers\n",
    "    x_vars.reset_index(inplace=True, drop=True) # drop original index and make a new one\n",
    "    x_vars.reset_index(inplace=True, drop=False) # also set the new index as a column for recoding row orders\n",
    "    x_vars_cols = x_vars.columns.tolist()\n",
    "    x_vars_cols[0] = 'sample_order' # change the name of the new column\n",
    "    x_vars.columns = x_vars_cols\n",
    "    x_vars.set_index('ncodpers', drop=True, inplace=True) # set the index to ncodpers again\n",
    "    x_vars = x_vars.join(df1_target) # direct join since df1_target contains all customers in month2\n",
    "    \n",
    "    print('Concatenate this and previous months ind_activadad_cliente.')\n",
    "    # concatenate this and previous month values of ind_activadad_cliente\n",
    "    df2_ind_actividad_cliente = df2[['ncodpers', 'ind_actividad_cliente']].copy()\n",
    "    df2_ind_actividad_cliente.set_index('ncodpers', inplace=True)\n",
    "    df2_ind_actividad_cliente.sort_index(inplace=True)\n",
    "    \n",
    "    df1_ind_actividad_cliente = df1[['ncodpers', 'ind_actividad_cliente']].copy()\n",
    "    df1_ind_actividad_cliente.set_index('ncodpers', inplace=True)\n",
    "    df1_ind_actividad_cliente.sort_index(inplace=True)\n",
    "\n",
    "    df2_ind_actividad_cliente = df2_ind_actividad_cliente.join(df1_ind_actividad_cliente, rsuffix='_p')\n",
    "    df2_ind_actividad_cliente.fillna(2.0, inplace=True)\n",
    "    df2_ind_actividad_cliente['ind_actividad_client_combine'] = 3*df2_ind_actividad_cliente.ind_actividad_cliente+df2_ind_actividad_cliente.ind_actividad_cliente_p\n",
    "    df2_ind_actividad_cliente = pd.DataFrame(df2_ind_actividad_cliente.iloc[:, -1])\n",
    "\n",
    "    x_vars = pd.merge(x_vars, df2_ind_actividad_cliente, left_index=True, right_index=True, how='left')\n",
    "    \n",
    "    print('Concatenate this and previous months tiprel_1mes.')\n",
    "    # concatenate this and previous month value of tiprel_1mes\n",
    "    df2_tiprel_1mes = df2[['ncodpers', 'tiprel_1mes']].copy()\n",
    "    df2_tiprel_1mes.set_index('ncodpers', inplace=True)\n",
    "    df2_tiprel_1mes.sort_index(inplace=True)\n",
    "\n",
    "    df1_tiprel_1mes = df1[['ncodpers', 'tiprel_1mes']].copy()\n",
    "    df1_tiprel_1mes.set_index('ncodpers', inplace=True)\n",
    "    df1_tiprel_1mes.sort_index(inplace=True)\n",
    "\n",
    "    df2_tiprel_1mes = df2_tiprel_1mes.join(df1_tiprel_1mes, rsuffix='_p')\n",
    "    df2_tiprel_1mes.fillna(0.0, inplace=True)\n",
    "    df2_tiprel_1mes['tiprel_1mes_combine'] = 6*df2_tiprel_1mes.tiprel_1mes+df2_tiprel_1mes.tiprel_1mes_p\n",
    "    df2_tiprel_1mes = pd.DataFrame(df2_tiprel_1mes.iloc[:, -1])\n",
    "\n",
    "    x_vars = pd.merge(x_vars, df2_tiprel_1mes, left_index=True, right_index=True, how='left')\n",
    "    \n",
    "    print('Combine all products for each customer.')\n",
    "    # combination of target columns\n",
    "    x_vars['target_combine'] = np.sum(x_vars[target_cols].values*\n",
    "        np.float_power(2, np.arange(-10, len(target_cols)-10)), axis=1, dtype=np.float64)\n",
    "    \n",
    "    # number of purchased products in the previous month\n",
    "    x_vars['n_products'] = x_vars[target_cols].sum(axis=1)\n",
    "\n",
    "    print('\\nStart counting patterns:')\n",
    "    # count patterns of historical products\n",
    "    dp = count_pattern(month1, max_lag)\n",
    "    x_vars = x_vars.join(dp)\n",
    "    x_vars.loc[:, dp.columns] = x_vars.loc[:, dp.columns].fillna(-1)\n",
    "    \n",
    "    #return x_vars, df2_ncodpers, df1, df2, df1_target, df2_target\n",
    "    \n",
    "    # return x_vars if target_flag is False\n",
    "    if not target_flag:\n",
    "        x_vars.drop('sample_order', axis=1, inplace=True) # drop sample_order\n",
    "        x_vars.reset_index(inplace=True, drop=False) # add ncodpers\n",
    "        \n",
    "        end_time = time.time()\n",
    "        print('Time used: {:.3f} min'.format((end_time-start_time)/60.0))\n",
    "        \n",
    "        return x_vars #, df2_ncodpers, df1, df2, df1_target, df2_target\n",
    "    \n",
    "    if target_flag:    \n",
    "        # prepare target/label for each added product from the first to second month\n",
    "        # join target to x_vars\n",
    "        x_vars_new = x_vars.join(target, rsuffix='_t')\n",
    "        # set ncodpers as one column\n",
    "        x_vars_new.reset_index(inplace=True, drop=False)\n",
    "        x_vars.reset_index(inplace=True, drop=False)\n",
    "\n",
    "        # melt\n",
    "        x_vars_new = x_vars_new.melt(id_vars=x_vars.columns)\n",
    "        # mapping from target_cols to index\n",
    "        target_cols_mapping = {c+'_t': n for (n, c) in enumerate(target_cols)}\n",
    "        # replace column name by index\n",
    "        x_vars_new.variable.replace(target_cols_mapping, inplace=True)\n",
    "        # reorder rows\n",
    "        x_vars_new.sort_values(['sample_order', 'variable'], inplace=True)\n",
    "        # keep new products\n",
    "        x_vars_new = x_vars_new[x_vars_new.value>0]\n",
    "        # drop sample_order and value\n",
    "        x_vars_new.drop(['sample_order', 'value'], axis=1, inplace=True)\n",
    "        # keep the order of rows as in the original data set\n",
    "        x_vars_new.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        var_cols = x_vars.columns.tolist()\n",
    "        var_cols.remove('sample_order')\n",
    "        # variable\n",
    "        x_vars = x_vars_new.loc[:, var_cols].copy()\n",
    "        # target/label\n",
    "        target = x_vars_new.loc[:, 'variable'].copy()\n",
    "\n",
    "        end_time = time.time()\n",
    "        print('Time used: {:.3f} min'.format((end_time-start_time)/60.0))\n",
    "        \n",
    "        return x_vars, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 2015-05-28 data\n",
      "Loading 2015-06-28 data\n",
      "Products in 2015-06-28...\n",
      "Products in 2015-05-28...\n",
      "New products added in 2015-06-28...\n",
      "Join customer features and previous month products for 2015-06-28...\n",
      "Concatenate this and previous months ind_activadad_cliente.\n",
      "Concatenate this and previous months tiprel_1mes.\n",
      "Combine all products for each customer.\n",
      "\n",
      "Start counting patterns:\n",
      "Encoding pattern...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 640825/640825 [01:41<00:00, 6307.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding pattern...\n",
      "Counting pattern...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 634760/634760 [03:11<00:00, 3323.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time used: 5.932 min\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = create_train_test('2015-06-28', target_flag=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 2015-11-28 data\n",
      "Loading 2015-12-28 data\n",
      "Products in 2015-12-28...\n",
      "Products in 2015-11-28...\n",
      "New products added in 2015-12-28...\n",
      "Join customer features and previous month products for 2015-12-28...\n",
      "Concatenate this and previous months ind_activadad_cliente.\n",
      "Concatenate this and previous months tiprel_1mes.\n",
      "Combine all products for each customer.\n",
      "\n",
      "Start counting patterns:\n",
      "Encoding pattern...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 912728/912728 [02:23<00:00, 6368.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding pattern...\n",
      "Counting pattern...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 893990/893990 [04:30<00:00, 3302.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time used: 8.403 min\n"
     ]
    }
   ],
   "source": [
    "x_val, y_val = create_train_test('2015-12-28', max_lag=5, target_flag=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 2016-05-28 data\n",
      "Loading 2016-06-28 data\n",
      "Products in 2016-06-28...\n",
      "Products in 2016-05-28...\n",
      "New products added in 2016-06-28...\n",
      "Join customer features and previous month products for 2016-06-28...\n",
      "Concatenate this and previous months ind_activadad_cliente.\n",
      "Concatenate this and previous months tiprel_1mes.\n",
      "Combine all products for each customer.\n",
      "\n",
      "Start counting patterns:\n",
      "Encoding pattern...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 938423/938423 [02:29<00:00, 6292.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding pattern...\n",
      "Counting pattern...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 930436/930436 [04:39<00:00, 3326.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time used: 7.526 min\n"
     ]
    }
   ],
   "source": [
    "x_test = create_train_test('2016-06-28', max_lag=5, target_flag=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model\n",
    "\n",
    "- benchmark: val = 1.62857\n",
    "- with only `ind_actividad_client_combine`, `tiprel_1mes_combine`, `target_combine`, mlogloss=1.57141\n",
    "- with `ind_actividad_client_combine`, `tiprel_1mes_combine`, `target_combine`, `n_products` and patterns: val = 1.31122"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:2.71402\tval-mlogloss:2.75939\n",
      "[1]\ttrain-mlogloss:2.54589\tval-mlogloss:2.60954\n",
      "[2]\ttrain-mlogloss:2.40884\tval-mlogloss:2.48637\n",
      "[3]\ttrain-mlogloss:2.29508\tval-mlogloss:2.38487\n",
      "[4]\ttrain-mlogloss:2.19892\tval-mlogloss:2.30475\n",
      "[5]\ttrain-mlogloss:2.11299\tval-mlogloss:2.23605\n",
      "[6]\ttrain-mlogloss:2.0368\tval-mlogloss:2.17092\n",
      "[7]\ttrain-mlogloss:1.96881\tval-mlogloss:2.10959\n",
      "[8]\ttrain-mlogloss:1.90714\tval-mlogloss:2.05393\n",
      "[9]\ttrain-mlogloss:1.85086\tval-mlogloss:2.00371\n",
      "[10]\ttrain-mlogloss:1.79873\tval-mlogloss:1.95666\n",
      "[11]\ttrain-mlogloss:1.75059\tval-mlogloss:1.91418\n",
      "[12]\ttrain-mlogloss:1.70589\tval-mlogloss:1.87387\n",
      "[13]\ttrain-mlogloss:1.66512\tval-mlogloss:1.84128\n",
      "[14]\ttrain-mlogloss:1.62729\tval-mlogloss:1.8082\n",
      "[15]\ttrain-mlogloss:1.59099\tval-mlogloss:1.77718\n",
      "[16]\ttrain-mlogloss:1.557\tval-mlogloss:1.74651\n",
      "[17]\ttrain-mlogloss:1.52485\tval-mlogloss:1.71792\n",
      "[18]\ttrain-mlogloss:1.49498\tval-mlogloss:1.69208\n",
      "[19]\ttrain-mlogloss:1.46665\tval-mlogloss:1.66769\n",
      "[20]\ttrain-mlogloss:1.44015\tval-mlogloss:1.64457\n",
      "[21]\ttrain-mlogloss:1.41476\tval-mlogloss:1.62239\n",
      "[22]\ttrain-mlogloss:1.39083\tval-mlogloss:1.60341\n",
      "[23]\ttrain-mlogloss:1.36813\tval-mlogloss:1.58363\n",
      "[24]\ttrain-mlogloss:1.3468\tval-mlogloss:1.56537\n",
      "[25]\ttrain-mlogloss:1.32664\tval-mlogloss:1.5473\n",
      "[26]\ttrain-mlogloss:1.30746\tval-mlogloss:1.53129\n",
      "[27]\ttrain-mlogloss:1.28899\tval-mlogloss:1.5178\n",
      "[28]\ttrain-mlogloss:1.27138\tval-mlogloss:1.50229\n",
      "[29]\ttrain-mlogloss:1.25436\tval-mlogloss:1.49003\n",
      "[30]\ttrain-mlogloss:1.23803\tval-mlogloss:1.47872\n",
      "[31]\ttrain-mlogloss:1.22273\tval-mlogloss:1.46541\n",
      "[32]\ttrain-mlogloss:1.20795\tval-mlogloss:1.45492\n",
      "[33]\ttrain-mlogloss:1.194\tval-mlogloss:1.44324\n",
      "[34]\ttrain-mlogloss:1.18061\tval-mlogloss:1.4329\n",
      "[35]\ttrain-mlogloss:1.16764\tval-mlogloss:1.42209\n",
      "[36]\ttrain-mlogloss:1.15535\tval-mlogloss:1.41175\n",
      "[37]\ttrain-mlogloss:1.14376\tval-mlogloss:1.40243\n",
      "[38]\ttrain-mlogloss:1.13244\tval-mlogloss:1.39228\n",
      "[39]\ttrain-mlogloss:1.12171\tval-mlogloss:1.38274\n",
      "[40]\ttrain-mlogloss:1.11121\tval-mlogloss:1.37399\n",
      "[41]\ttrain-mlogloss:1.10117\tval-mlogloss:1.3659\n",
      "[42]\ttrain-mlogloss:1.09167\tval-mlogloss:1.35858\n",
      "[43]\ttrain-mlogloss:1.08239\tval-mlogloss:1.35084\n",
      "[44]\ttrain-mlogloss:1.0736\tval-mlogloss:1.34442\n",
      "[45]\ttrain-mlogloss:1.06488\tval-mlogloss:1.33685\n",
      "[46]\ttrain-mlogloss:1.05684\tval-mlogloss:1.33035\n",
      "[47]\ttrain-mlogloss:1.04881\tval-mlogloss:1.32423\n",
      "[48]\ttrain-mlogloss:1.04096\tval-mlogloss:1.31755\n",
      "[49]\ttrain-mlogloss:1.03339\tval-mlogloss:1.31122\n"
     ]
    }
   ],
   "source": [
    "param = {'objective': 'multi:softprob', \n",
    "         'eta': 0.05, \n",
    "         'max_depth': 8, \n",
    "         'silent': 1, \n",
    "         'num_class': len(target_cols),\n",
    "         'eval_metric': 'mlogloss',\n",
    "         'min_child_weight': 1,\n",
    "         'subsample': 0.7,\n",
    "         'colsample_bytree': 0.7,\n",
    "         'seed': 0}\n",
    "num_rounds = 50\n",
    "\n",
    "dtrain = xgb.DMatrix(x_train.values, y_train.values)\n",
    "dval = xgb.DMatrix(x_val.values, y_val.values)\n",
    "model = xgb.train(param, dtrain, num_rounds, evals=[(dtrain, 'train'), (dval, 'val')], verbose_eval=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction from my model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(xgb.DMatrix(x_test.values))\n",
    "\n",
    "df_preds = pd.DataFrame(preds, index=x_test.index, columns=target_cols)\n",
    "# Remove already bought products \n",
    "df_preds[x_test[target_cols]==1] = 0 \n",
    "preds = df_preds.values\n",
    "preds = np.argsort(preds, axis=1)\n",
    "preds = np.fliplr(preds)[:, :7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write out prediction results from my model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = x_test.loc[:, 'ncodpers'].values\n",
    "final_preds = [' '.join([target_cols[k] for k in pred]) for pred in preds]\n",
    "\n",
    "out_df = pd.DataFrame({'ncodpers': test_id, 'added_products': final_preds})\n",
    "out_df.to_csv('eda_4_16.csv.gz', compression='gzip', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
