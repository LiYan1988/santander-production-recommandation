{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering in RAM-Limited Data, Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if os.name=='nt':\n",
    "    try:\n",
    "        mingw_path = 'C:\\\\Program Files\\\\mingw-w64\\\\x86_64-8.1.0-posix-seh-rt_v6-rev0\\\\mingw64\\\\bin'\n",
    "        os.environ['PATH'] = mingw_path + ';' + os.environ['PATH']\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "import gc\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import copy\n",
    "import time\n",
    "\n",
    "tqdm.tqdm.pandas()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['ncodpers',\n",
    " 'canal_entrada',\n",
    " 'conyuemp',\n",
    " 'ind_actividad_cliente',\n",
    " 'ind_empleado',\n",
    " 'ind_nuevo',\n",
    " 'indext',\n",
    " 'indfall',\n",
    " 'indrel',\n",
    " 'indrel_1mes',\n",
    " 'indresi',\n",
    " 'pais_residencia',\n",
    " 'segmento',\n",
    " 'sexo',\n",
    " 'tipodom',\n",
    " 'tiprel_1mes',\n",
    " 'age',\n",
    " 'antiguedad',\n",
    " 'renta']\n",
    "\n",
    "target_cols = ['ind_cco_fin_ult1',\n",
    " 'ind_cder_fin_ult1',\n",
    " 'ind_cno_fin_ult1',\n",
    " 'ind_ctju_fin_ult1',\n",
    " 'ind_ctma_fin_ult1',\n",
    " 'ind_ctop_fin_ult1',\n",
    " 'ind_ctpp_fin_ult1',\n",
    " #'ind_deco_fin_ult1',\n",
    " 'ind_dela_fin_ult1',\n",
    " #'ind_deme_fin_ult1',\n",
    " 'ind_ecue_fin_ult1',\n",
    " 'ind_fond_fin_ult1',\n",
    " 'ind_hip_fin_ult1',\n",
    " 'ind_nom_pens_ult1',\n",
    " 'ind_nomina_ult1',\n",
    " 'ind_plan_fin_ult1',\n",
    " 'ind_pres_fin_ult1',\n",
    " 'ind_reca_fin_ult1',\n",
    " 'ind_recibo_ult1',\n",
    " 'ind_tjcr_fin_ult1',\n",
    " 'ind_valo_fin_ult1']\n",
    " #'ind_viv_fin_ult1']\n",
    "    \n",
    "month_list = ['2015-01-28', '2015-02-28', '2015-03-28', '2015-04-28', '2015-05-28', '2015-06-28', \n",
    "              '2015-07-28', '2015-08-28', '2015-09-28', '2015-10-28', '2015-11-28', '2015-12-28', \n",
    "              '2016-01-28', '2016-02-28', '2016-03-28', '2016-04-28', '2016-05-28', '2016-06-28']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test(month1, month2, target_flag=True):\n",
    "    '''Create train and test data between month1 and month2'''\n",
    "    \n",
    "    # first/early month\n",
    "    df1 = pd.read_hdf('../input/data_month_{}.hdf'.format(month1), 'data_month')\n",
    "    # second/later month\n",
    "    df2 = pd.read_hdf('../input/data_month_{}.hdf'.format(month2), 'data_month')\n",
    "    \n",
    "    # second month products\n",
    "    df2_target = df2.loc[:, ['ncodpers']+target_cols].copy()\n",
    "    df2_target.set_index('ncodpers', inplace=True, drop=False) # initially keep ncodpers as a column and drop it later\n",
    "    # a dataframe containing the ncodpers only\n",
    "    df2_ncodpers = pd.DataFrame(df2_target.ncodpers)\n",
    "    # drop ncodpers from df2_target\n",
    "    df2_target.drop('ncodpers', axis=1, inplace=True)\n",
    "    \n",
    "    # first month products for all the customers in the second month\n",
    "    df1_target = df1.loc[:, ['ncodpers']+target_cols].copy()\n",
    "    df1_target.set_index('ncodpers', inplace=True, drop=True) # do not keep ncodpers as column\n",
    "    # obtain the products purchased by all the customers in the second month\n",
    "    # by joining df1_target to df2_ncodpers, NAN filled by 0.0\n",
    "    df1_target = df2_ncodpers.join(df1_target, how='left')\n",
    "    df1_target.fillna(0.0, inplace=True)\n",
    "    df1_target.drop('ncodpers', axis=1, inplace=True)\n",
    "    \n",
    "    # new products from the first to second month\n",
    "    target = df2_target.subtract(df1_target)\n",
    "    target[target<0] = 0\n",
    "    target.fillna(0.0, inplace=True)\n",
    "    \n",
    "    # feature of the second month: \n",
    "    # 1. customer features in the second month\n",
    "    # 2. products in the first month\n",
    "    x_vars = df2[cat_cols].copy() # cat_cols already includes ncodpers\n",
    "    x_vars.reset_index(inplace=True, drop=True) # drop original index and make a new one\n",
    "    x_vars.reset_index(inplace=True, drop=False) # also set the new index as a column for recoding row orders\n",
    "    x_vars_cols = x_vars.columns.tolist()\n",
    "    x_vars_cols[0] = 'sample_order' # change the name of the new column\n",
    "    x_vars.columns = x_vars_cols\n",
    "    x_vars.set_index('ncodpers', drop=True, inplace=True) # set the index to ncodpers again\n",
    "    x_vars = x_vars.join(df1_target) # direct join since df1_target contains all customers in month2\n",
    "    \n",
    "    # concatenate this and previous month values of ind_activadad_cliente\n",
    "    df2_ind_actividad_cliente = df2[['ncodpers', 'ind_actividad_cliente']].copy()\n",
    "    df2_ind_actividad_cliente.set_index('ncodpers', inplace=True)\n",
    "    df2_ind_actividad_cliente.sort_index(inplace=True)\n",
    "    \n",
    "    df1_ind_actividad_cliente = df1[['ncodpers', 'ind_actividad_cliente']].copy()\n",
    "    df1_ind_actividad_cliente.set_index('ncodpers', inplace=True)\n",
    "    df1_ind_actividad_cliente.sort_index(inplace=True)\n",
    "\n",
    "    df2_ind_actividad_cliente = df2_ind_actividad_cliente.join(df1_ind_actividad_cliente, rsuffix='_p')\n",
    "    df2_ind_actividad_cliente.fillna(2.0, inplace=True)\n",
    "    df2_ind_actividad_cliente['ind_actividad_client_combine'] = 3*df2_ind_actividad_cliente.ind_actividad_cliente+df2_ind_actividad_cliente.ind_actividad_cliente_p\n",
    "    df2_ind_actividad_cliente = pd.DataFrame(df2_ind_actividad_cliente.iloc[:, -1])\n",
    "\n",
    "    x_vars = pd.merge(x_vars, df2_ind_actividad_cliente, left_index=True, right_index=True, how='left')\n",
    "    \n",
    "    # concatenate this and previous month value of tiprel_1mes\n",
    "    df2_tiprel_1mes = df2[['ncodpers', 'tiprel_1mes']].copy()\n",
    "    df2_tiprel_1mes.set_index('ncodpers', inplace=True)\n",
    "    df2_tiprel_1mes.sort_index(inplace=True)\n",
    "\n",
    "    df1_tiprel_1mes = df1[['ncodpers', 'tiprel_1mes']].copy()\n",
    "    df1_tiprel_1mes.set_index('ncodpers', inplace=True)\n",
    "    df1_tiprel_1mes.sort_index(inplace=True)\n",
    "\n",
    "    df2_tiprel_1mes = df2_tiprel_1mes.join(df1_tiprel_1mes, rsuffix='_p')\n",
    "    df2_tiprel_1mes.fillna(0.0, inplace=True)\n",
    "    df2_tiprel_1mes['tiprel_1mes_combine'] = 6*df2_tiprel_1mes.tiprel_1mes+df2_tiprel_1mes.tiprel_1mes_p\n",
    "    df2_tiprel_1mes = pd.DataFrame(df2_tiprel_1mes.iloc[:, -1])\n",
    "\n",
    "    x_vars = pd.merge(x_vars, df2_tiprel_1mes, left_index=True, right_index=True, how='left')\n",
    "    \n",
    "    # combination of target columns\n",
    "    x_vars['target_combine'] = np.sum(x_vars[target_cols].values*\n",
    "        np.float_power(2, np.arange(-10, len(target_cols)-10)), axis=1, dtype=np.float64)\n",
    "    \n",
    "    # number of purchased products in the previous month\n",
    "    x_vars['n_products'] = x_vars[target_cols].sum(axis=1)\n",
    "    \n",
    "    # return x_vars, df2_ncodpers, df1, df2, df1_target, df2_target\n",
    "    \n",
    "    # return x_vars if target_flag is False\n",
    "    if not target_flag:\n",
    "        x_vars.drop('sample_order', axis=1, inplace=True) # drop sample_order\n",
    "        x_vars.reset_index(inplace=True, drop=False) # add ncodpers\n",
    "        return x_vars #, df2_ncodpers, df1, df2, df1_target, df2_target\n",
    "    \n",
    "    if target_flag:    \n",
    "        # prepare target/label for each added product from the first to second month\n",
    "        # join target to x_vars\n",
    "        x_vars_new = x_vars.join(target, rsuffix='_t')\n",
    "        # set ncodpers as one column\n",
    "        x_vars_new.reset_index(inplace=True, drop=False)\n",
    "        x_vars.reset_index(inplace=True, drop=False)\n",
    "\n",
    "        # melt\n",
    "        x_vars_new = x_vars_new.melt(id_vars=x_vars.columns)\n",
    "        # mapping from target_cols to index\n",
    "        target_cols_mapping = {c+'_t': n for (n, c) in enumerate(target_cols)}\n",
    "        # replace column name by index\n",
    "        x_vars_new.variable.replace(target_cols_mapping, inplace=True)\n",
    "        # reorder rows\n",
    "        x_vars_new.sort_values(['sample_order', 'variable'], inplace=True)\n",
    "        # keep new products\n",
    "        x_vars_new = x_vars_new[x_vars_new.value>0]\n",
    "        # drop sample_order and value\n",
    "        x_vars_new.drop(['sample_order', 'value'], axis=1, inplace=True)\n",
    "        # keep the order of rows as in the original data set\n",
    "        x_vars_new.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        var_cols = x_vars.columns.tolist()\n",
    "        var_cols.remove('sample_order')\n",
    "        # variable\n",
    "        x_vars = x_vars_new.loc[:, var_cols].copy()\n",
    "        # target/label\n",
    "        target = x_vars_new.loc[:, 'variable'].copy()\n",
    "\n",
    "        return x_vars, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train, y_train = create_train_test('2015-05-28', '2015-06-28', target_flag=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_val, y_val = create_train_test('2015-11-28', '2015-12-28', target_flag=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count of index change pattern (0 to 0, 0 to 1, 1 to 0 and 1 to 1) until last month of 20 products (80 features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#month1 = month_list[5]\n",
    "#df1 = pd.read_hdf('../input/data_month_{}.hdf'.format(month1), 'data_month')\n",
    "#df1_ncodpers = df1.ncodpers.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding(x):\n",
    "    '''\n",
    "    Encoding the pattern in one product for one customer\n",
    "    (previous, this):\n",
    "    (0, 0): 0\n",
    "    (0, 1): 2\n",
    "    (1, 0): 1\n",
    "    (1, 1): 3\n",
    "    '''\n",
    "    a, b = x.values[:-1, :], x.values[1:, :]\n",
    "    c = a+b*2\n",
    "    c = pd.DataFrame(c, index=x.index[0:-1], columns=x.columns)\n",
    "    return c\n",
    "\n",
    "def count_changes(dt):\n",
    "    '''Process for the whole dataframe'''\n",
    "\n",
    "    # group by customer\n",
    "    group = dt.groupby('ncodpers')[target_cols]\n",
    "    # encode patterns\n",
    "    print('Encoding pattern...')\n",
    "    dt_changes = group.progress_apply(encoding)\n",
    "    \n",
    "    # find appearance each patterns\n",
    "    print('Finding pattern...')\n",
    "    a3 = (dt_changes==3.0).astype(int)\n",
    "    a3.columns = [k+'_3' for k in a3.columns]\n",
    "    a2 = (dt_changes==2.0).astype(int)\n",
    "    a2.columns = [k+'_2' for k in a2.columns]\n",
    "    a1 = (dt_changes==1.0).astype(int)\n",
    "    a1.columns = [k+'_1' for k in a1.columns]\n",
    "    a0 = (dt_changes==0.0).astype(int)\n",
    "    a0.columns = [k+'_0' for k in a0.columns]\n",
    "    a = pd.concat((a3, a2, a1, a0), axis=1)\n",
    "    \n",
    "    # count number of patterns\n",
    "    print('Counting pattern...')\n",
    "    dt_count = a.groupby('ncodpers').progress_apply(np.sum, axis=0)\n",
    "    \n",
    "    return dt_count\n",
    "\n",
    "def count_pattern(month_index):\n",
    "    '''\n",
    "    Encoding the pattern in one product for one customer\n",
    "    (previous, this):\n",
    "    (0, 0): 0\n",
    "    (0, 1): 2\n",
    "    (1, 0): 1\n",
    "    (1, 1): 3\n",
    "    '''\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Create a DataFrame containing all the previous months up to the month_index month\n",
    "    df = []\n",
    "    for m in range(month_index):\n",
    "        df.append(pd.read_hdf('../input/data_month_{}.hdf'.format(month_list[m]), 'data_month'))\n",
    "\n",
    "    ncodpers_list = df[-1].ncodpers.unique().tolist()\n",
    "\n",
    "    df = pd.concat(df, ignore_index=True)\n",
    "    \n",
    "    # count patterns for customers with at least two months records\n",
    "    dt = count_changes(df)\n",
    "    \n",
    "    # create patterns for all customers, fillna with 0.0 if less than two months records\n",
    "    pattern_count = df.loc[df.fecha_dato==month_list[month_index-1], ['ncodpers']]\n",
    "    pattern_count.set_index('ncodpers', drop=False, inplace=True)\n",
    "    pattern_count = pattern_count.join(dt)\n",
    "    pattern_count.drop('ncodpers', axis=1, inplace=True)\n",
    "    pattern_count.fillna(0.0, inplace=True)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    print('Time used: {:.3f} min'.format((end_time-start_time)/60.0))\n",
    "    \n",
    "    return pattern_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding pattern...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 640825/640825 [02:56<00:00, 3623.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding pattern...\n",
      "Counting pattern...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 634760/634760 [05:42<00:00, 1855.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time used: 8.762 min\n"
     ]
    }
   ],
   "source": [
    "dp = count_pattern(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 76)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df = []\n",
    "for m in range(5):\n",
    "    df.append(pd.read_hdf('../input/data_month_{}.hdf'.format(month_list[m]), 'data_month'))\n",
    "\n",
    "ncodpers_list = df[-1].ncodpers.unique().tolist()\n",
    "\n",
    "df = pd.concat(df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dt = count_changes(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pattern_count = df.loc[df.fecha_dato=='2015-05-28', ['ncodpers']]\n",
    "\n",
    "pattern_count.set_index('ncodpers', drop=False, inplace=True)\n",
    "\n",
    "pattern_count = pattern_count.join(dt)\n",
    "\n",
    "pattern_count.drop('ncodpers', axis=1, inplace=True)\n",
    "\n",
    "pattern_count.fillna(0.0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model\n",
    "\n",
    "- benchmark val: 1.58164"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "param = {'objective': 'multi:softprob', \n",
    "         'eta': 0.05, \n",
    "         'max_depth': 8, \n",
    "         'silent': 1, \n",
    "         'num_class': len(target_cols),\n",
    "         'eval_metric': 'mlogloss',\n",
    "         'min_child_weight': 1,\n",
    "         'subsample': 0.7,\n",
    "         'colsample_bytree': 0.7,\n",
    "         'seed': 0}\n",
    "num_rounds = 50\n",
    "\n",
    "dtrain = xgb.DMatrix(x_train.values, y_train.values)\n",
    "dval = xgb.DMatrix(x_val.values, y_val.values)\n",
    "model = xgb.train(param, dtrain, num_rounds, evals=[(dtrain, 'train'), (dval, 'val')], verbose_eval=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction from my model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preds = model.predict(xgb.DMatrix(x_test.values))\n",
    "\n",
    "df_preds = pd.DataFrame(preds, index=x_test.index, columns=target_cols)\n",
    "df_preds[x_test[target_cols]==1] = 0\n",
    "preds = df_preds.values\n",
    "preds = np.argsort(preds, axis=1)\n",
    "preds = np.fliplr(preds)[:, :7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write out prediction results from my model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test_id = x_test.loc[:, 'ncodpers'].values\n",
    "final_preds = [' '.join([target_cols[k] for k in pred]) for pred in preds]\n",
    "\n",
    "out_df = pd.DataFrame({'ncodpers': test_id, 'added_products': final_preds})\n",
    "out_df.to_csv('eda_4_15.csv.gz', compression='gzip', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
