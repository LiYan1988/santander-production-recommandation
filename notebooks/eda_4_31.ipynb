{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAP\n",
    "\n",
    "Improve MAP evaluation speed\n",
    "10 times run:\n",
    "- 17.7s: original\n",
    "- 18.05s: removes `apks`\n",
    "- 18.01: remove `enumerate`\n",
    "- 17.04: remove `y_prob = {}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from santander_helper import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def apk1(actual, predicted, k=7, default=0.0):\n",
    "    if predicted.size>k:\n",
    "        predicted = predicted[:k]\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "    \n",
    "    for i,p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "\n",
    "    if actual.size==0:\n",
    "        return default\n",
    "\n",
    "    return score / min(actual.size, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def eval_map1(y_prob, dtrain, gt={}, ts={}):\n",
    "    '''\n",
    "    Evaluate MAP@7 for train and validation sets---\n",
    "    '''\n",
    "    # Check which set is it?\n",
    "    if len(dtrain.get_label())==ts['train']:\n",
    "        glist = gt['train']\n",
    "    elif len(dtrain.get_label())==ts['val']:\n",
    "        glist = gt['val']\n",
    "    \n",
    "    n = len(gti)\n",
    "    score = 0\n",
    "    for i in range(n):\n",
    "        tmp = np.mean(y_prob[glist[i][1], :], axis=0)\n",
    "        tmp = np.argsort(tmp)[:-8:-1]\n",
    "        score += apk1(glist[i][0], tmp)\n",
    "    score /= n\n",
    "\n",
    "    return 'MAP@7', score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_map1(x_train, y_train):\n",
    "    '''Prepare ground truth value and index for MAP evaluation, and save it.'''\n",
    "    # Ground truth value: MAP needs to know the products bought by each customers\n",
    "    gtv = pd.concat((pd.DataFrame(x_train.loc[:, 'ncodpers'].copy()), y_train), axis=1, ignore_index=True)\n",
    "    gtv.columns = ['ncodpers', 'target']\n",
    "    gtv = gtv.groupby('ncodpers')['target'].apply(lambda x: x.values).to_dict()\n",
    "    # Ground truth index: MAP needs to know for each customer which rows are its corresponding data\n",
    "    gti = pd.DataFrame(x_train.loc[:, 'ncodpers']).reset_index()\n",
    "    gti = gti.groupby('ncodpers')['index'].apply(lambda x: x.values).to_dict()\n",
    "    \n",
    "    gt = [(gtv[k], gti[k]) for k in gtv.keys()]\n",
    "    \n",
    "    return gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_month1(param, num_rounds, month_train, month_val, n_repeat=2, random_seed=0,\n",
    "                    lag_train=5, lag_val=5, weight_set=(1), verbose_eval=True):\n",
    "    '''Train on one month and validate on another'''\n",
    "    history = {}\n",
    "    model_dict = {}\n",
    "\n",
    "    x_train, y_train, weight_train = create_train(month_train, max_lag=lag_train, pattern_flag=True)\n",
    "    x_val, y_val, weight_val = create_train(month_val, max_lag=lag_val, pattern_flag=True)\n",
    "\n",
    "    gt_train = prep_map(x_train, y_train)\n",
    "    gt_val = prep_map(x_val, y_val)\n",
    "\n",
    "    dtrain = xgb.DMatrix(x_train, y_train)\n",
    "    dval = xgb.DMatrix(x_val, y_val)\n",
    "\n",
    "    ground_truth = {'train': gt_train, 'val': gt_val}\n",
    "    data_hash = {'train': hash(dtrain.get_label().tostring()), 'val': hash(dval.get_label().tostring())}\n",
    "    # data_len = {'train': len(dtrain.get_label()), 'val': len(dval.get_label())}\n",
    "\n",
    "    for weight_index in weight_set:\n",
    "        history[weight_index] = {}\n",
    "        model_dict[weight_index] = []\n",
    "\n",
    "        dtrain.set_weight(weight_train.values[:, weight_index])\n",
    "        dval.set_weight(weight_val.values[:, weight_index])\n",
    "        \n",
    "        for n in range(n_repeat):\n",
    "            history[weight_index][n] = {}\n",
    "            \n",
    "            param['seed'] = np.random.randint(10**6)\n",
    "            \n",
    "            time_start = time.time()\n",
    "            print('Train with weight {}, repetition {} of {}'.format(weight_index, n, n_repeat))\n",
    "            model = xgb.train(param, dtrain, num_rounds, evals=[(dtrain, 'train'), (dval, 'val')], \n",
    "                verbose_eval=verbose_eval, feval=eval_map, evals_result=history[weight_index][n], \n",
    "                gt=ground_truth, ts=data_hash)\n",
    "            model_dict[weight_index].append(model)\n",
    "            time_end = time.time()\n",
    "            print('Validate logloss = {:.5f}, MAP@7 = {:.5f}, time = {:.2f} min'.format(\n",
    "                history[weight_index][n]['val']['mlogloss'][-1], \n",
    "                history[weight_index][n]['val']['MAP@7'][-1], (time_end-time_start)/60))\n",
    "            print('-'*50)\n",
    "            print('')\n",
    "        print('')\n",
    "\n",
    "    history = {(w, n, d, m): history[w][n][d][m] \n",
    "               for w in weight_set \n",
    "               for n in range(n_repeat)\n",
    "               for d in ['train', 'val'] \n",
    "               for m in ['mlogloss', 'MAP@7']}\n",
    "    history = pd.DataFrame(history)\n",
    "    history.columns.names = ['weight_index', 'repetition', 'data_set', 'metrics']\n",
    "        \n",
    "    return history, model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_train = '2015-06-28'\n",
    "month_val = '2016-05-28'\n",
    "\n",
    "param = {'objective': 'multi:softprob', \n",
    "         'eta': 0.05, \n",
    "         'max_depth': 8, \n",
    "         'silent': 1, \n",
    "         'num_class': len(target_cols),\n",
    "         'eval_metric': 'mlogloss',\n",
    "         'min_child_weight': 1,\n",
    "         'subsample': 0.7,\n",
    "         'colsample_bytree': 0.7,\n",
    "         'seed': 0,\n",
    "         'booster': 'gbtree', \n",
    "         'rate_drop': 0.1, \n",
    "         'skip_drop': 0.5,\n",
    "         'normalize_type': 'tree', \n",
    "         'sample_type': 'uniform'}\n",
    "num_rounds = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, weight_train = create_train(month_train, pattern_flag=True)\n",
    "x_val, y_val, weight_val = create_train(month_val, pattern_flag=True)\n",
    "\n",
    "gt_train = prep_map1(x_train, y_train)\n",
    "gt_val = prep_map1(x_val, y_val)\n",
    "\n",
    "dtrain = xgb.DMatrix(x_train, y_train)\n",
    "dval = xgb.DMatrix(x_val, y_val)\n",
    "\n",
    "ground_truth = {'train': gt_train, 'val': gt_val}\n",
    "# data_hash = {'train': hash(dtrain.get_label().tostring()), 'val': hash(dval.get_label().tostring())}\n",
    "data_len = {'train': len(dtrain.get_label()), 'val': len(dval.get_label())}\n",
    "\n",
    "weight_index = 0\n",
    "\n",
    "dtrain.set_weight(weight_train.values[:, weight_index])\n",
    "dval.set_weight(weight_val.values[:, weight_index])\n",
    "\n",
    "param['seed'] = np.random.randint(10**6)\n",
    "model = xgb.train(param, dtrain, num_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'train'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-8c9a2a170f2c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_rounds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_map1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'val'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\xgboost-0.72-py3.6.egg\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[0;32m    202\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[0;32m    205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\xgboost-0.72-py3.6.egg\\xgboost\\training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[1;31m# check evaluation result.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m             \u001b[0mbst_eval_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_set\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbst_eval_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSTRING_TYPES\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbst_eval_set\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\xgboost-0.72-py3.6.egg\\xgboost\\core.py\u001b[0m in \u001b[0;36meval_set\u001b[1;34m(self, evals, iteration, feval)\u001b[0m\n\u001b[0;32m    960\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfeval\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    961\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mdmat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mevals\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 962\u001b[1;33m                 \u001b[0mfeval_ret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdmat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdmat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    963\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeval_ret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    964\u001b[0m                     \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfeval_ret\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'train'"
     ]
    }
   ],
   "source": [
    "model = xgb.train(param, dtrain, num_rounds, feval=eval_map1, verbose_eval=True, evals=[(dtrain, 'train'), (dval, 'val')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_prob = model.predict(dtrain)\n",
    "y_val_prob = model.predict(dval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.38330179999997"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeit.timeit('eval_map1(y_train_prob, dtrain, gt=ground_truth, ts=data_hash)', globals=globals(), number=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65.5014271"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeit.timeit('model = xgb.train(param, dtrain, num_rounds)', globals=globals(), number=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64.29673359999992"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeit.timeit('model = xgb.train(param, dtrain, num_rounds, feval=eval_map1)', globals=globals(), number=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
