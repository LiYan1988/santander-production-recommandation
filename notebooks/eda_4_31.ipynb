{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAP\n",
    "\n",
    "Improve MAP evaluation speed\n",
    "10 times run:\n",
    "- 17.7s: original\n",
    "- 18.05s: removes `apks`\n",
    "- 18.01: remove `enumerate`\n",
    "- 17.04: remove `y_prob = {}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from santander_helper import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def apk1(actual, predicted, k=7, default=0.0):\n",
    "    if actual.size==0:\n",
    "        return default\n",
    "    \n",
    "    if predicted.size>k:\n",
    "        predicted = predicted[:k]\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "    \n",
    "    for i,p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "\n",
    "    return score / min(actual.size, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def eval_map1(y_prob, dtrain, gt={}, ts={}):\n",
    "    '''\n",
    "    Evaluate MAP@7 for train and validation sets---\n",
    "    '''\n",
    "    # Check which set is it?\n",
    "    if len(dtrain.get_label())==ts['train']:\n",
    "        glist = gt['train']\n",
    "    elif len(dtrain.get_label())==ts['val']:\n",
    "        glist = gt['val']\n",
    "    \n",
    "    n = len(glist)\n",
    "    score = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        tmp = np.mean(y_prob[glist[i][1], :], axis=0)\n",
    "        tmp = np.argsort(tmp)[:-8:-1]\n",
    "        score[i] = apk1(glist[i][0], tmp)\n",
    "    score = np.mean(score)\n",
    "\n",
    "    return 'MAP@7', score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_map1(x_train, y_train):\n",
    "    '''Prepare ground truth value and index for MAP evaluation, and save it.'''\n",
    "    # Ground truth value: MAP needs to know the products bought by each customers\n",
    "    gtv = pd.concat((pd.DataFrame(x_train.loc[:, 'ncodpers'].copy()), y_train), axis=1, ignore_index=True)\n",
    "    gtv.columns = ['ncodpers', 'target']\n",
    "    gtv = gtv.groupby('ncodpers')['target'].apply(lambda x: x.values).to_dict()\n",
    "    # Ground truth index: MAP needs to know for each customer which rows are its corresponding data\n",
    "    gti = pd.DataFrame(x_train.loc[:, 'ncodpers']).reset_index()\n",
    "    gti = gti.groupby('ncodpers')['index'].apply(lambda x: x.values).to_dict()\n",
    "    \n",
    "    gt = np.array([[gtv[k], gti[k]] for k in gtv.keys()])\n",
    "    \n",
    "    return gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_month1(param, num_rounds, month_train, month_val, n_repeat=2, random_seed=0,\n",
    "                    lag_train=5, lag_val=5, weight_set=(1), verbose_eval=True):\n",
    "    '''Train on one month and validate on another'''\n",
    "    history = {}\n",
    "    model_dict = {}\n",
    "\n",
    "    x_train, y_train, weight_train = create_train(month_train, max_lag=lag_train, pattern_flag=True)\n",
    "    x_val, y_val, weight_val = create_train(month_val, max_lag=lag_val, pattern_flag=True)\n",
    "\n",
    "    gt_train = prep_map(x_train, y_train)\n",
    "    gt_val = prep_map(x_val, y_val)\n",
    "\n",
    "    dtrain = xgb.DMatrix(x_train, y_train)\n",
    "    dval = xgb.DMatrix(x_val, y_val)\n",
    "\n",
    "    ground_truth = {'train': gt_train, 'val': gt_val}\n",
    "    data_hash = {'train': hash(dtrain.get_label().tostring()), 'val': hash(dval.get_label().tostring())}\n",
    "    # data_len = {'train': len(dtrain.get_label()), 'val': len(dval.get_label())}\n",
    "\n",
    "    for weight_index in weight_set:\n",
    "        history[weight_index] = {}\n",
    "        model_dict[weight_index] = []\n",
    "\n",
    "        dtrain.set_weight(weight_train.values[:, weight_index])\n",
    "        dval.set_weight(weight_val.values[:, weight_index])\n",
    "        \n",
    "        for n in range(n_repeat):\n",
    "            history[weight_index][n] = {}\n",
    "            \n",
    "            param['seed'] = np.random.randint(10**6)\n",
    "            \n",
    "            time_start = time.time()\n",
    "            print('Train with weight {}, repetition {} of {}'.format(weight_index, n, n_repeat))\n",
    "            model = xgb.train(param, dtrain, num_rounds, evals=[(dtrain, 'train'), (dval, 'val')], \n",
    "                verbose_eval=verbose_eval, feval=eval_map, evals_result=history[weight_index][n], \n",
    "                gt=ground_truth, ts=data_hash)\n",
    "            model_dict[weight_index].append(model)\n",
    "            time_end = time.time()\n",
    "            print('Validate logloss = {:.5f}, MAP@7 = {:.5f}, time = {:.2f} min'.format(\n",
    "                history[weight_index][n]['val']['mlogloss'][-1], \n",
    "                history[weight_index][n]['val']['MAP@7'][-1], (time_end-time_start)/60))\n",
    "            print('-'*50)\n",
    "            print('')\n",
    "        print('')\n",
    "\n",
    "    history = {(w, n, d, m): history[w][n][d][m] \n",
    "               for w in weight_set \n",
    "               for n in range(n_repeat)\n",
    "               for d in ['train', 'val'] \n",
    "               for m in ['mlogloss', 'MAP@7']}\n",
    "    history = pd.DataFrame(history)\n",
    "    history.columns.names = ['weight_index', 'repetition', 'data_set', 'metrics']\n",
    "        \n",
    "    return history, model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_train = '2015-06-28'\n",
    "month_val = '2016-05-28'\n",
    "\n",
    "param = {'objective': 'multi:softprob', \n",
    "         'eta': 0.05, \n",
    "         'max_depth': 8, \n",
    "         'silent': 1, \n",
    "         'num_class': len(target_cols),\n",
    "         'eval_metric': 'mlogloss',\n",
    "         'min_child_weight': 1,\n",
    "         'subsample': 0.7,\n",
    "         'colsample_bytree': 0.7,\n",
    "         'seed': 0,\n",
    "         'booster': 'gbtree', \n",
    "         'rate_drop': 0.1, \n",
    "         'skip_drop': 0.5,\n",
    "         'normalize_type': 'tree', \n",
    "         'sample_type': 'uniform'}\n",
    "num_rounds = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, weight_train = create_train(month_train, pattern_flag=True)\n",
    "x_val, y_val, weight_val = create_train(month_val, pattern_flag=True)\n",
    "\n",
    "gt_train = prep_map1(x_train, y_train)\n",
    "gt_val = prep_map1(x_val, y_val)\n",
    "\n",
    "dtrain = xgb.DMatrix(x_train, y_train)\n",
    "dval = xgb.DMatrix(x_val, y_val)\n",
    "\n",
    "ground_truth = {'train': gt_train, 'val': gt_val}\n",
    "# data_hash = {'train': hash(dtrain.get_label().tostring()), 'val': hash(dval.get_label().tostring())}\n",
    "data_len = {'train': len(dtrain.get_label()), 'val': len(dval.get_label())}\n",
    "\n",
    "weight_index = 0\n",
    "\n",
    "dtrain.set_weight(weight_train.values[:, weight_index])\n",
    "dval.set_weight(weight_val.values[:, weight_index])\n",
    "\n",
    "param['seed'] = np.random.randint(10**6)\n",
    "#model = xgb.train(param, dtrain, num_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = xgb.train(param, dtrain, num_rounds, feval=eval_map1, verbose_eval=True, evals=[(dtrain, 'train'), (dval, 'val')], \n",
    "#                  gt=ground_truth, ts=data_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_prob = model.predict(dtrain)\n",
    "y_val_prob = model.predict(dval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = np.zeros((y_train.shape[0], len(target_cols)))\n",
    "\n",
    "y_prob[np.arange(len(y_train)), y_train] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('MAP@7', 1.0)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_map1(y_prob, dtrain, gt=ground_truth, ts=data_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.217208700000015"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeit.timeit('eval_map1(y_prob, dtrain, gt=ground_truth, ts=data_len)', globals=globals(), number=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.38330179999997"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeit.timeit('eval_map1(y_prob, dtrain, gt=ground_truth, ts=data_len)', globals=globals(), number=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65.5014271"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeit.timeit('model = xgb.train(param, dtrain, num_rounds)', globals=globals(), number=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64.29673359999992"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeit.timeit('model = xgb.train(param, dtrain, num_rounds, feval=eval_map1)', globals=globals(), number=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
