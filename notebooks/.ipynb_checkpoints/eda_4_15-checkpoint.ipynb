{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering in RAM-Limited Data, Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if os.name=='nt':\n",
    "    try:\n",
    "        mingw_path = 'C:\\\\Program Files\\\\mingw-w64\\\\x86_64-8.1.0-posix-seh-rt_v6-rev0\\\\mingw64\\\\bin'\n",
    "        os.environ['PATH'] = mingw_path + ';' + os.environ['PATH']\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "import gc\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "tqdm.tqdm.pandas()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['ncodpers',\n",
    " 'canal_entrada',\n",
    " 'conyuemp',\n",
    " 'ind_actividad_cliente',\n",
    " 'ind_empleado',\n",
    " 'ind_nuevo',\n",
    " 'indext',\n",
    " 'indfall',\n",
    " 'indrel',\n",
    " 'indrel_1mes',\n",
    " 'indresi',\n",
    " 'pais_residencia',\n",
    " 'segmento',\n",
    " 'sexo',\n",
    " 'tipodom',\n",
    " 'tiprel_1mes',\n",
    " 'age',\n",
    " 'antiguedad',\n",
    " 'renta']\n",
    "\n",
    "target_cols = ['ind_cco_fin_ult1',\n",
    " 'ind_cder_fin_ult1',\n",
    " 'ind_cno_fin_ult1',\n",
    " 'ind_ctju_fin_ult1',\n",
    " 'ind_ctma_fin_ult1',\n",
    " 'ind_ctop_fin_ult1',\n",
    " 'ind_ctpp_fin_ult1',\n",
    " #'ind_deco_fin_ult1',\n",
    " 'ind_dela_fin_ult1',\n",
    " #'ind_deme_fin_ult1',\n",
    " 'ind_ecue_fin_ult1',\n",
    " 'ind_fond_fin_ult1',\n",
    " 'ind_hip_fin_ult1',\n",
    " 'ind_nom_pens_ult1',\n",
    " 'ind_nomina_ult1',\n",
    " 'ind_plan_fin_ult1',\n",
    " 'ind_pres_fin_ult1',\n",
    " 'ind_reca_fin_ult1',\n",
    " 'ind_recibo_ult1',\n",
    " 'ind_tjcr_fin_ult1',\n",
    " 'ind_valo_fin_ult1']\n",
    " #'ind_viv_fin_ult1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test(month1, month2, target_flag=True):\n",
    "    '''Create train and test data between month1 and month2'''\n",
    "    \n",
    "    # first/early month\n",
    "    df1 = pd.read_hdf('../input/data_month_{}.hdf'.format(month1), 'data_month')\n",
    "    # second/later month\n",
    "    df2 = pd.read_hdf('../input/data_month_{}.hdf'.format(month2), 'data_month')\n",
    "    \n",
    "    # second month products\n",
    "    df2_target = df2.loc[:, ['ncodpers']+target_cols].copy()\n",
    "    df2_target.set_index('ncodpers', inplace=True, drop=False) # initially keep ncodpers as a column and drop it later\n",
    "    # a dataframe containing the ncodpers only\n",
    "    df2_ncodpers = pd.DataFrame(df2_target.ncodpers)\n",
    "    # drop ncodpers from df2_target\n",
    "    df2_target.drop('ncodpers', axis=1, inplace=True)\n",
    "    \n",
    "    # first month products for all the customers in the second month\n",
    "    df1_target = df1.loc[:, ['ncodpers']+target_cols].copy()\n",
    "    df1_target.set_index('ncodpers', inplace=True, drop=True) # do not keep ncodpers as column\n",
    "    # obtain the products purchased by all the customers in the second month\n",
    "    # by joining df1_target to df2_ncodpers, NAN filled by 0.0\n",
    "    df1_target = df2_ncodpers.join(df1_target, how='left')\n",
    "    df1_target.fillna(0.0, inplace=True)\n",
    "    df1_target.drop('ncodpers', axis=1, inplace=True)\n",
    "    \n",
    "    # new products from the first to second month\n",
    "    target = df2_target.subtract(df1_target)\n",
    "    target[target<0] = 0\n",
    "    target.fillna(0.0, inplace=True)\n",
    "    \n",
    "    # feature of the second month: \n",
    "    # 1. customer features in the second month\n",
    "    # 2. products in the first month\n",
    "    x_vars = df2[cat_cols].copy() # cat_cols already includes ncodpers\n",
    "    x_vars.reset_index(inplace=True, drop=True) # drop original index and make a new one\n",
    "    x_vars.reset_index(inplace=True, drop=False) # also set the new index as a column for recoding row orders\n",
    "    x_vars_cols = x_vars.columns.tolist()\n",
    "    x_vars_cols[0] = 'sample_order' # change the name of the new column\n",
    "    x_vars.columns = x_vars_cols\n",
    "    x_vars.set_index('ncodpers', drop=True, inplace=True) # set the index to ncodpers again\n",
    "    x_vars = x_vars.join(df1_target) # direct join since df1_target contains all customers in month2\n",
    "    \n",
    "    # concatenate this and previous month values of ind_activadad_cliente\n",
    "    df2_ind_actividad_cliente = df2[['ncodpers', 'ind_actividad_cliente']].copy()\n",
    "    df2_ind_actividad_cliente.set_index('ncodpers', inplace=True)\n",
    "    df2_ind_actividad_cliente.sort_index(inplace=True)\n",
    "    \n",
    "    df1_ind_actividad_cliente = df1[['ncodpers', 'ind_actividad_cliente']].copy()\n",
    "    df1_ind_actividad_cliente.set_index('ncodpers', inplace=True)\n",
    "    df1_ind_actividad_cliente.sort_index(inplace=True)\n",
    "\n",
    "    df2_ind_actividad_cliente = df2_ind_actividad_cliente.join(df1_ind_actividad_cliente, rsuffix='_p')\n",
    "    df2_ind_actividad_cliente.fillna(2.0, inplace=True)\n",
    "    df2_ind_actividad_cliente['ind_actividad_client_combine'] = 3*df2_ind_actividad_cliente.ind_actividad_cliente+df2_ind_actividad_cliente.ind_actividad_cliente_p\n",
    "    df2_ind_actividad_cliente = pd.DataFrame(df2_ind_actividad_cliente.iloc[:, -1])\n",
    "\n",
    "    x_vars = pd.merge(x_vars, df2_ind_actividad_cliente, left_index=True, right_index=True, how='left')\n",
    "    \n",
    "    # concatenate this and previous month value of tiprel_1mes\n",
    "    df2_tiprel_1mes = df2[['ncodpers', 'tiprel_1mes']].copy()\n",
    "    df2_tiprel_1mes.set_index('ncodpers', inplace=True)\n",
    "    df2_tiprel_1mes.sort_index(inplace=True)\n",
    "\n",
    "    df1_tiprel_1mes = df1[['ncodpers', 'tiprel_1mes']].copy()\n",
    "    df1_tiprel_1mes.set_index('ncodpers', inplace=True)\n",
    "    df1_tiprel_1mes.sort_index(inplace=True)\n",
    "\n",
    "    df2_tiprel_1mes = df2_tiprel_1mes.join(df1_tiprel_1mes, rsuffix='_p')\n",
    "    df2_tiprel_1mes.fillna(0.0, inplace=True)\n",
    "    df2_tiprel_1mes['tiprel_1mes_combine'] = 6*df2_tiprel_1mes.tiprel_1mes+df2_tiprel_1mes.tiprel_1mes_p\n",
    "    df2_tiprel_1mes = pd.DataFrame(df2_tiprel_1mes.iloc[:, -1])\n",
    "\n",
    "    x_vars = pd.merge(x_vars, df2_tiprel_1mes, left_index=True, right_index=True, how='left')\n",
    "    \n",
    "    # combination of target columns\n",
    "    x_vars['target_combine'] = np.sum(x_vars[target_cols].values*\n",
    "        np.float_power(2, np.arange(-10, len(target_cols)-10)), axis=1, dtype=np.float64)\n",
    "    \n",
    "    # return x_vars, df2_ncodpers, df1, df2, df1_target, df2_target\n",
    "    \n",
    "    # return x_vars if target_flag is False\n",
    "    if not target_flag:\n",
    "        x_vars.drop('sample_order', axis=1, inplace=True) # drop sample_order\n",
    "        x_vars.reset_index(inplace=True, drop=False) # add ncodpers\n",
    "        return x_vars #, df2_ncodpers, df1, df2, df1_target, df2_target\n",
    "    \n",
    "    if target_flag:    \n",
    "        # prepare target/label for each added product from the first to second month\n",
    "        # join target to x_vars\n",
    "        x_vars_new = x_vars.join(target, rsuffix='_t')\n",
    "        # set ncodpers as one column\n",
    "        x_vars_new.reset_index(inplace=True, drop=False)\n",
    "        x_vars.reset_index(inplace=True, drop=False)\n",
    "\n",
    "        # melt\n",
    "        x_vars_new = x_vars_new.melt(id_vars=x_vars.columns)\n",
    "        # mapping from target_cols to index\n",
    "        target_cols_mapping = {c+'_t': n for (n, c) in enumerate(target_cols)}\n",
    "        # replace column name by index\n",
    "        x_vars_new.variable.replace(target_cols_mapping, inplace=True)\n",
    "        # reorder rows\n",
    "        x_vars_new.sort_values(['sample_order', 'variable'], inplace=True)\n",
    "        # keep new products\n",
    "        x_vars_new = x_vars_new[x_vars_new.value>0]\n",
    "        # drop sample_order and value\n",
    "        x_vars_new.drop(['sample_order', 'value'], axis=1, inplace=True)\n",
    "        # keep the order of rows as in the original data set\n",
    "        x_vars_new.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        var_cols = x_vars.columns.tolist()\n",
    "        var_cols.remove('sample_order')\n",
    "        # variable\n",
    "        x_vars = x_vars_new.loc[:, var_cols].copy()\n",
    "        # target/label\n",
    "        target = x_vars_new.loc[:, 'variable'].copy()\n",
    "\n",
    "        return x_vars, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = create_train_test('2015-05-28', '2015-06-28', target_flag=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val, y_val = create_train_test('2015-11-28', '2015-12-28', target_flag=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combination of target cols\n",
    "\n",
    "generate a value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vars['target_combine'] = np.sum(x_vars[target_cols].values*np.float_power(2, np.arange(-10, len(target_cols)-10)), axis=1, dtype=np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combination of target cols, generate a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = x_vars[target_cols].values.astype(int)\n",
    "n = [np.array_str(n[k]).strip('[]').replace(' ', '') for k in range(n.shape[0])]\n",
    "x_vars['target_str'] = n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ind_actividad_cliente, this and previous months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_ind_actividad_cliente = df2[['ncodpers', 'ind_actividad_cliente']].copy()\n",
    "df2_ind_actividad_cliente.set_index('ncodpers', inplace=True)\n",
    "df2_ind_actividad_cliente.sort_index(inplace=True)\n",
    "\n",
    "df1_ind_actividad_cliente = df1[['ncodpers', 'ind_actividad_cliente']].copy()\n",
    "df1_ind_actividad_cliente.set_index('ncodpers', inplace=True)\n",
    "df1_ind_actividad_cliente.sort_index(inplace=True)\n",
    "\n",
    "df2_ind_actividad_cliente = df2_ind_actividad_cliente.join(df1_ind_actividad_cliente, rsuffix='_p')\n",
    "df2_ind_actividad_cliente.fillna(2.0, inplace=True)\n",
    "df2_ind_actividad_cliente['ind_actividad_client_combine'] = 3*df2_ind_actividad_cliente.ind_actividad_cliente+df2_ind_actividad_cliente.ind_actividad_cliente_p\n",
    "df2_ind_actividad_cliente = pd.DataFrame(df2_ind_actividad_cliente.iloc[:, -1])\n",
    "\n",
    "x_train = pd.merge(x_train, df2_ind_actividad_cliente, left_index=True, right_index=True, how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tiprel_1mes, this and previous months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_tiprel_1mes = df2[['ncodpers', 'tiprel_1mes']].copy()\n",
    "df2_tiprel_1mes.set_index('ncodpers', inplace=True)\n",
    "df2_tiprel_1mes.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_tiprel_1mes = df2[['ncodpers', 'tiprel_1mes']].copy()\n",
    "df2_tiprel_1mes.set_index('ncodpers', inplace=True)\n",
    "df2_tiprel_1mes.sort_index(inplace=True)\n",
    "\n",
    "df1_tiprel_1mes = df1[['ncodpers', 'tiprel_1mes']].copy()\n",
    "df1_tiprel_1mes.set_index('ncodpers', inplace=True)\n",
    "df1_tiprel_1mes.sort_index(inplace=True)\n",
    "\n",
    "df2_tiprel_1mes = df2_tiprel_1mes.join(df1_tiprel_1mes, rsuffix='_p')\n",
    "df2_tiprel_1mes.fillna(0.0, inplace=True)\n",
    "df2_tiprel_1mes['tiprel_1mes_combine'] = 6*df2_tiprel_1mes.tiprel_1mes+df2_tiprel_1mes.tiprel_1mes_p\n",
    "df2_tiprel_1mes = pd.DataFrame(df2_tiprel_1mes.iloc[:, -1])\n",
    "\n",
    "x_train = pd.merge(x_train, df2_tiprel_1mes, left_index=True, right_index=True, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_val, y_val = create_train_test('2015-11-28', '2015-12-28', target_flag=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_test = create_train_test('2016-05-28', '2016-06-28', target_flag=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "param = {'objective': 'multi:softprob', \n",
    "         'eta': 0.05, \n",
    "         'max_depth': 8, \n",
    "         'silent': 1, \n",
    "         'num_class': len(target_cols),\n",
    "         'eval_metric': 'mlogloss',\n",
    "         'min_child_weight': 1,\n",
    "         'subsample': 0.7,\n",
    "         'colsample_bytree': 0.7,\n",
    "         'seed': 0}\n",
    "num_rounds =ยง 50\n",
    "\n",
    "dtrain = xgb.DMatrix(x_train.values, y_train.values)\n",
    "dval = xgb.DMatrix(x_val.values, y_val.values)\n",
    "model = xgb.train(param, dtrain, num_rounds, evals=[(dtrain, 'train'), (dval, 'val')], verbose_eval=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction from my model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(xgb.DMatrix(x_test.values))\n",
    "\n",
    "df_preds = pd.DataFrame(preds, index=x_test.index, columns=target_cols)\n",
    "df_preds[x_test[target_cols]==1] = 0\n",
    "preds = df_preds.values\n",
    "preds = np.argsort(preds, axis=1)\n",
    "preds = np.fliplr(preds)[:, :7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write out prediction results from my model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = x_test.loc[:, 'ncodpers'].values\n",
    "final_preds = [' '.join([target_cols[k] for k in pred]) for pred in preds]\n",
    "\n",
    "out_df = pd.DataFrame({'ncodpers': test_id, 'added_products': final_preds})\n",
    "out_df.to_csv('eda_4_15.csv.gz', compression='gzip', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
