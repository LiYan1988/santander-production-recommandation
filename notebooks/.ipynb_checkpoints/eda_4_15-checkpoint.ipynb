{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering in RAM-Limited Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if os.name=='nt':\n",
    "    try:\n",
    "        mingw_path = 'C:\\\\Program Files\\\\mingw-w64\\\\x86_64-8.1.0-posix-seh-rt_v6-rev0\\\\mingw64\\\\bin'\n",
    "        os.environ['PATH'] = mingw_path + ';' + os.environ['PATH']\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "import gc\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "tqdm.tqdm.pandas()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['ncodpers',\n",
    " 'canal_entrada',\n",
    " 'conyuemp',\n",
    " 'ind_actividad_cliente',\n",
    " 'ind_empleado',\n",
    " 'ind_nuevo',\n",
    " 'indext',\n",
    " 'indfall',\n",
    " 'indrel',\n",
    " 'indrel_1mes',\n",
    " 'indresi',\n",
    " 'pais_residencia',\n",
    " 'segmento',\n",
    " 'sexo',\n",
    " 'tipodom',\n",
    " 'tiprel_1mes',\n",
    " 'age',\n",
    " 'antiguedad',\n",
    " 'renta']\n",
    "\n",
    "target_cols = ['ind_cco_fin_ult1',\n",
    " 'ind_cder_fin_ult1',\n",
    " 'ind_cno_fin_ult1',\n",
    " 'ind_ctju_fin_ult1',\n",
    " 'ind_ctma_fin_ult1',\n",
    " 'ind_ctop_fin_ult1',\n",
    " 'ind_ctpp_fin_ult1',\n",
    " #'ind_deco_fin_ult1',\n",
    " 'ind_dela_fin_ult1',\n",
    " #'ind_deme_fin_ult1',\n",
    " 'ind_ecue_fin_ult1',\n",
    " 'ind_fond_fin_ult1',\n",
    " 'ind_hip_fin_ult1',\n",
    " 'ind_nom_pens_ult1',\n",
    " 'ind_nomina_ult1',\n",
    " 'ind_plan_fin_ult1',\n",
    " 'ind_pres_fin_ult1',\n",
    " 'ind_reca_fin_ult1',\n",
    " 'ind_recibo_ult1',\n",
    " 'ind_tjcr_fin_ult1',\n",
    " 'ind_valo_fin_ult1']\n",
    " #'ind_viv_fin_ult1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test(month1, month2, target_flag=True):\n",
    "    '''Create train and test data between month1 and month2'''\n",
    "    \n",
    "    # first/early month\n",
    "    df1 = pd.read_hdf('../input/data_month_{}.hdf'.format(month1), 'data_month')\n",
    "    # second/later month\n",
    "    df2 = pd.read_hdf('../input/data_month_{}.hdf'.format(month2), 'data_month')\n",
    "    \n",
    "    # second month products\n",
    "    df2_target = df2.loc[:, ['ncodpers']+target_cols].copy()\n",
    "    df2_target.set_index('ncodpers', inplace=True, drop=False) # initially keep ncodpers as a column and drop it later\n",
    "    # a dataframe containing the ncodpers only\n",
    "    df2_ncodpers = pd.DataFrame(df2_target.ncodpers)\n",
    "    # drop ncodpers from df2_target\n",
    "    df2_target.drop('ncodpers', axis=1, inplace=True)\n",
    "    \n",
    "    # first month products for all the customers in the second month\n",
    "    df1_target = df1.loc[:, ['ncodpers']+target_cols].copy()\n",
    "    df1_target.set_index('ncodpers', inplace=True, drop=True) # do not keep ncodpers as column\n",
    "    # obtain the products purchased by all the customers in the second month\n",
    "    # by joining df1_target to df2_ncodpers, NAN filled by 0.0\n",
    "    df1_target = df2_ncodpers.join(df1_target, how='left')\n",
    "    df1_target.fillna(0.0, inplace=True)\n",
    "    df1_target.drop('ncodpers', axis=1, inplace=True)\n",
    "    \n",
    "    # new products from the first to second month\n",
    "    target = df2_target.subtract(df1_target)\n",
    "    target[target<0] = 0\n",
    "    target.fillna(0.0, inplace=True)\n",
    "    \n",
    "    # feature of the second month: \n",
    "    # 1. customer features in the second month\n",
    "    # 2. products in the first month\n",
    "    x_vars = df2[cat_cols].copy() # cat_cols already includes ncodpers\n",
    "    x_vars.reset_index(inplace=True, drop=True) # drop original index and make a new one\n",
    "    x_vars.reset_index(inplace=True, drop=False) # also set the new index as a column for recoding row orders\n",
    "    x_vars_cols = x_vars.columns.tolist()\n",
    "    x_vars_cols[0] = 'sample_order' # change the name of the new column\n",
    "    x_vars.columns = x_vars_cols\n",
    "    x_vars.set_index('ncodpers', drop=True, inplace=True) # set the index to ncodpers again\n",
    "    x_vars = x_vars.join(df1_target) # direct join since df1_target contains all customers in month2\n",
    "    \n",
    "    # concatenate this and previous month values of ind_activadad_cliente\n",
    "    df2_ind_actividad_cliente = df2[['ncodpers', 'ind_actividad_cliente']].copy()\n",
    "    df2_ind_actividad_cliente.set_index('ncodpers', inplace=True)\n",
    "    df2_ind_actividad_cliente.sort_index(inplace=True)\n",
    "    \n",
    "    df1_ind_actividad_cliente = df1[['ncodpers', 'ind_actividad_cliente']].copy()\n",
    "    df1_ind_actividad_cliente.set_index('ncodpers', inplace=True)\n",
    "    df1_ind_actividad_cliente.sort_index(inplace=True)\n",
    "\n",
    "    df2_ind_actividad_cliente = df2_ind_actividad_cliente.join(df1_ind_actividad_cliente, rsuffix='_p')\n",
    "    df2_ind_actividad_cliente.fillna(2.0, inplace=True)\n",
    "    df2_ind_actividad_cliente['ind_actividad_client_combine'] = 3*df2_ind_actividad_cliente.ind_actividad_cliente+df2_ind_actividad_cliente.ind_actividad_cliente_p\n",
    "    df2_ind_actividad_cliente = pd.DataFrame(df2_ind_actividad_cliente.iloc[:, -1])\n",
    "\n",
    "    x_vars = pd.merge(x_vars, df2_ind_actividad_cliente, left_index=True, right_index=True, how='left')\n",
    "    \n",
    "    # concatenate this and previous month value of tiprel_1mes\n",
    "    df2_tiprel_1mes = df2[['ncodpers', 'tiprel_1mes']].copy()\n",
    "    df2_tiprel_1mes.set_index('ncodpers', inplace=True)\n",
    "    df2_tiprel_1mes.sort_index(inplace=True)\n",
    "\n",
    "    df1_tiprel_1mes = df1[['ncodpers', 'tiprel_1mes']].copy()\n",
    "    df1_tiprel_1mes.set_index('ncodpers', inplace=True)\n",
    "    df1_tiprel_1mes.sort_index(inplace=True)\n",
    "\n",
    "    df2_tiprel_1mes = df2_tiprel_1mes.join(df1_tiprel_1mes, rsuffix='_p')\n",
    "    df2_tiprel_1mes.fillna(0.0, inplace=True)\n",
    "    df2_tiprel_1mes['tiprel_1mes_combine'] = 6*df2_tiprel_1mes.tiprel_1mes+df2_tiprel_1mes.tiprel_1mes_p\n",
    "    df2_tiprel_1mes = pd.DataFrame(df2_tiprel_1mes.iloc[:, -1])\n",
    "\n",
    "    x_vars = pd.merge(x_vars, df2_tiprel_1mes, left_index=True, right_index=True, how='left')\n",
    "    \n",
    "    # combination of target columns\n",
    "    x_vars['target_combine'] = np.sum(x_vars[target_cols].values*\n",
    "        np.float_power(2, np.arange(-10, len(target_cols)-10)), axis=1, dtype=np.float64)\n",
    "    \n",
    "    # return x_vars, df2_ncodpers, df1, df2, df1_target, df2_target\n",
    "    \n",
    "    # return x_vars if target_flag is False\n",
    "    if not target_flag:\n",
    "        x_vars.drop('sample_order', axis=1, inplace=True) # drop sample_order\n",
    "        x_vars.reset_index(inplace=True, drop=False) # add ncodpers\n",
    "        return x_vars #, df2_ncodpers, df1, df2, df1_target, df2_target\n",
    "    \n",
    "    if target_flag:    \n",
    "        # prepare target/label for each added product from the first to second month\n",
    "        # join target to x_vars\n",
    "        x_vars_new = x_vars.join(target, rsuffix='_t')\n",
    "        # set ncodpers as one column\n",
    "        x_vars_new.reset_index(inplace=True, drop=False)\n",
    "        x_vars.reset_index(inplace=True, drop=False)\n",
    "\n",
    "        # melt\n",
    "        x_vars_new = x_vars_new.melt(id_vars=x_vars.columns)\n",
    "        # mapping from target_cols to index\n",
    "        target_cols_mapping = {c+'_t': n for (n, c) in enumerate(target_cols)}\n",
    "        # replace column name by index\n",
    "        x_vars_new.variable.replace(target_cols_mapping, inplace=True)\n",
    "        # reorder rows\n",
    "        x_vars_new.sort_values(['sample_order', 'variable'], inplace=True)\n",
    "        # keep new products\n",
    "        x_vars_new = x_vars_new[x_vars_new.value>0]\n",
    "        # drop sample_order and value\n",
    "        x_vars_new.drop(['sample_order', 'value'], axis=1, inplace=True)\n",
    "        # keep the order of rows as in the original data set\n",
    "        x_vars_new.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        var_cols = x_vars.columns.tolist()\n",
    "        var_cols.remove('sample_order')\n",
    "        # variable\n",
    "        x_vars = x_vars_new.loc[:, var_cols].copy()\n",
    "        # target/label\n",
    "        target = x_vars_new.loc[:, 'variable'].copy()\n",
    "\n",
    "        return x_vars, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = create_train_test('2015-05-28', '2015-06-28', target_flag=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val, y_val = create_train_test('2015-11-28', '2015-12-28', target_flag=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combination of target cols, generate a value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vars['target_combine'] = np.sum(x_vars[target_cols].values*np.float_power(2, np.arange(-10, len(target_cols)-10)), axis=1, dtype=np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combination of target cols, generate a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = x_vars[target_cols].values.astype(int)\n",
    "n = [np.array_str(n[k]).strip('[]').replace(' ', '') for k in range(n.shape[0])]\n",
    "x_vars['target_str'] = n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ind_actividad_cliente, this and previous months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_ind_actividad_cliente = df2[['ncodpers', 'ind_actividad_cliente']].copy()\n",
    "df2_ind_actividad_cliente.set_index('ncodpers', inplace=True)\n",
    "df2_ind_actividad_cliente.sort_index(inplace=True)\n",
    "\n",
    "df1_ind_actividad_cliente = df1[['ncodpers', 'ind_actividad_cliente']].copy()\n",
    "df1_ind_actividad_cliente.set_index('ncodpers', inplace=True)\n",
    "df1_ind_actividad_cliente.sort_index(inplace=True)\n",
    "\n",
    "df2_ind_actividad_cliente = df2_ind_actividad_cliente.join(df1_ind_actividad_cliente, rsuffix='_p')\n",
    "df2_ind_actividad_cliente.fillna(2.0, inplace=True)\n",
    "df2_ind_actividad_cliente['ind_actividad_client_combine'] = 3*df2_ind_actividad_cliente.ind_actividad_cliente+df2_ind_actividad_cliente.ind_actividad_cliente_p\n",
    "df2_ind_actividad_cliente = pd.DataFrame(df2_ind_actividad_cliente.iloc[:, -1])\n",
    "\n",
    "x_train = pd.merge(x_train, df2_ind_actividad_cliente, left_index=True, right_index=True, how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tiprel_1mes, this and previous months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_tiprel_1mes = df2[['ncodpers', 'tiprel_1mes']].copy()\n",
    "df2_tiprel_1mes.set_index('ncodpers', inplace=True)\n",
    "df2_tiprel_1mes.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_tiprel_1mes = df2[['ncodpers', 'tiprel_1mes']].copy()\n",
    "df2_tiprel_1mes.set_index('ncodpers', inplace=True)\n",
    "df2_tiprel_1mes.sort_index(inplace=True)\n",
    "\n",
    "df1_tiprel_1mes = df1[['ncodpers', 'tiprel_1mes']].copy()\n",
    "df1_tiprel_1mes.set_index('ncodpers', inplace=True)\n",
    "df1_tiprel_1mes.sort_index(inplace=True)\n",
    "\n",
    "df2_tiprel_1mes = df2_tiprel_1mes.join(df1_tiprel_1mes, rsuffix='_p')\n",
    "df2_tiprel_1mes.fillna(0.0, inplace=True)\n",
    "df2_tiprel_1mes['tiprel_1mes_combine'] = 6*df2_tiprel_1mes.tiprel_1mes+df2_tiprel_1mes.tiprel_1mes_p\n",
    "df2_tiprel_1mes = pd.DataFrame(df2_tiprel_1mes.iloc[:, -1])\n",
    "\n",
    "x_train = pd.merge(x_train, df2_tiprel_1mes, left_index=True, right_index=True, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_val, y_val = create_train_test('2015-11-28', '2015-12-28', target_flag=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_test = create_train_test('2016-05-28', '2016-06-28', target_flag=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:2.91645\tval-mlogloss:2.93945\n",
      "[1]\ttrain-mlogloss:2.78563\tval-mlogloss:2.82684\n",
      "[2]\ttrain-mlogloss:2.6751\tval-mlogloss:2.72827\n",
      "[3]\ttrain-mlogloss:2.58366\tval-mlogloss:2.65113\n",
      "[4]\ttrain-mlogloss:2.49453\tval-mlogloss:2.57273\n",
      "[5]\ttrain-mlogloss:2.41242\tval-mlogloss:2.50677\n",
      "[6]\ttrain-mlogloss:2.34612\tval-mlogloss:2.4467\n",
      "[7]\ttrain-mlogloss:2.28669\tval-mlogloss:2.39776\n",
      "[8]\ttrain-mlogloss:2.22937\tval-mlogloss:2.35122\n",
      "[9]\ttrain-mlogloss:2.17384\tval-mlogloss:2.29996\n",
      "[10]\ttrain-mlogloss:2.12307\tval-mlogloss:2.25661\n",
      "[11]\ttrain-mlogloss:2.08031\tval-mlogloss:2.21912\n",
      "[12]\ttrain-mlogloss:2.04\tval-mlogloss:2.18456\n",
      "[13]\ttrain-mlogloss:1.99893\tval-mlogloss:2.15046\n",
      "[14]\ttrain-mlogloss:1.95945\tval-mlogloss:2.11762\n",
      "[15]\ttrain-mlogloss:1.92307\tval-mlogloss:2.08713\n",
      "[16]\ttrain-mlogloss:1.88998\tval-mlogloss:2.06008\n",
      "[17]\ttrain-mlogloss:1.85772\tval-mlogloss:2.03347\n",
      "[18]\ttrain-mlogloss:1.82859\tval-mlogloss:2.00913\n",
      "[19]\ttrain-mlogloss:1.80279\tval-mlogloss:1.98838\n",
      "[20]\ttrain-mlogloss:1.77791\tval-mlogloss:1.96712\n",
      "[21]\ttrain-mlogloss:1.75428\tval-mlogloss:1.94514\n",
      "[22]\ttrain-mlogloss:1.72977\tval-mlogloss:1.92619\n",
      "[23]\ttrain-mlogloss:1.70668\tval-mlogloss:1.9072\n",
      "[24]\ttrain-mlogloss:1.68579\tval-mlogloss:1.88961\n",
      "[25]\ttrain-mlogloss:1.66468\tval-mlogloss:1.87427\n",
      "[26]\ttrain-mlogloss:1.6446\tval-mlogloss:1.85773\n",
      "[27]\ttrain-mlogloss:1.62652\tval-mlogloss:1.84262\n",
      "[28]\ttrain-mlogloss:1.61053\tval-mlogloss:1.8309\n",
      "[29]\ttrain-mlogloss:1.59396\tval-mlogloss:1.81752\n",
      "[30]\ttrain-mlogloss:1.57689\tval-mlogloss:1.80325\n",
      "[31]\ttrain-mlogloss:1.56132\tval-mlogloss:1.79009\n",
      "[32]\ttrain-mlogloss:1.54642\tval-mlogloss:1.77782\n",
      "[33]\ttrain-mlogloss:1.5324\tval-mlogloss:1.76676\n",
      "[34]\ttrain-mlogloss:1.5179\tval-mlogloss:1.75652\n",
      "[35]\ttrain-mlogloss:1.5043\tval-mlogloss:1.7453\n",
      "[36]\ttrain-mlogloss:1.49227\tval-mlogloss:1.7348\n",
      "[37]\ttrain-mlogloss:1.48045\tval-mlogloss:1.72487\n",
      "[38]\ttrain-mlogloss:1.46843\tval-mlogloss:1.71476\n",
      "[39]\ttrain-mlogloss:1.45647\tval-mlogloss:1.70455\n",
      "[40]\ttrain-mlogloss:1.44583\tval-mlogloss:1.69617\n",
      "[41]\ttrain-mlogloss:1.43534\tval-mlogloss:1.68847\n",
      "[42]\ttrain-mlogloss:1.42487\tval-mlogloss:1.67937\n",
      "[43]\ttrain-mlogloss:1.4151\tval-mlogloss:1.67082\n",
      "[44]\ttrain-mlogloss:1.40488\tval-mlogloss:1.66243\n",
      "[45]\ttrain-mlogloss:1.39618\tval-mlogloss:1.65533\n",
      "[46]\ttrain-mlogloss:1.38665\tval-mlogloss:1.64806\n",
      "[47]\ttrain-mlogloss:1.37767\tval-mlogloss:1.64064\n",
      "[48]\ttrain-mlogloss:1.36934\tval-mlogloss:1.63402\n",
      "[49]\ttrain-mlogloss:1.36178\tval-mlogloss:1.62857\n"
     ]
    }
   ],
   "source": [
    "param = {'objective': 'multi:softprob', \n",
    "         'eta': 0.05, \n",
    "         'max_depth': 8, \n",
    "         'silent': 1, \n",
    "         'num_class': len(target_cols),\n",
    "         'eval_metric': 'mlogloss',\n",
    "         'min_child_weight': 1,\n",
    "         'subsample': 0.7,\n",
    "         'colsample_bytree': 0.7,\n",
    "         'seed': 0}\n",
    "num_rounds = 50\n",
    "\n",
    "dtrain = xgb.DMatrix(x_train.values, y_train.values)\n",
    "dval = xgb.DMatrix(x_val.values, y_val.values)\n",
    "model = xgb.train(param, dtrain, num_rounds, evals=[(dtrain, 'train'), (dval, 'val')], verbose_eval=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction from my model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(xgb.DMatrix(x_test.values))\n",
    "\n",
    "df_preds = pd.DataFrame(preds, index=x_test.index, columns=target_cols)\n",
    "df_preds[x_test[target_cols]==1] = 0\n",
    "preds = df_preds.values\n",
    "preds = np.argsort(preds, axis=1)\n",
    "preds = np.fliplr(preds)[:, :7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write out prediction results from my model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = x_test.loc[:, 'ncodpers'].values\n",
    "final_preds = [' '.join([target_cols[k] for k in pred]) for pred in preds]\n",
    "\n",
    "out_df = pd.DataFrame({'ncodpers': test_id, 'added_products': final_preds})\n",
    "out_df.to_csv('eda_4_15.csv.gz', compression='gzip', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
