{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation with RAM-Limited Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if os.name=='nt':\n",
    "    try:\n",
    "        mingw_path = 'C:\\\\Program Files\\\\mingw-w64\\\\x86_64-8.1.0-posix-seh-rt_v6-rev0\\\\mingw64\\\\bin'\n",
    "        os.environ['PATH'] = mingw_path + ';' + os.environ['PATH']\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "import gc\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "tqdm.tqdm.pandas()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['ncodpers',\n",
    " 'canal_entrada',\n",
    " 'conyuemp',\n",
    " 'ind_actividad_cliente',\n",
    " 'ind_empleado',\n",
    " 'ind_nuevo',\n",
    " 'indext',\n",
    " 'indfall',\n",
    " 'indrel',\n",
    " 'indrel_1mes',\n",
    " 'indresi',\n",
    " 'pais_residencia',\n",
    " 'segmento',\n",
    " 'sexo',\n",
    " 'tipodom',\n",
    " 'tiprel_1mes',\n",
    " 'age',\n",
    " 'antiguedad',\n",
    " 'renta']\n",
    "\n",
    "target_cols = ['ind_cco_fin_ult1',\n",
    " 'ind_cder_fin_ult1',\n",
    " 'ind_cno_fin_ult1',\n",
    " 'ind_ctju_fin_ult1',\n",
    " 'ind_ctma_fin_ult1',\n",
    " 'ind_ctop_fin_ult1',\n",
    " 'ind_ctpp_fin_ult1',\n",
    " 'ind_deco_fin_ult1',\n",
    " 'ind_dela_fin_ult1',\n",
    " 'ind_deme_fin_ult1',\n",
    " 'ind_ecue_fin_ult1',\n",
    " 'ind_fond_fin_ult1',\n",
    " 'ind_hip_fin_ult1',\n",
    " 'ind_nom_pens_ult1',\n",
    " 'ind_nomina_ult1',\n",
    " 'ind_plan_fin_ult1',\n",
    " 'ind_pres_fin_ult1',\n",
    " 'ind_reca_fin_ult1',\n",
    " 'ind_recibo_ult1',\n",
    " 'ind_tjcr_fin_ult1',\n",
    " 'ind_valo_fin_ult1',\n",
    " 'ind_viv_fin_ult1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test(month1, month2, target_flag=True):\n",
    "    '''Create train and test data between month1 and month2'''\n",
    "    \n",
    "    # first/early month\n",
    "    df1 = pd.read_hdf('../input/data_month_{}.hdf'.format(month1), 'data_month')\n",
    "    # second/later month\n",
    "    df2 = pd.read_hdf('../input/data_month_{}.hdf'.format(month2), 'data_month')\n",
    "    \n",
    "    # second month products\n",
    "    df2_target = df2.loc[:, ['ncodpers']+target_cols].copy()\n",
    "    df2_target.set_index('ncodpers', inplace=True, drop=False) # initially keep ncodpers as a column and drop it later\n",
    "    # a dataframe containing the ncodpers only\n",
    "    df2_ncodpers = pd.DataFrame(df2_target.ncodpers)\n",
    "    # drop ncodpers from df2_target\n",
    "    df2_target.drop('ncodpers', axis=1, inplace=True)\n",
    "    \n",
    "    # first month products for all the customers in the second month\n",
    "    df1_target = df1.loc[:, ['ncodpers']+target_cols].copy()\n",
    "    df1_target.set_index('ncodpers', inplace=True, drop=True) # do not keep ncodpers as column\n",
    "    # obtain the products purchased by all the customers in the second month\n",
    "    # by joining df1_target to df2_ncodpers, NAN filled by 0.0\n",
    "    df1_target = df2_ncodpers.join(df1_target, how='left')\n",
    "    df1_target.fillna(0.0, inplace=True)\n",
    "    df1_target.drop('ncodpers', axis=1, inplace=True)\n",
    "    \n",
    "    # new products from the first to second month\n",
    "    target = df2_target.subtract(df1_target)\n",
    "    target[target<0] = 0\n",
    "    target.fillna(0.0, inplace=True)\n",
    "    \n",
    "    # feature of the second month: \n",
    "    # 1. customer features in the second month\n",
    "    # 2. products in the first month\n",
    "    x_vars = df2[cat_cols].copy() # cat_cols already includes ncodpers\n",
    "    x_vars.reset_index(inplace=True, drop=True) # drop original index and make a new one\n",
    "    x_vars.reset_index(inplace=True, drop=False) # also set the new index as a column for recoding row orders\n",
    "    x_vars_cols = x_vars.columns.tolist()\n",
    "    x_vars_cols[0] = 'sample_order' # change the name of the new column\n",
    "    x_vars.columns = x_vars_cols\n",
    "    x_vars.set_index('ncodpers', drop=True, inplace=True) # set the index to ncodpers again\n",
    "    x_vars = x_vars.join(df1_target) # direct join since df1_target contains all customers in month2\n",
    "    \n",
    "    # return x_vars if target_flag is False\n",
    "    if not target_flag:\n",
    "        x_vars.drop('sample_order', axis=1, inplace=True) # drop sample_order\n",
    "        x_vars.reset_index(inplace=True, drop=False) # add ncodpers\n",
    "        return x_vars\n",
    "    \n",
    "    # prepare target/label for each added product from the first to second month\n",
    "    # join target to x_vars\n",
    "    x_vars_new = x_vars.join(target, rsuffix='_t')\n",
    "    # set ncodpers as one column\n",
    "    x_vars_new.reset_index(inplace=True, drop=False)\n",
    "    x_vars.reset_index(inplace=True, drop=False)\n",
    "    \n",
    "    # melt\n",
    "    x_vars_new = x_vars_new.melt(id_vars=x_vars.columns)\n",
    "    # mapping from target_cols to index\n",
    "    target_cols_mapping = {c+'_t': n for (n, c) in enumerate(target_cols)}\n",
    "    # replace column name by index\n",
    "    x_vars_new.variable.replace(target_cols_mapping, inplace=True)\n",
    "    # reorder rows\n",
    "    x_vars_new.sort_values(['sample_order', 'variable'], inplace=True)\n",
    "    # keep new products\n",
    "    x_vars_new = x_vars_new[x_vars_new.value>0]\n",
    "    # drop sample_order and value\n",
    "    x_vars_new.drop(['sample_order', 'value'], axis=1, inplace=True)\n",
    "    # keep the order of rows as in the original data set\n",
    "    x_vars_new.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # variable\n",
    "    x_vars = x_vars_new.iloc[:, :-1].copy()\n",
    "    # target/label\n",
    "    target = x_vars_new.iloc[:, -1].copy()\n",
    "    \n",
    "    return x_vars, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = create_train_test('2015-05-28', '2015-06-28', target_flag=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val, y_val = create_train_test('2015-11-28', '2015-12-28', target_flag=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = create_train_test('2016-05-28', '2016-06-28', target_flag=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:2.91645\tval-mlogloss:2.93945\n",
      "[1]\ttrain-mlogloss:2.78563\tval-mlogloss:2.82684\n",
      "[2]\ttrain-mlogloss:2.6751\tval-mlogloss:2.72827\n",
      "[3]\ttrain-mlogloss:2.58366\tval-mlogloss:2.65113\n",
      "[4]\ttrain-mlogloss:2.49453\tval-mlogloss:2.57273\n",
      "[5]\ttrain-mlogloss:2.41242\tval-mlogloss:2.50677\n",
      "[6]\ttrain-mlogloss:2.34612\tval-mlogloss:2.4467\n",
      "[7]\ttrain-mlogloss:2.28669\tval-mlogloss:2.39776\n",
      "[8]\ttrain-mlogloss:2.22937\tval-mlogloss:2.35122\n",
      "[9]\ttrain-mlogloss:2.17384\tval-mlogloss:2.29996\n",
      "[10]\ttrain-mlogloss:2.12307\tval-mlogloss:2.25661\n",
      "[11]\ttrain-mlogloss:2.08031\tval-mlogloss:2.21912\n",
      "[12]\ttrain-mlogloss:2.04\tval-mlogloss:2.18456\n",
      "[13]\ttrain-mlogloss:1.99893\tval-mlogloss:2.15046\n",
      "[14]\ttrain-mlogloss:1.95945\tval-mlogloss:2.11762\n",
      "[15]\ttrain-mlogloss:1.92307\tval-mlogloss:2.08713\n",
      "[16]\ttrain-mlogloss:1.88998\tval-mlogloss:2.06008\n",
      "[17]\ttrain-mlogloss:1.85772\tval-mlogloss:2.03347\n",
      "[18]\ttrain-mlogloss:1.82859\tval-mlogloss:2.00913\n",
      "[19]\ttrain-mlogloss:1.80279\tval-mlogloss:1.98838\n",
      "[20]\ttrain-mlogloss:1.77791\tval-mlogloss:1.96712\n",
      "[21]\ttrain-mlogloss:1.75428\tval-mlogloss:1.94514\n",
      "[22]\ttrain-mlogloss:1.72977\tval-mlogloss:1.92619\n",
      "[23]\ttrain-mlogloss:1.70668\tval-mlogloss:1.9072\n",
      "[24]\ttrain-mlogloss:1.68579\tval-mlogloss:1.88961\n",
      "[25]\ttrain-mlogloss:1.66468\tval-mlogloss:1.87427\n",
      "[26]\ttrain-mlogloss:1.6446\tval-mlogloss:1.85773\n",
      "[27]\ttrain-mlogloss:1.62652\tval-mlogloss:1.84262\n",
      "[28]\ttrain-mlogloss:1.61053\tval-mlogloss:1.8309\n",
      "[29]\ttrain-mlogloss:1.59396\tval-mlogloss:1.81752\n",
      "[30]\ttrain-mlogloss:1.57689\tval-mlogloss:1.80325\n",
      "[31]\ttrain-mlogloss:1.56132\tval-mlogloss:1.79009\n",
      "[32]\ttrain-mlogloss:1.54642\tval-mlogloss:1.77782\n",
      "[33]\ttrain-mlogloss:1.5324\tval-mlogloss:1.76676\n",
      "[34]\ttrain-mlogloss:1.5179\tval-mlogloss:1.75652\n",
      "[35]\ttrain-mlogloss:1.5043\tval-mlogloss:1.7453\n",
      "[36]\ttrain-mlogloss:1.49227\tval-mlogloss:1.7348\n",
      "[37]\ttrain-mlogloss:1.48045\tval-mlogloss:1.72487\n",
      "[38]\ttrain-mlogloss:1.46843\tval-mlogloss:1.71476\n",
      "[39]\ttrain-mlogloss:1.45647\tval-mlogloss:1.70455\n",
      "[40]\ttrain-mlogloss:1.44583\tval-mlogloss:1.69617\n",
      "[41]\ttrain-mlogloss:1.43534\tval-mlogloss:1.68847\n",
      "[42]\ttrain-mlogloss:1.42487\tval-mlogloss:1.67937\n",
      "[43]\ttrain-mlogloss:1.4151\tval-mlogloss:1.67082\n",
      "[44]\ttrain-mlogloss:1.40488\tval-mlogloss:1.66243\n",
      "[45]\ttrain-mlogloss:1.39618\tval-mlogloss:1.65533\n",
      "[46]\ttrain-mlogloss:1.38665\tval-mlogloss:1.64806\n",
      "[47]\ttrain-mlogloss:1.37767\tval-mlogloss:1.64064\n",
      "[48]\ttrain-mlogloss:1.36934\tval-mlogloss:1.63402\n",
      "[49]\ttrain-mlogloss:1.36178\tval-mlogloss:1.62857\n"
     ]
    }
   ],
   "source": [
    "param = {'objective': 'multi:softprob', \n",
    "         'eta': 0.05, \n",
    "         'max_depth': 8, \n",
    "         'silent': 1, \n",
    "         'num_class': len(target_cols),\n",
    "         'eval_metric': 'mlogloss',\n",
    "         'min_child_weight': 1,\n",
    "         'subsample': 0.7,\n",
    "         'colsample_bytree': 0.7,\n",
    "         'seed': 0}\n",
    "num_rounds = 50\n",
    "\n",
    "dtrain = xgb.DMatrix(x_train.values, y_train.values)\n",
    "dval = xgb.DMatrix(x_val.values, y_val.values)\n",
    "model = xgb.train(param, dtrain, num_rounds, evals=[(dtrain, 'train'), (dval, 'val')], verbose_eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:2.94794\tval-mlogloss:2.91292\n",
      "[1]\ttrain-mlogloss:2.83664\tval-mlogloss:2.77859\n",
      "[2]\ttrain-mlogloss:2.73212\tval-mlogloss:2.65919\n",
      "[3]\ttrain-mlogloss:2.66538\tval-mlogloss:2.57861\n",
      "[4]\ttrain-mlogloss:2.5994\tval-mlogloss:2.49824\n",
      "[5]\ttrain-mlogloss:2.53806\tval-mlogloss:2.4258\n",
      "[6]\ttrain-mlogloss:2.47779\tval-mlogloss:2.35482\n",
      "[7]\ttrain-mlogloss:2.4202\tval-mlogloss:2.28942\n",
      "[8]\ttrain-mlogloss:2.37275\tval-mlogloss:2.23272\n",
      "[9]\ttrain-mlogloss:2.32865\tval-mlogloss:2.18113\n",
      "[10]\ttrain-mlogloss:2.28575\tval-mlogloss:2.13157\n",
      "[11]\ttrain-mlogloss:2.24709\tval-mlogloss:2.08721\n",
      "[12]\ttrain-mlogloss:2.21443\tval-mlogloss:2.04795\n",
      "[13]\ttrain-mlogloss:2.1798\tval-mlogloss:2.00793\n",
      "[14]\ttrain-mlogloss:2.15196\tval-mlogloss:1.97425\n",
      "[15]\ttrain-mlogloss:2.11943\tval-mlogloss:1.93757\n",
      "[16]\ttrain-mlogloss:2.09003\tval-mlogloss:1.90419\n",
      "[17]\ttrain-mlogloss:2.06219\tval-mlogloss:1.87285\n",
      "[18]\ttrain-mlogloss:2.03761\tval-mlogloss:1.84293\n",
      "[19]\ttrain-mlogloss:2.01264\tval-mlogloss:1.81432\n",
      "[20]\ttrain-mlogloss:1.98958\tval-mlogloss:1.78753\n",
      "[21]\ttrain-mlogloss:1.97056\tval-mlogloss:1.76341\n",
      "[22]\ttrain-mlogloss:1.95418\tval-mlogloss:1.74183\n",
      "[23]\ttrain-mlogloss:1.93509\tval-mlogloss:1.71881\n",
      "[24]\ttrain-mlogloss:1.91882\tval-mlogloss:1.69868\n",
      "[25]\ttrain-mlogloss:1.90395\tval-mlogloss:1.67915\n",
      "[26]\ttrain-mlogloss:1.88774\tval-mlogloss:1.65889\n",
      "[27]\ttrain-mlogloss:1.87332\tval-mlogloss:1.64013\n",
      "[28]\ttrain-mlogloss:1.85932\tval-mlogloss:1.6226\n",
      "[29]\ttrain-mlogloss:1.84639\tval-mlogloss:1.60635\n",
      "[30]\ttrain-mlogloss:1.83343\tval-mlogloss:1.58966\n",
      "[31]\ttrain-mlogloss:1.82093\tval-mlogloss:1.57389\n",
      "[32]\ttrain-mlogloss:1.80945\tval-mlogloss:1.55881\n",
      "[33]\ttrain-mlogloss:1.80051\tval-mlogloss:1.54556\n",
      "[34]\ttrain-mlogloss:1.7906\tval-mlogloss:1.53274\n",
      "[35]\ttrain-mlogloss:1.78068\tval-mlogloss:1.51965\n",
      "[36]\ttrain-mlogloss:1.7711\tval-mlogloss:1.5071\n",
      "[37]\ttrain-mlogloss:1.76215\tval-mlogloss:1.49543\n",
      "[38]\ttrain-mlogloss:1.75335\tval-mlogloss:1.4841\n",
      "[39]\ttrain-mlogloss:1.745\tval-mlogloss:1.47307\n",
      "[40]\ttrain-mlogloss:1.73624\tval-mlogloss:1.46181\n",
      "[41]\ttrain-mlogloss:1.7282\tval-mlogloss:1.45128\n",
      "[42]\ttrain-mlogloss:1.72166\tval-mlogloss:1.44139\n",
      "[43]\ttrain-mlogloss:1.71389\tval-mlogloss:1.43209\n",
      "[44]\ttrain-mlogloss:1.70754\tval-mlogloss:1.42287\n",
      "[45]\ttrain-mlogloss:1.70045\tval-mlogloss:1.41377\n",
      "[46]\ttrain-mlogloss:1.69456\tval-mlogloss:1.40539\n",
      "[47]\ttrain-mlogloss:1.68783\tval-mlogloss:1.39671\n",
      "[48]\ttrain-mlogloss:1.68283\tval-mlogloss:1.389\n",
      "[49]\ttrain-mlogloss:1.67735\tval-mlogloss:1.3815\n"
     ]
    }
   ],
   "source": [
    "param = {'objective': 'multi:softprob', \n",
    "         'eta': 0.05, \n",
    "         'max_depth': 8, \n",
    "         'silent': 1, \n",
    "         'num_class': len(target_cols),\n",
    "         'eval_metric': 'mlogloss',\n",
    "         'min_child_weight': 1,\n",
    "         'subsample': 0.7,\n",
    "         'colsample_bytree': 0.7,\n",
    "         'seed': 0}\n",
    "num_rounds = 50\n",
    "\n",
    "dtrain = xgb.DMatrix(x_train.values, y_train.values)\n",
    "dval = xgb.DMatrix(x_val.values, y_val.values)\n",
    "model = xgb.train(param, dval, num_rounds, evals=[(dtrain, 'train'), (dval, 'val')], verbose_eval=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction from my model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(xgb.DMatrix(x_test.values))\n",
    "preds = np.argsort(preds, axis=1)\n",
    "preds = np.fliplr(preds)[:, :7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write out prediction results from my model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = x_test.loc[:, 'ncodpers'].values\n",
    "final_preds = [' '.join([target_cols[k] for k in pred]) for pred in preds]\n",
    "\n",
    "out_df = pd.DataFrame({'ncodpers': test_id, 'added_products': final_preds})\n",
    "out_df.to_csv('eda_4_12.csv.gz', compression='gzip', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of new products in each month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_list = ['2015-01-28', '2015-02-28', '2015-03-28', '2015-04-28', '2015-05-28', '2015-06-28', \n",
    "              '2015-07-28', '2015-08-28', '2015-09-28', '2015-10-28', '2015-11-28', '2015-12-28', \n",
    "              '2016-01-28', '2016-02-28', '2016-03-28', '2016-04-28', '2016-05-28', '2016-06-28']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-01-28 2015-02-28\n",
      "2015-02-28 2015-03-28\n",
      "2015-03-28 2015-04-28\n",
      "2015-04-28 2015-05-28\n",
      "2015-05-28 2015-06-28\n",
      "2015-06-28 2015-07-28\n",
      "2015-07-28 2015-08-28\n",
      "2015-08-28 2015-09-28\n",
      "2015-09-28 2015-10-28\n",
      "2015-10-28 2015-11-28\n",
      "2015-11-28 2015-12-28\n",
      "2015-12-28 2016-01-28\n",
      "2016-01-28 2016-02-28\n",
      "2016-02-28 2016-03-28\n",
      "2016-03-28 2016-04-28\n",
      "2016-04-28 2016-05-28\n"
     ]
    }
   ],
   "source": [
    "target_dict = {}\n",
    "for month1, month2 in zip(month_list[:-2], month_list[1:-1]):\n",
    "    _, target_dict[month1] = create_train_test(month1, month2, target_flag=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
