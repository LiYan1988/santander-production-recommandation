{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering in RAM-Limited Data, Part 4\n",
    "\n",
    "#### Mean encoding of `target_combine` one the previous month target\n",
    "1. In order to mean encode `target_combine`, I have to first have lag target of previous months. For example, for June training set, I can include products in April and May, and also encode all products bought in April with the mean target in May.\n",
    "\n",
    "2. Another way of mean encoding is to not use time series. Just put all target together and analyze. In this case, we can have the results as in the [3-rd solution](http://blog.kaggle.com/2017/02/22/santander-product-recommendation-competition-3rd-place-winners-interview-ryuji-sakata/) and [forum discussion](https://www.kaggle.com/c/santander-product-recommendation/discussion/26899).\n",
    "\n",
    "The first method is too complicated to implement, so I will try the second one.\n",
    "\n",
    "#### CV@2015-12-28:\n",
    "- benchmark: val = 1.62857\n",
    "- with only `ind_actividad_client_combine`, `tiprel_1mes_combine`, `target_combine`, mlogloss=1.57141\n",
    "- with `ind_actividad_client_combine`, `tiprel_1mes_combine`, `target_combine`, `n_products` and patterns: val = 1.31122\n",
    "- Private score: 0.0302475, public score: 0.0299266"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from santander_helper import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load targets\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile('../input/targets.hdf'):\n",
    "    print('Load targets')\n",
    "    targets = pd.read_hdf('../input/targets.hdf', 'targets')\n",
    "else:\n",
    "    print('Create targets')\n",
    "    targets = []\n",
    "    for m1, m2 in tqdm.tqdm_notebook(list(zip(month_list[:-2], month_list[1:-1]))):\n",
    "        target1 = obtain_target(m2)\n",
    "        target1['fecha_dato'] = m2\n",
    "        targets.append(target1)\n",
    "\n",
    "    targets = pd.concat(targets, ignore_index=True, copy=False)\n",
    "    targets.to_hdf('../input/targets.hdf', 'targets', complib='blosc:lz4', complevel=9, format='t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New products for each customer at each month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_p = targets.copy()\n",
    "targets_p['dummy'] = 1\n",
    "targets_p = targets_p.pivot_table(index=['ncodpers', 'fecha_dato'], columns=['target'], values=['dummy'])\n",
    "targets_p.fillna(0.0, inplace=True)\n",
    "targets_p.reset_index(inplace=True)\n",
    "targets_p.columns = ['ncodpers', 'fecha_dato']+target_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate `target_combine`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_product_per_customer = targets.groupby(['ncodpers', 'fecha_dato'])['target'].count()\n",
    "new_product_per_customer = pd.DataFrame(new_product_per_customer)\n",
    "new_product_per_customer.reset_index(inplace=True, drop=False)\n",
    "cols = new_product_per_customer.columns.tolist()\n",
    "cols[-1] = 'target_count'\n",
    "new_product_per_customer.columns = cols\n",
    "\n",
    "month_mapping = dict(zip(month_list[1:-1], month_list[:-2]))\n",
    "new_product_per_customer.fecha_dato = new_product_per_customer.fecha_dato.map(month_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load products and extract product information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load df_target_cols\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile('../input/df_target_cols.hdf'):\n",
    "    print('Load df_target_cols')\n",
    "    df = pd.read_hdf('../input/df_target_cols.hdf', 'df_target_cols')\n",
    "else:\n",
    "    print('Create df_target_cols')\n",
    "    df = []\n",
    "    for month in tqdm.tqdm_notebook(month_list):\n",
    "        df.append(pd.read_hdf('../input/data_month_{}.hdf'.format(month), 'data_month'))\n",
    "    df = pd.concat(df, ignore_index=True)\n",
    "    df = df.loc[:, ['fecha_dato', 'ncodpers']+target_cols].copy()\n",
    "    df['target_combine'] = np.sum(df[target_cols].values*\n",
    "        np.float_power(2, np.arange(-10, len(target_cols)-10)), \n",
    "        axis=1, dtype=np.float64)\n",
    "    \n",
    "    df.to_hdf('../input/df_target_cols.hdf', 'df_target_cols', complib='blosc:lz4', complevel=9, format='t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge `target_combine` and `target_count`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = pd.merge(df, new_product_per_customer, how='left')\n",
    "dt.target_count = dt.target_count.fillna(0)\n",
    "dt['target_indicator'] = (dt.target_count>0).astype(int)\n",
    "\n",
    "count_mean_encoding = pd.DataFrame(dt.groupby('target_combine')['target_count'].mean())\n",
    "count_mean_encoding.columns = ['count_mean_encoding']\n",
    "indicator_mean_encoding = pd.DataFrame(dt.groupby('target_combine')['target_indicator'].mean())\n",
    "indicator_mean_encoding.columns = ['indicator_mean_encoding']\n",
    "\n",
    "# Merge mean encodings\n",
    "dt = pd.merge(dt, count_mean_encoding, how='left', left_on='target_combine', right_index=True)\n",
    "dt = pd.merge(dt, indicator_mean_encoding, how='left', left_on='target_combine', right_index=True)\n",
    "\n",
    "# Remove auxiliary columns\n",
    "dt.drop(target_cols+['target_count', 'target_indicator', 'fecha_dato', 'ncodpers'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_combine</th>\n",
       "      <th>count_mean_encoding</th>\n",
       "      <th>indicator_mean_encoding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.019237</td>\n",
       "      <td>0.015769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011855</td>\n",
       "      <td>0.010358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>64.000977</td>\n",
       "      <td>0.044697</td>\n",
       "      <td>0.025529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.250977</td>\n",
       "      <td>0.062157</td>\n",
       "      <td>0.054265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>64.250977</td>\n",
       "      <td>0.067220</td>\n",
       "      <td>0.048638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    target_combine  count_mean_encoding  indicator_mean_encoding\n",
       "0         0.000977             0.019237                 0.015769\n",
       "3         0.000000             0.011855                 0.010358\n",
       "21       64.000977             0.044697                 0.025529\n",
       "41        0.250977             0.062157                 0.054265\n",
       "44       64.250977             0.067220                 0.048638"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9568, 3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.to_hdf('../input/target_mean_encoding.hdf', 'target_mean_encoding', complib='blosc:lz4', complevel=9, format='t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
