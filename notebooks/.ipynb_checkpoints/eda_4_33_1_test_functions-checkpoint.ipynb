{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering and CV based on 5-th Place Solutions\n",
    "\n",
    "`param = {'objective': 'multi:softprob', \n",
    "         'eta': 0.05, \n",
    "         'max_depth': 8,\n",
    "         'silent': 1, \n",
    "         'num_class': len(target_cols),\n",
    "         'eval_metric': 'mlogloss',\n",
    "         'min_child_weight': 1,\n",
    "         'subsample': 0.7,\n",
    "         'colsample_bytree': 0.7,\n",
    "         'seed': 0}`\n",
    "         \n",
    "`n_repeats=2\n",
    "n_trees = 150`\n",
    "\n",
    "val-MAP@7:0.89935, private LB: 0.0266884, public LB: 0.0264044\n",
    "\n",
    "New in this notebook:\n",
    "- Create training data for all months (2015-02-28 to 2016-04-28) and validate on 2016-05-28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from santander_helper import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create all months' data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fixed_lag = 6\n",
    "# for i, m in tqdm.tqdm_notebook(enumerate(month_list), total=len(month_list)):\n",
    "#     print(m)\n",
    "#     if m in ['2015-01-28', '2016-06-28']:\n",
    "#         continue\n",
    "#     x_train, y_train, w_train = create_train(m, max_lag=i, fixed_lag=fixed_lag, pattern_flag=True)\n",
    "#     print('-'*60)\n",
    "# del x_train, y_train, w_train\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all months' data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7167cee5a6d84c4db308164e555ec228",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=18), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "203"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "w_train = []\n",
    "fixed_lag = 6\n",
    "for i, m in tqdm.tqdm_notebook(enumerate(month_list), total=len(month_list)):\n",
    "    if m in ['2015-01-28', '2016-06-28']:\n",
    "        continue\n",
    "    x_tmp, y_tmp, w_tmp = create_train(m, max_lag=i, fixed_lag=fixed_lag, pattern_flag=True)\n",
    "    x_train.append(x_tmp)\n",
    "    y_train.append(y_tmp)\n",
    "    w_train.append(w_tmp)\n",
    "del x_tmp, y_tmp, w_tmp\n",
    "gc.collect()\n",
    "\n",
    "# Prepare for train and validation\n",
    "x_val = x_train[-1]\n",
    "y_val = y_train[-1]\n",
    "w_val = w_train[-1]\n",
    "\n",
    "x_train = pd.concat(x_train[:-1], axis=0, ignore_index=True, sort=False)\n",
    "y_train = pd.concat(y_train[:-1], axis=0, ignore_index=True, sort=False)\n",
    "w_train = pd.concat(w_train[:-1], axis=0, ignore_index=True, sort=False)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.264369\tval-merror:0.280592\ttrain-MAP@7:0\tval-MAP@7:0.89426\n",
      "[1]\ttrain-merror:0.261121\tval-merror:0.276471\ttrain-MAP@7:0\tval-MAP@7:0.898705\n",
      "[2]\ttrain-merror:0.259361\tval-merror:0.273682\ttrain-MAP@7:0\tval-MAP@7:0.901197\n",
      "[3]\ttrain-merror:0.25834\tval-merror:0.272487\ttrain-MAP@7:0\tval-MAP@7:0.902048\n",
      "[4]\ttrain-merror:0.25738\tval-merror:0.271646\ttrain-MAP@7:0\tval-MAP@7:0.902625\n",
      "[5]\ttrain-merror:0.256701\tval-merror:0.271411\ttrain-MAP@7:0\tval-MAP@7:0.903462\n",
      "[6]\ttrain-merror:0.256367\tval-merror:0.271032\ttrain-MAP@7:0\tval-MAP@7:0.903767\n",
      "[7]\ttrain-merror:0.255809\tval-merror:0.270889\ttrain-MAP@7:0\tval-MAP@7:0.904071\n",
      "[8]\ttrain-merror:0.255355\tval-merror:0.270498\ttrain-MAP@7:0\tval-MAP@7:0.904665\n",
      "[9]\ttrain-merror:0.254994\tval-merror:0.270451\ttrain-MAP@7:0\tval-MAP@7:0.904784\n",
      "[10]\ttrain-merror:0.254642\tval-merror:0.270532\ttrain-MAP@7:0\tval-MAP@7:0.904831\n",
      "[11]\ttrain-merror:0.254294\tval-merror:0.270396\ttrain-MAP@7:0\tval-MAP@7:0.904902\n",
      "[12]\ttrain-merror:0.254006\tval-merror:0.270291\ttrain-MAP@7:0\tval-MAP@7:0.90504\n",
      "[13]\ttrain-merror:0.253537\tval-merror:0.270023\ttrain-MAP@7:0\tval-MAP@7:0.905435\n",
      "[14]\ttrain-merror:0.253164\tval-merror:0.269993\ttrain-MAP@7:0\tval-MAP@7:0.905657\n",
      "[15]\ttrain-merror:0.252941\tval-merror:0.26964\ttrain-MAP@7:0\tval-MAP@7:0.906003\n",
      "[16]\ttrain-merror:0.252657\tval-merror:0.269482\ttrain-MAP@7:0\tval-MAP@7:0.906247\n",
      "[17]\ttrain-merror:0.252346\tval-merror:0.269401\ttrain-MAP@7:0\tval-MAP@7:0.906496\n",
      "[18]\ttrain-merror:0.252097\tval-merror:0.26901\ttrain-MAP@7:0\tval-MAP@7:0.906962\n",
      "[19]\ttrain-merror:0.251836\tval-merror:0.268792\ttrain-MAP@7:0\tval-MAP@7:0.907025\n",
      "[20]\ttrain-merror:0.251603\tval-merror:0.268557\ttrain-MAP@7:0\tval-MAP@7:0.907266\n",
      "[21]\ttrain-merror:0.251264\tval-merror:0.268402\ttrain-MAP@7:0\tval-MAP@7:0.90749\n",
      "[22]\ttrain-merror:0.250996\tval-merror:0.268114\ttrain-MAP@7:0\tval-MAP@7:0.907665\n",
      "[23]\ttrain-merror:0.250827\tval-merror:0.267825\ttrain-MAP@7:0\tval-MAP@7:0.907931\n",
      "[24]\ttrain-merror:0.250631\tval-merror:0.267601\ttrain-MAP@7:0\tval-MAP@7:0.908016\n",
      "[25]\ttrain-merror:0.250404\tval-merror:0.267281\ttrain-MAP@7:0\tval-MAP@7:0.908275\n",
      "[26]\ttrain-merror:0.250185\tval-merror:0.266995\ttrain-MAP@7:0\tval-MAP@7:0.908457\n",
      "[27]\ttrain-merror:0.249939\tval-merror:0.267008\ttrain-MAP@7:0\tval-MAP@7:0.90846\n",
      "[28]\ttrain-merror:0.249794\tval-merror:0.267084\ttrain-MAP@7:0\tval-MAP@7:0.908557\n",
      "[29]\ttrain-merror:0.249615\tval-merror:0.266769\ttrain-MAP@7:0\tval-MAP@7:0.908829\n",
      "[30]\ttrain-merror:0.249449\tval-merror:0.266607\ttrain-MAP@7:0\tval-MAP@7:0.909037\n",
      "[31]\ttrain-merror:0.249251\tval-merror:0.266481\ttrain-MAP@7:0\tval-MAP@7:0.909074\n",
      "[32]\ttrain-merror:0.249085\tval-merror:0.266513\ttrain-MAP@7:0\tval-MAP@7:0.909244\n",
      "[33]\ttrain-merror:0.248927\tval-merror:0.266737\ttrain-MAP@7:0\tval-MAP@7:0.909189\n",
      "[34]\ttrain-merror:0.248703\tval-merror:0.266741\ttrain-MAP@7:0\tval-MAP@7:0.909251\n",
      "[35]\ttrain-merror:0.248593\tval-merror:0.266803\ttrain-MAP@7:0\tval-MAP@7:0.909307\n",
      "[36]\ttrain-merror:0.248329\tval-merror:0.266678\ttrain-MAP@7:0\tval-MAP@7:0.909437\n",
      "[37]\ttrain-merror:0.248114\tval-merror:0.266175\ttrain-MAP@7:0\tval-MAP@7:0.909723\n",
      "[38]\ttrain-merror:0.247989\tval-merror:0.266298\ttrain-MAP@7:0\tval-MAP@7:0.909679\n",
      "[39]\ttrain-merror:0.247828\tval-merror:0.265973\ttrain-MAP@7:0\tval-MAP@7:0.909841\n",
      "[40]\ttrain-merror:0.247586\tval-merror:0.265998\ttrain-MAP@7:0\tval-MAP@7:0.909826\n",
      "[41]\ttrain-merror:0.247433\tval-merror:0.265698\ttrain-MAP@7:0\tval-MAP@7:0.909994\n",
      "[42]\ttrain-merror:0.247226\tval-merror:0.265531\ttrain-MAP@7:0\tval-MAP@7:0.910138\n",
      "[43]\ttrain-merror:0.247167\tval-merror:0.2653\ttrain-MAP@7:0\tval-MAP@7:0.910229\n",
      "[44]\ttrain-merror:0.247017\tval-merror:0.265229\ttrain-MAP@7:0\tval-MAP@7:0.910288\n",
      "[45]\ttrain-merror:0.246912\tval-merror:0.265138\ttrain-MAP@7:0\tval-MAP@7:0.91039\n",
      "[46]\ttrain-merror:0.246746\tval-merror:0.265091\ttrain-MAP@7:0\tval-MAP@7:0.910471\n",
      "[47]\ttrain-merror:0.246645\tval-merror:0.265015\ttrain-MAP@7:0\tval-MAP@7:0.910501\n",
      "[48]\ttrain-merror:0.246535\tval-merror:0.265195\ttrain-MAP@7:0\tval-MAP@7:0.910413\n",
      "[49]\ttrain-merror:0.246385\tval-merror:0.264954\ttrain-MAP@7:0\tval-MAP@7:0.910568\n",
      "Repeat 0, validate score = 0.265, running time = 35.016 min\n",
      "Score mean = 0.265, std = nan\n"
     ]
    }
   ],
   "source": [
    "param = {'objective': 'multi:softprob', \n",
    "         'eta': 0.1, \n",
    "         'max_depth': 8,\n",
    "         'silent': 1, \n",
    "         'num_class': len(target_cols),\n",
    "         'eval_metric': 'merror',\n",
    "         'min_child_weight': 10,\n",
    "         'lambda': 5,\n",
    "         'subsample': 0.7,\n",
    "         'colsample_bytree': 0.7,\n",
    "         'seed': 0}\n",
    "\n",
    "n_rows = None # number of rows in train dataset, to simplify testing, always set to None\n",
    "n_repeats = 1\n",
    "n_trees = 50\n",
    "train = {'x': x_train.iloc[:n_rows, :], 'y': y_train.iloc[:n_rows], 'w': w_train.iloc[:n_rows]}\n",
    "val = {'x': x_val.iloc[:n_rows, :], 'y': y_val.iloc[:n_rows], 'w': w_val.iloc[:n_rows]}\n",
    "df, clfs, running_time = cv_all_month(param, train, val, n_features=350, num_boost_round=n_trees, \n",
    "    n_repeats=n_repeats, random_state=0, verbose_eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = create_test(month='2016-06-28', max_lag=17, fixed_lag=6, pattern_flag=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_name = 'p1'\n",
    "y_pred, y_sub = predict_all_month(model_dict=clfs, x_test=x_test, \n",
    "    sub_name='eda_4_33_{}.csv.gz'.format(simulation_name), n_features=350, n_trees=n_trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = load_pickle('parameter_tune_eda_4_32_p4.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = y_pred2[-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 929615, 19)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 929615, 19)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_final = np.concatenate((y_pred, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_final = np.mean(y_pred_final, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(929615, 19)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_sub = np.argsort(y_pred_final, axis=1)\n",
    "y_sub = np.fliplr(y_sub)[:, :7]\n",
    "# Prepare submission\n",
    "test_id = x_test.loc[:, 'ncodpers'].values\n",
    "y_sub = [' '.join([target_cols[k] for k in pred]) for pred in y_sub]\n",
    "y_sub = pd.DataFrame({'ncodpers': test_id, 'added_products': y_sub})\n",
    "y_sub.to_csv(sub_name, compression='gzip', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
