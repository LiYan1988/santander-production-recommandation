{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAP\n",
    "\n",
    "Improve MAP evaluation speed\n",
    "10 times run:\n",
    "- 17.7s: original\n",
    "- 18.05s: removes `apks`\n",
    "- 18.01: remove `enumerate`\n",
    "- 17.04: remove `y_prob = {}`\n",
    "\n",
    "Optimizations:\n",
    "- convert `dict` to `np.array`\n",
    "- `enumerate` is quite efficient, so do not remove it, if I cannot find a better way\n",
    "- `for` loop limits the speed, but so many customers with very few products, hard to optimize\n",
    "- `np.mean` and `np.array` seem more efficient than `a += 1` and `a /= n`, but not sure\n",
    "- use `numpy` whenever you can\n",
    "- train+evaluation time reduced by 35%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from santander_helper import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def apk1(actual, predicted, k=7, default=0.0):\n",
    "    if actual.size==0:\n",
    "        return default\n",
    "    \n",
    "    if predicted.size>k:\n",
    "        predicted = predicted[:k]\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "    \n",
    "    for i,p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "\n",
    "    return score / min(actual.size, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def eval_map1(y_prob, dtrain, gt={}, ts={}):\n",
    "    '''\n",
    "    Evaluate MAP@7 for train and validation sets---\n",
    "    '''\n",
    "    # Check which set is it?\n",
    "    if len(dtrain.get_label())==ts['train']:\n",
    "        glist = gt['train']\n",
    "    elif len(dtrain.get_label())==ts['val']:\n",
    "        glist = gt['val']\n",
    "    \n",
    "    n = len(glist)\n",
    "    score = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        tmp = np.mean(y_prob[glist[i][1], :], axis=0)\n",
    "        tmp = np.argsort(tmp)[:-8:-1]\n",
    "        score[i] = apk1(glist[i][0], tmp)\n",
    "    score = np.mean(score)\n",
    "\n",
    "    return 'MAP@7', score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_map1(x_train, y_train):\n",
    "    '''Prepare ground truth value and index for MAP evaluation, and save it.'''\n",
    "    # Ground truth value: MAP needs to know the products bought by each customers\n",
    "    gtv = pd.concat((pd.DataFrame(x_train.loc[:, 'ncodpers'].copy()), y_train), axis=1, ignore_index=True)\n",
    "    gtv.columns = ['ncodpers', 'target']\n",
    "    gtv = gtv.groupby('ncodpers')['target'].apply(lambda x: x.values).to_dict()\n",
    "    # Ground truth index: MAP needs to know for each customer which rows are its corresponding data\n",
    "    gti = pd.DataFrame(x_train.loc[:, 'ncodpers']).reset_index()\n",
    "    gti = gti.groupby('ncodpers')['index'].apply(lambda x: x.values).to_dict()\n",
    "    \n",
    "    gt = np.array([[gtv[k], gti[k]] for k in gtv.keys()])\n",
    "    \n",
    "    return gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_train = '2015-06-28'\n",
    "month_val = '2016-05-28'\n",
    "\n",
    "param = {'objective': 'multi:softprob', \n",
    "         'eta': 0.05, \n",
    "         'max_depth': 8, \n",
    "         'silent': 1, \n",
    "         'num_class': len(target_cols),\n",
    "         'eval_metric': 'mlogloss',\n",
    "         'min_child_weight': 1,\n",
    "         'subsample': 0.7,\n",
    "         'colsample_bytree': 0.7,\n",
    "         'seed': 0,\n",
    "         'booster': 'gbtree', \n",
    "         'rate_drop': 0.1, \n",
    "         'skip_drop': 0.5,\n",
    "         'normalize_type': 'tree', \n",
    "         'sample_type': 'uniform'}\n",
    "num_rounds = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:2.60259\tval-mlogloss:2.62607\ttrain-MAP@7:0.96534\tval-MAP@7:0.965859\n",
      "[1]\ttrain-mlogloss:2.37044\tval-mlogloss:2.41404\ttrain-MAP@7:0.968539\tval-MAP@7:0.962926\n",
      "[2]\ttrain-mlogloss:2.19071\tval-mlogloss:2.24495\ttrain-MAP@7:0.969591\tval-MAP@7:0.964\n",
      "[3]\ttrain-mlogloss:2.043\tval-mlogloss:2.10607\ttrain-MAP@7:0.970032\tval-MAP@7:0.965531\n",
      "[4]\ttrain-mlogloss:1.9175\tval-mlogloss:1.98782\ttrain-MAP@7:0.970235\tval-MAP@7:0.966833\n",
      "[5]\ttrain-mlogloss:1.80862\tval-mlogloss:1.88123\ttrain-MAP@7:0.970676\tval-MAP@7:0.969043\n",
      "[6]\ttrain-mlogloss:1.71258\tval-mlogloss:1.79014\ttrain-MAP@7:0.971184\tval-MAP@7:0.966674\n",
      "[7]\ttrain-mlogloss:1.62668\tval-mlogloss:1.7092\ttrain-MAP@7:0.971655\tval-MAP@7:0.968602\n",
      "[8]\ttrain-mlogloss:1.54919\tval-mlogloss:1.63335\ttrain-MAP@7:0.972032\tval-MAP@7:0.968778\n",
      "[9]\ttrain-mlogloss:1.47879\tval-mlogloss:1.56767\ttrain-MAP@7:0.972389\tval-MAP@7:0.968722\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, weight_train = create_train(month_train, pattern_flag=True)\n",
    "x_val, y_val, weight_val = create_train(month_val, pattern_flag=True)\n",
    "\n",
    "gt_train = prep_map(x_train, y_train)\n",
    "gt_val = prep_map(x_val, y_val)\n",
    "ground_truth = {'train': gt_train, 'val': gt_val}\n",
    "\n",
    "dtrain = xgb.DMatrix(x_train, y_train)\n",
    "dval = xgb.DMatrix(x_val, y_val)\n",
    "\n",
    "data_hash = {'train': hash(dtrain.get_label().tostring()), 'val': hash(dval.get_label().tostring())}\n",
    "data_len = {'train': len(dtrain.get_label()), 'val': len(dval.get_label())}\n",
    "\n",
    "weight_index = 0\n",
    "\n",
    "dtrain.set_weight(weight_train.values[:, weight_index])\n",
    "dval.set_weight(weight_val.values[:, weight_index])\n",
    "\n",
    "param['seed'] = np.random.randint(10**6)\n",
    "#model = xgb.train(param, dtrain, num_rounds)\n",
    "\n",
    "model = xgb.train(param, dtrain, num_rounds, feval=eval_map, verbose_eval=True, evals=[(dtrain, 'train'), (dval, 'val')], \n",
    "                 gt=ground_truth, ts=data_hash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, weight_train = create_train(month_train, pattern_flag=True)\n",
    "x_val, y_val, weight_val = create_train(month_val, pattern_flag=True)\n",
    "\n",
    "gt_train = prep_map1(x_train, y_train)\n",
    "gt_val = prep_map1(x_val, y_val)\n",
    "ground_truth = {'train': gt_train, 'val': gt_val}\n",
    "\n",
    "dtrain = xgb.DMatrix(x_train, y_train)\n",
    "dval = xgb.DMatrix(x_val, y_val)\n",
    "\n",
    "data_hash = {'train': hash(dtrain.get_label().tostring()), 'val': hash(dval.get_label().tostring())}\n",
    "data_len = {'train': len(dtrain.get_label()), 'val': len(dval.get_label())}\n",
    "\n",
    "weight_index = 0\n",
    "\n",
    "dtrain.set_weight(weight_train.values[:, weight_index])\n",
    "dval.set_weight(weight_val.values[:, weight_index])\n",
    "\n",
    "param['seed'] = np.random.randint(10**6)\n",
    "#model = xgb.train(param, dtrain, num_rounds)\n",
    "\n",
    "model = xgb.train(param, dtrain, num_rounds, feval=eval_map1, verbose_eval=True, evals=[(dtrain, 'train'), (dval, 'val')], \n",
    "                 gt=ground_truth, ts=data_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('MAP@7', 1.0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Is the MAP correct? If not, the answer should not be 1\n",
    "y_train_prob = model.predict(dtrain)\n",
    "y_val_prob = model.predict(dval)\n",
    "\n",
    "y_prob = np.zeros((y_train.shape[0], len(target_cols)))\n",
    "\n",
    "y_prob[np.arange(len(y_train)), y_train] = 1\n",
    "\n",
    "eval_map1(y_prob, dtrain, gt=ground_truth, ts=data_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time of evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.170260999999982"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_train = prep_map1(x_train, y_train)\n",
    "gt_val = prep_map1(x_val, y_val)\n",
    "ground_truth = {'train': gt_train, 'val': gt_val}\n",
    "timeit.timeit('eval_map1(y_prob, dtrain, gt=ground_truth, ts=data_len)', globals=globals(), number=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.318205699999993"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeit.timeit('model = xgb.train(param, dtrain, num_boost_round=1)', globals=globals(), number=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time of training+evaluating with `eval_map1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:2.6029\tval-mlogloss:2.62639\ttrain-MAP@7:0.965442\tval-MAP@7:0.960371\n",
      "[0]\ttrain-mlogloss:2.6029\tval-mlogloss:2.62639\ttrain-MAP@7:0.965442\tval-MAP@7:0.960371\n",
      "[0]\ttrain-mlogloss:2.6029\tval-mlogloss:2.62639\ttrain-MAP@7:0.965442\tval-MAP@7:0.960371\n",
      "[0]\ttrain-mlogloss:2.6029\tval-mlogloss:2.62639\ttrain-MAP@7:0.965442\tval-MAP@7:0.960371\n",
      "[0]\ttrain-mlogloss:2.6029\tval-mlogloss:2.62639\ttrain-MAP@7:0.965442\tval-MAP@7:0.960371\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "56.101055599999995"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeit.timeit(\"model = xgb.train(param, dtrain, num_boost_round=1, feval=eval_map1, evals=[(dtrain, 'train'), (dval, 'val')], gt=ground_truth, ts=data_len, )\", globals=globals(), number=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time of train+evaluation with `eval_map`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:2.60259\tval-mlogloss:2.62607\ttrain-MAP@7:0.96534\tval-MAP@7:0.965859\n",
      "[0]\ttrain-mlogloss:2.60259\tval-mlogloss:2.62607\ttrain-MAP@7:0.96534\tval-MAP@7:0.965859\n",
      "[0]\ttrain-mlogloss:2.60259\tval-mlogloss:2.62607\ttrain-MAP@7:0.96534\tval-MAP@7:0.965859\n",
      "[0]\ttrain-mlogloss:2.60259\tval-mlogloss:2.62607\ttrain-MAP@7:0.96534\tval-MAP@7:0.965859\n",
      "[0]\ttrain-mlogloss:2.60259\tval-mlogloss:2.62607\ttrain-MAP@7:0.96534\tval-MAP@7:0.965859\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "85.21862490000001"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeit.timeit(\"model = xgb.train(param, dtrain, num_boost_round=1, feval=eval_map, evals=[(dtrain, 'train'), (dval, 'val')], gt=ground_truth, ts=data_hash)\", globals=globals(), number=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two methods should have the same evaluation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:2.60259\tval-mlogloss:2.62607\ttrain-MAP@7:0.96534\tval-MAP@7:0.965859\n"
     ]
    }
   ],
   "source": [
    "gt_train = prep_map(x_train, y_train)\n",
    "gt_val = prep_map(x_val, y_val)\n",
    "ground_truth = {'train': gt_train, 'val': gt_val}\n",
    "model = xgb.train(param, dtrain, num_boost_round=1, feval=eval_map, evals=[(dtrain, 'train'), (dval, 'val')], gt=ground_truth, ts=data_hash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:2.60259\tval-mlogloss:2.62607\ttrain-MAP@7:0.96534\tval-MAP@7:0.965859\n"
     ]
    }
   ],
   "source": [
    "gt_train = prep_map1(x_train, y_train)\n",
    "gt_val = prep_map1(x_val, y_val)\n",
    "ground_truth = {'train': gt_train, 'val': gt_val}\n",
    "model = xgb.train(param, dtrain, num_boost_round=1, feval=eval_map1, evals=[(dtrain, 'train'), (dval, 'val')], gt=ground_truth, ts=data_len)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
