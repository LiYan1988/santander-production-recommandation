{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if os.name=='nt':\n",
    "    try:\n",
    "        mingw_path = 'C:\\\\Program Files\\\\mingw-w64\\\\x86_64-8.1.0-posix-seh-rt_v6-rev0\\\\mingw64\\\\bin'\n",
    "        os.environ['PATH'] = mingw_path + ';' + os.environ['PATH']\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "import gc\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "tqdm.tqdm.pandas()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_hdf('../input/data_all.hdf', 'train_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in df:\n",
    "    if df[c].dtype.name=='category':\n",
    "        le = LabelEncoder()\n",
    "        df[c] = le.fit_transform(df[c])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use 2015-05 and 2015-06 data to train a model, and predict on 2016-05 for 2016-06\n",
    "\n",
    "1. Use two months data to create one dataset\n",
    "    1. For each user in 2015-06, extract all the history data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = ['ind_ahor_fin_ult1','ind_aval_fin_ult1',\n",
    "               'ind_cco_fin_ult1','ind_cder_fin_ult1',\n",
    "               'ind_cno_fin_ult1','ind_ctju_fin_ult1',\n",
    "               'ind_ctma_fin_ult1','ind_ctop_fin_ult1',\n",
    "               'ind_ctpp_fin_ult1',\n",
    "               #'ind_deco_fin_ult1',\n",
    "               #'ind_deme_fin_ult1',\n",
    "               'ind_dela_fin_ult1',\n",
    "               'ind_ecue_fin_ult1','ind_fond_fin_ult1',\n",
    "               'ind_hip_fin_ult1','ind_plan_fin_ult1',\n",
    "               'ind_pres_fin_ult1','ind_reca_fin_ult1',\n",
    "               'ind_tjcr_fin_ult1','ind_valo_fin_ult1',\n",
    "               #'ind_viv_fin_ult1',\n",
    "               'ind_nomina_ult1',\n",
    "               'ind_nom_pens_ult1','ind_recibo_ult1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['fecha_dato', 'ncodpers', 'ind_empleado', 'pais_residencia', 'sexo',\n",
    "       'age', 'fecha_alta', 'ind_nuevo', 'antiguedad', 'indrel',\n",
    "       'ult_fec_cli_1t', 'indrel_1mes', 'tiprel_1mes', 'indresi', 'indext',\n",
    "       'conyuemp', 'canal_entrada', 'indfall', 'tipodom', 'cod_prov',\n",
    "       'nomprov', 'ind_actividad_cliente', 'renta', 'segmento',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot = df.pivot_table(index='ncodpers', columns='fecha_dato', \n",
    "                                values=target_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_cols = df.fecha_dato.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2 = month_cols[-2]\n",
    "m1 = month_cols[-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_max_score(df, df_pivot, m1, m2):\n",
    "    '''Calculate the maximum possible score for each month'''\n",
    "    \n",
    "    # sales of m2\n",
    "    tmp2 = df_pivot.loc[:, (slice(None), m2)].copy()\n",
    "    # sales of m1\n",
    "    tmp1 = df_pivot.loc[:, (slice(None), m1)].copy()\n",
    "\n",
    "    # customer ids in m2\n",
    "    tmp2_ncodpers = df.loc[df.fecha_dato==m2].ncodpers\n",
    "    # keep customers existing in m2, and remove irrelavent customers\n",
    "    tmp2 = tmp2.loc[tmp2.index.isin(tmp2_ncodpers)]    \n",
    "    # replace NAN with 0.0\n",
    "    tmp2.fillna(0.0, inplace=True)\n",
    "    \n",
    "    # customers in m2 should also in tmp1, even though some of them\n",
    "    # are new in m2 and do not exist in m1 (they will be NAN)\n",
    "    tmp1 = tmp1.loc[tmp1.index.isin(tmp2.index)]\n",
    "    # replace NAN with 0.0\n",
    "    tmp1.fillna(0.0, inplace=True)\n",
    "\n",
    "    # change column names so that subtract works\n",
    "    tmp1.columns = target_cols\n",
    "    tmp2.columns = target_cols\n",
    "\n",
    "    # sales in m2 - sales in m1\n",
    "    tmp_diff = tmp2.subtract(tmp1)\n",
    "\n",
    "    # replace negative values with 0.0\n",
    "    tmp_diff[tmp_diff<0] = 0\n",
    "    # replace NAN with 0.0\n",
    "    tmp_diff.fillna(0.0, inplace=True)\n",
    "    \n",
    "    # maximum possible score\n",
    "    score_max = tmp_diff.max(axis=1).sum()/tmp_diff.shape[0]\n",
    "    \n",
    "    return tmp_diff, score_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-01-28T00:00:00.000000000 2015-02-28T00:00:00.000000000 0.0438368871873177\n",
      "2015-02-28T00:00:00.000000000 2015-03-28T00:00:00.000000000 0.04537284113863597\n",
      "2015-03-28T00:00:00.000000000 2015-04-28T00:00:00.000000000 0.045397363757937834\n",
      "2015-04-28T00:00:00.000000000 2015-05-28T00:00:00.000000000 0.03886656845323337\n",
      "2015-05-28T00:00:00.000000000 2015-06-28T00:00:00.000000000 0.05748050181139359\n",
      "2015-06-28T00:00:00.000000000 2015-07-28T00:00:00.000000000 0.046959751366867634\n",
      "2015-07-28T00:00:00.000000000 2015-08-28T00:00:00.000000000 0.041536952636441374\n",
      "2015-08-28T00:00:00.000000000 2015-09-28T00:00:00.000000000 0.05104686633388796\n",
      "2015-09-28T00:00:00.000000000 2015-10-28T00:00:00.000000000 0.0539904130115853\n",
      "2015-10-28T00:00:00.000000000 2015-11-28T00:00:00.000000000 0.04038035159125447\n",
      "2015-11-28T00:00:00.000000000 2015-12-28T00:00:00.000000000 0.04067340554658281\n",
      "2015-12-28T00:00:00.000000000 2016-01-28T00:00:00.000000000 0.0331016328174368\n",
      "2016-01-28T00:00:00.000000000 2016-02-28T00:00:00.000000000 0.04224001633177834\n",
      "2016-02-28T00:00:00.000000000 2016-03-28T00:00:00.000000000 0.03301350375536713\n",
      "2016-03-28T00:00:00.000000000 2016-04-28T00:00:00.000000000 0.030922981792013995\n",
      "2016-04-28T00:00:00.000000000 2016-05-28T00:00:00.000000000 0.0319006970829446\n"
     ]
    }
   ],
   "source": [
    "month_cols = df.fecha_dato.unique()\n",
    "best_score = {}\n",
    "for n, m in enumerate(month_cols[:-2]):\n",
    "    m1 = m\n",
    "    m2 = month_cols[n+1]\n",
    "    tmp_diff, score_max = calculate_max_score(df, df_pivot, m1, m2)\n",
    "    print(m1, m2, score_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train on 2015-05 to 2015-06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the two months\n",
    "m1 = month_cols[4] # numpy.datetime64('2015-05-28T00:00:00.000000000')\n",
    "m2 = month_cols[5] # numpy.datetime64('2015-06-28T00:00:00.000000000')\n",
    "\n",
    "# target is the increment between 2015-06 and 2015-05\n",
    "target, score_max = calculate_max_score(df, df_pivot, m1, m2)\n",
    "\n",
    "# use customer features in 2015-06 \n",
    "x_train = df.loc[df.fecha_dato==m2, feature_cols].copy()\n",
    "# set customer id as row index\n",
    "x_train.set_index('ncodpers', inplace=True)\n",
    "\n",
    "# add sales in the previous month (2015-05)\n",
    "prev_target = df_pivot.loc[:, (slice(None), m1)]\n",
    "# change column names\n",
    "prev_target.columns = target_cols\n",
    "# join features\n",
    "x_train = x_train.join(prev_target)\n",
    "# replace NAN in previous target_cols with 0.0\n",
    "x_train.loc[:, target_cols] = x_train.loc[:, target_cols].fillna(0.0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train.drop(['fecha_dato', 'fecha_alta', 'ult_fec_cli_1t'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a number, not 'NaTType'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-43ea0d5a2f07>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mnum_rounds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mdtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_rounds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\xgboost-0.72-py3.6.egg\\xgboost\\core.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, label, missing, weight, silent, feature_names, feature_types, nthread)\u001b[0m\n\u001b[0;32m    279\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_from_csc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 281\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_from_npy2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnthread\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    282\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\xgboost-0.72-py3.6.egg\\xgboost\\core.py\u001b[0m in \u001b[0;36m_init_from_npy2d\u001b[1;34m(self, mat, missing, nthread)\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[1;31m# we try to avoid data copies if possible (reshape returns a view when possible\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m         \u001b[1;31m# and we explicitly tell np.array to try and avoid copying)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 349\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    350\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m         \u001b[0mmissing\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmissing\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mmissing\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'NaTType'"
     ]
    }
   ],
   "source": [
    "param = {'objective': 'multi:softprob', \n",
    "         'eta': 0.05, \n",
    "         'max_depth': 8, \n",
    "         'silent': 0, \n",
    "         'num_class': len(target_cols),\n",
    "         'eval_metric': 'mlogloss',\n",
    "         'min_child_weight': 1,\n",
    "         'subsample': 0.7,\n",
    "         'colsample_bytree': 0.7,\n",
    "         'seed': 1}\n",
    "num_rounds = 50\n",
    "\n",
    "dtrain = xgb.DMatrix(x_train.values, target.values)\n",
    "model = xgb.train(param, dtrain, num_rounds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
