{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering in RAM-Limited Data, Part 1\n",
    "\n",
    "- `ind_actividad_client_combine`\n",
    "- `tiprel_1mes_combine`\n",
    "- `target_combine`\n",
    "\n",
    "benchmark on 2015-12-28: mlogloss=1.62857\n",
    "\n",
    "cv on 2015-12-28: mlogloss=1.57141"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if os.name=='nt':\n",
    "    try:\n",
    "        mingw_path = 'C:\\\\Program Files\\\\mingw-w64\\\\x86_64-8.1.0-posix-seh-rt_v6-rev0\\\\mingw64\\\\bin'\n",
    "        os.environ['PATH'] = mingw_path + ';' + os.environ['PATH']\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "import gc\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "tqdm.tqdm.pandas()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['ncodpers',\n",
    " 'canal_entrada',\n",
    " 'conyuemp',\n",
    " 'ind_actividad_cliente',\n",
    " 'ind_empleado',\n",
    " 'ind_nuevo',\n",
    " 'indext',\n",
    " 'indfall',\n",
    " 'indrel',\n",
    " 'indrel_1mes',\n",
    " 'indresi',\n",
    " 'pais_residencia',\n",
    " 'segmento',\n",
    " 'sexo',\n",
    " 'tipodom',\n",
    " 'tiprel_1mes',\n",
    " 'age',\n",
    " 'antiguedad',\n",
    " 'renta']\n",
    "\n",
    "target_cols = ['ind_cco_fin_ult1',\n",
    " 'ind_cder_fin_ult1',\n",
    " 'ind_cno_fin_ult1',\n",
    " 'ind_ctju_fin_ult1',\n",
    " 'ind_ctma_fin_ult1',\n",
    " 'ind_ctop_fin_ult1',\n",
    " 'ind_ctpp_fin_ult1',\n",
    " #'ind_deco_fin_ult1',\n",
    " 'ind_dela_fin_ult1',\n",
    " #'ind_deme_fin_ult1',\n",
    " 'ind_ecue_fin_ult1',\n",
    " 'ind_fond_fin_ult1',\n",
    " 'ind_hip_fin_ult1',\n",
    " 'ind_nom_pens_ult1',\n",
    " 'ind_nomina_ult1',\n",
    " 'ind_plan_fin_ult1',\n",
    " 'ind_pres_fin_ult1',\n",
    " 'ind_reca_fin_ult1',\n",
    " 'ind_recibo_ult1',\n",
    " 'ind_tjcr_fin_ult1',\n",
    " 'ind_valo_fin_ult1']\n",
    " #'ind_viv_fin_ult1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test(month1, month2, target_flag=True):\n",
    "    '''Create train and test data between month1 and month2'''\n",
    "    \n",
    "    # first/early month\n",
    "    df1 = pd.read_hdf('../input/data_month_{}.hdf'.format(month1), 'data_month')\n",
    "    # second/later month\n",
    "    df2 = pd.read_hdf('../input/data_month_{}.hdf'.format(month2), 'data_month')\n",
    "    \n",
    "    # second month products\n",
    "    df2_target = df2.loc[:, ['ncodpers']+target_cols].copy()\n",
    "    df2_target.set_index('ncodpers', inplace=True, drop=False) # initially keep ncodpers as a column and drop it later\n",
    "    # a dataframe containing the ncodpers only\n",
    "    df2_ncodpers = pd.DataFrame(df2_target.ncodpers)\n",
    "    # drop ncodpers from df2_target\n",
    "    df2_target.drop('ncodpers', axis=1, inplace=True)\n",
    "    \n",
    "    # first month products for all the customers in the second month\n",
    "    df1_target = df1.loc[:, ['ncodpers']+target_cols].copy()\n",
    "    df1_target.set_index('ncodpers', inplace=True, drop=True) # do not keep ncodpers as column\n",
    "    # obtain the products purchased by all the customers in the second month\n",
    "    # by joining df1_target to df2_ncodpers, NAN filled by 0.0\n",
    "    df1_target = df2_ncodpers.join(df1_target, how='left')\n",
    "    df1_target.fillna(0.0, inplace=True)\n",
    "    df1_target.drop('ncodpers', axis=1, inplace=True)\n",
    "    \n",
    "    # new products from the first to second month\n",
    "    target = df2_target.subtract(df1_target)\n",
    "    target[target<0] = 0\n",
    "    target.fillna(0.0, inplace=True)\n",
    "    \n",
    "    # feature of the second month: \n",
    "    # 1. customer features in the second month\n",
    "    # 2. products in the first month\n",
    "    x_vars = df2[cat_cols].copy() # cat_cols already includes ncodpers\n",
    "    x_vars.reset_index(inplace=True, drop=True) # drop original index and make a new one\n",
    "    x_vars.reset_index(inplace=True, drop=False) # also set the new index as a column for recoding row orders\n",
    "    x_vars_cols = x_vars.columns.tolist()\n",
    "    x_vars_cols[0] = 'sample_order' # change the name of the new column\n",
    "    x_vars.columns = x_vars_cols\n",
    "    x_vars.set_index('ncodpers', drop=True, inplace=True) # set the index to ncodpers again\n",
    "    x_vars = x_vars.join(df1_target) # direct join since df1_target contains all customers in month2\n",
    "    \n",
    "    # concatenate this and previous month values of ind_activadad_cliente\n",
    "    df2_ind_actividad_cliente = df2[['ncodpers', 'ind_actividad_cliente']].copy()\n",
    "    df2_ind_actividad_cliente.set_index('ncodpers', inplace=True)\n",
    "    df2_ind_actividad_cliente.sort_index(inplace=True)\n",
    "    \n",
    "    df1_ind_actividad_cliente = df1[['ncodpers', 'ind_actividad_cliente']].copy()\n",
    "    df1_ind_actividad_cliente.set_index('ncodpers', inplace=True)\n",
    "    df1_ind_actividad_cliente.sort_index(inplace=True)\n",
    "\n",
    "    df2_ind_actividad_cliente = df2_ind_actividad_cliente.join(df1_ind_actividad_cliente, rsuffix='_p')\n",
    "    df2_ind_actividad_cliente.fillna(2.0, inplace=True)\n",
    "    df2_ind_actividad_cliente['ind_actividad_client_combine'] = 3*df2_ind_actividad_cliente.ind_actividad_cliente+df2_ind_actividad_cliente.ind_actividad_cliente_p\n",
    "    df2_ind_actividad_cliente = pd.DataFrame(df2_ind_actividad_cliente.iloc[:, -1])\n",
    "\n",
    "    x_vars = pd.merge(x_vars, df2_ind_actividad_cliente, left_index=True, right_index=True, how='left')\n",
    "    \n",
    "    # concatenate this and previous month value of tiprel_1mes\n",
    "    df2_tiprel_1mes = df2[['ncodpers', 'tiprel_1mes']].copy()\n",
    "    df2_tiprel_1mes.set_index('ncodpers', inplace=True)\n",
    "    df2_tiprel_1mes.sort_index(inplace=True)\n",
    "\n",
    "    df1_tiprel_1mes = df1[['ncodpers', 'tiprel_1mes']].copy()\n",
    "    df1_tiprel_1mes.set_index('ncodpers', inplace=True)\n",
    "    df1_tiprel_1mes.sort_index(inplace=True)\n",
    "\n",
    "    df2_tiprel_1mes = df2_tiprel_1mes.join(df1_tiprel_1mes, rsuffix='_p')\n",
    "    df2_tiprel_1mes.fillna(0.0, inplace=True)\n",
    "    df2_tiprel_1mes['tiprel_1mes_combine'] = 6*df2_tiprel_1mes.tiprel_1mes+df2_tiprel_1mes.tiprel_1mes_p\n",
    "    df2_tiprel_1mes = pd.DataFrame(df2_tiprel_1mes.iloc[:, -1])\n",
    "\n",
    "    x_vars = pd.merge(x_vars, df2_tiprel_1mes, left_index=True, right_index=True, how='left')\n",
    "    \n",
    "    # combination of target columns\n",
    "    x_vars['target_combine'] = np.sum(x_vars[target_cols].values*\n",
    "        np.float_power(2, np.arange(-10, len(target_cols)-10)), axis=1, dtype=np.float64)\n",
    "    \n",
    "    # return x_vars, df2_ncodpers, df1, df2, df1_target, df2_target\n",
    "    \n",
    "    # return x_vars if target_flag is False\n",
    "    if not target_flag:\n",
    "        x_vars.drop('sample_order', axis=1, inplace=True) # drop sample_order\n",
    "        x_vars.reset_index(inplace=True, drop=False) # add ncodpers\n",
    "        return x_vars #, df2_ncodpers, df1, df2, df1_target, df2_target\n",
    "    \n",
    "    if target_flag:    \n",
    "        # prepare target/label for each added product from the first to second month\n",
    "        # join target to x_vars\n",
    "        x_vars_new = x_vars.join(target, rsuffix='_t')\n",
    "        # set ncodpers as one column\n",
    "        x_vars_new.reset_index(inplace=True, drop=False)\n",
    "        x_vars.reset_index(inplace=True, drop=False)\n",
    "\n",
    "        # melt\n",
    "        x_vars_new = x_vars_new.melt(id_vars=x_vars.columns)\n",
    "        # mapping from target_cols to index\n",
    "        target_cols_mapping = {c+'_t': n for (n, c) in enumerate(target_cols)}\n",
    "        # replace column name by index\n",
    "        x_vars_new.variable.replace(target_cols_mapping, inplace=True)\n",
    "        # reorder rows\n",
    "        x_vars_new.sort_values(['sample_order', 'variable'], inplace=True)\n",
    "        # keep new products\n",
    "        x_vars_new = x_vars_new[x_vars_new.value>0]\n",
    "        # drop sample_order and value\n",
    "        x_vars_new.drop(['sample_order', 'value'], axis=1, inplace=True)\n",
    "        # keep the order of rows as in the original data set\n",
    "        x_vars_new.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        var_cols = x_vars.columns.tolist()\n",
    "        var_cols.remove('sample_order')\n",
    "        # variable\n",
    "        x_vars = x_vars_new.loc[:, var_cols].copy()\n",
    "        # target/label\n",
    "        target = x_vars_new.loc[:, 'variable'].copy()\n",
    "\n",
    "        return x_vars, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = create_train_test('2015-05-28', '2015-06-28', target_flag=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val, y_val = create_train_test('2015-11-28', '2015-12-28', target_flag=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combination of target cols\n",
    "\n",
    "generate a value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vars['target_combine'] = np.sum(x_vars[target_cols].values*np.float_power(2, np.arange(-10, len(target_cols)-10)), axis=1, dtype=np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combination of target cols, generate a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = x_vars[target_cols].values.astype(int)\n",
    "n = [np.array_str(n[k]).strip('[]').replace(' ', '') for k in range(n.shape[0])]\n",
    "x_vars['target_str'] = n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ind_actividad_cliente, this and previous months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_ind_actividad_cliente = df2[['ncodpers', 'ind_actividad_cliente']].copy()\n",
    "df2_ind_actividad_cliente.set_index('ncodpers', inplace=True)\n",
    "df2_ind_actividad_cliente.sort_index(inplace=True)\n",
    "\n",
    "df1_ind_actividad_cliente = df1[['ncodpers', 'ind_actividad_cliente']].copy()\n",
    "df1_ind_actividad_cliente.set_index('ncodpers', inplace=True)\n",
    "df1_ind_actividad_cliente.sort_index(inplace=True)\n",
    "\n",
    "df2_ind_actividad_cliente = df2_ind_actividad_cliente.join(df1_ind_actividad_cliente, rsuffix='_p')\n",
    "df2_ind_actividad_cliente.fillna(2.0, inplace=True)\n",
    "df2_ind_actividad_cliente['ind_actividad_client_combine'] = 3*df2_ind_actividad_cliente.ind_actividad_cliente+df2_ind_actividad_cliente.ind_actividad_cliente_p\n",
    "df2_ind_actividad_cliente = pd.DataFrame(df2_ind_actividad_cliente.iloc[:, -1])\n",
    "\n",
    "x_train = pd.merge(x_train, df2_ind_actividad_cliente, left_index=True, right_index=True, how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tiprel_1mes, this and previous months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_tiprel_1mes = df2[['ncodpers', 'tiprel_1mes']].copy()\n",
    "df2_tiprel_1mes.set_index('ncodpers', inplace=True)\n",
    "df2_tiprel_1mes.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_tiprel_1mes = df2[['ncodpers', 'tiprel_1mes']].copy()\n",
    "df2_tiprel_1mes.set_index('ncodpers', inplace=True)\n",
    "df2_tiprel_1mes.sort_index(inplace=True)\n",
    "\n",
    "df1_tiprel_1mes = df1[['ncodpers', 'tiprel_1mes']].copy()\n",
    "df1_tiprel_1mes.set_index('ncodpers', inplace=True)\n",
    "df1_tiprel_1mes.sort_index(inplace=True)\n",
    "\n",
    "df2_tiprel_1mes = df2_tiprel_1mes.join(df1_tiprel_1mes, rsuffix='_p')\n",
    "df2_tiprel_1mes.fillna(0.0, inplace=True)\n",
    "df2_tiprel_1mes['tiprel_1mes_combine'] = 6*df2_tiprel_1mes.tiprel_1mes+df2_tiprel_1mes.tiprel_1mes_p\n",
    "df2_tiprel_1mes = pd.DataFrame(df2_tiprel_1mes.iloc[:, -1])\n",
    "\n",
    "x_train = pd.merge(x_train, df2_tiprel_1mes, left_index=True, right_index=True, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_val, y_val = create_train_test('2015-11-28', '2015-12-28', target_flag=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_test = create_train_test('2016-05-28', '2016-06-28', target_flag=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:2.78588\tval-mlogloss:2.81081\n",
      "[1]\ttrain-mlogloss:2.64934\tval-mlogloss:2.68425\n",
      "[2]\ttrain-mlogloss:2.53863\tval-mlogloss:2.58187\n",
      "[3]\ttrain-mlogloss:2.44868\tval-mlogloss:2.50256\n",
      "[4]\ttrain-mlogloss:2.36749\tval-mlogloss:2.43314\n",
      "[5]\ttrain-mlogloss:2.29299\tval-mlogloss:2.36547\n",
      "[6]\ttrain-mlogloss:2.22584\tval-mlogloss:2.30934\n",
      "[7]\ttrain-mlogloss:2.16867\tval-mlogloss:2.2672\n",
      "[8]\ttrain-mlogloss:2.11775\tval-mlogloss:2.22926\n",
      "[9]\ttrain-mlogloss:2.06721\tval-mlogloss:2.18504\n",
      "[10]\ttrain-mlogloss:2.0226\tval-mlogloss:2.14531\n",
      "[11]\ttrain-mlogloss:1.98011\tval-mlogloss:2.11163\n",
      "[12]\ttrain-mlogloss:1.9408\tval-mlogloss:2.07727\n",
      "[13]\ttrain-mlogloss:1.90795\tval-mlogloss:2.05248\n",
      "[14]\ttrain-mlogloss:1.87261\tval-mlogloss:2.02346\n",
      "[15]\ttrain-mlogloss:1.83892\tval-mlogloss:1.99364\n",
      "[16]\ttrain-mlogloss:1.80716\tval-mlogloss:1.96815\n",
      "[17]\ttrain-mlogloss:1.77723\tval-mlogloss:1.9417\n",
      "[18]\ttrain-mlogloss:1.7499\tval-mlogloss:1.92143\n",
      "[19]\ttrain-mlogloss:1.72376\tval-mlogloss:1.89904\n",
      "[20]\ttrain-mlogloss:1.69868\tval-mlogloss:1.87747\n",
      "[21]\ttrain-mlogloss:1.67541\tval-mlogloss:1.8582\n",
      "[22]\ttrain-mlogloss:1.65276\tval-mlogloss:1.83976\n",
      "[23]\ttrain-mlogloss:1.63118\tval-mlogloss:1.82109\n",
      "[24]\ttrain-mlogloss:1.61101\tval-mlogloss:1.80398\n",
      "[25]\ttrain-mlogloss:1.59224\tval-mlogloss:1.7891\n",
      "[26]\ttrain-mlogloss:1.57387\tval-mlogloss:1.77389\n",
      "[27]\ttrain-mlogloss:1.55657\tval-mlogloss:1.75971\n",
      "[28]\ttrain-mlogloss:1.54016\tval-mlogloss:1.74593\n",
      "[29]\ttrain-mlogloss:1.52435\tval-mlogloss:1.73486\n",
      "[30]\ttrain-mlogloss:1.50934\tval-mlogloss:1.7224\n",
      "[31]\ttrain-mlogloss:1.49451\tval-mlogloss:1.7102\n",
      "[32]\ttrain-mlogloss:1.4804\tval-mlogloss:1.69989\n",
      "[33]\ttrain-mlogloss:1.46675\tval-mlogloss:1.68884\n",
      "[34]\ttrain-mlogloss:1.454\tval-mlogloss:1.67857\n",
      "[35]\ttrain-mlogloss:1.44182\tval-mlogloss:1.66994\n",
      "[36]\ttrain-mlogloss:1.42998\tval-mlogloss:1.66081\n",
      "[37]\ttrain-mlogloss:1.41855\tval-mlogloss:1.65197\n",
      "[38]\ttrain-mlogloss:1.40726\tval-mlogloss:1.64364\n",
      "[39]\ttrain-mlogloss:1.39676\tval-mlogloss:1.63597\n",
      "[40]\ttrain-mlogloss:1.3864\tval-mlogloss:1.6284\n",
      "[41]\ttrain-mlogloss:1.3769\tval-mlogloss:1.62131\n",
      "[42]\ttrain-mlogloss:1.36736\tval-mlogloss:1.61373\n",
      "[43]\ttrain-mlogloss:1.35821\tval-mlogloss:1.60644\n",
      "[44]\ttrain-mlogloss:1.34966\tval-mlogloss:1.59966\n",
      "[45]\ttrain-mlogloss:1.3414\tval-mlogloss:1.59419\n",
      "[46]\ttrain-mlogloss:1.33287\tval-mlogloss:1.58834\n",
      "[47]\ttrain-mlogloss:1.32495\tval-mlogloss:1.58277\n",
      "[48]\ttrain-mlogloss:1.31744\tval-mlogloss:1.57634\n",
      "[49]\ttrain-mlogloss:1.30987\tval-mlogloss:1.57141\n"
     ]
    }
   ],
   "source": [
    "param = {'objective': 'multi:softprob', \n",
    "         'eta': 0.05, \n",
    "         'max_depth': 8, \n",
    "         'silent': 1, \n",
    "         'num_class': len(target_cols),\n",
    "         'eval_metric': 'mlogloss',\n",
    "         'min_child_weight': 1,\n",
    "         'subsample': 0.7,\n",
    "         'colsample_bytree': 0.7,\n",
    "         'seed': 0}\n",
    "num_rounds = 50\n",
    "\n",
    "dtrain = xgb.DMatrix(x_train.values, y_train.values)\n",
    "dval = xgb.DMatrix(x_val.values, y_val.values)\n",
    "model = xgb.train(param, dtrain, num_rounds, evals=[(dtrain, 'train'), (dval, 'val')], verbose_eval=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction from my model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(xgb.DMatrix(x_test.values))\n",
    "\n",
    "df_preds = pd.DataFrame(preds, index=x_test.index, columns=target_cols)\n",
    "df_preds[x_test[target_cols]==1] = 0\n",
    "preds = df_preds.values\n",
    "preds = np.argsort(preds, axis=1)\n",
    "preds = np.fliplr(preds)[:, :7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write out prediction results from my model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = x_test.loc[:, 'ncodpers'].values\n",
    "final_preds = [' '.join([target_cols[k] for k in pred]) for pred in preds]\n",
    "\n",
    "out_df = pd.DataFrame({'ncodpers': test_id, 'added_products': final_preds})\n",
    "out_df.to_csv('eda_4_15.csv.gz', compression='gzip', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
