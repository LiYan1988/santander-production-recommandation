{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering and CV, continued from eda_4_21\n",
    "\n",
    "New train and test generation, features include:\n",
    "- customer info in the second month\n",
    "- products in the first month\n",
    "- combination of first and second month `ind_actividad_cliente`\n",
    "- combination of first and second month `tiprel_1mes`\n",
    "- combination of first month product by using binary number (`target_combine`)\n",
    "- encoding `target_combine` with \n",
    "    - mean number of new products\n",
    "    - mean number of customers with new products\n",
    "    - mean number of customers with each new products\n",
    "\n",
    "\n",
    "#### CV@2015-12-28:\n",
    "- benchmark: val = 1.62857\n",
    "- with only `ind_actividad_client_combine`, `tiprel_1mes_combine`, `target_combine`, mlogloss=1.57141\n",
    "- with `ind_actividad_client_combine`, `tiprel_1mes_combine`, `target_combine`, `n_products` and patterns: val = 1.31122\n",
    "- Private score: 0.0302475, public score: 0.0299266"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from santander_helper import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 113.79it/s]\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = create_train('2015-06-28')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 184.48it/s]\n"
     ]
    }
   ],
   "source": [
    "x_val, y_val = create_train('2015-12-28')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:02<00:00,  7.73it/s]\n"
     ]
    }
   ],
   "source": [
    "x_test = create_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model\n",
    "\n",
    "- benchmark: val = 1.62857\n",
    "- with only `ind_actividad_client_combine`, `tiprel_1mes_combine`, `target_combine`, mlogloss=1.57141\n",
    "- with `ind_actividad_client_combine`, `tiprel_1mes_combine`, `target_combine`, `n_products` and patterns: val = 1.31122"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:2.72219\tval-mlogloss:2.74082\n",
      "[1]\ttrain-mlogloss:2.56442\tval-mlogloss:2.60281\n",
      "[2]\ttrain-mlogloss:2.42179\tval-mlogloss:2.47642\n",
      "[3]\ttrain-mlogloss:2.3052\tval-mlogloss:2.37478\n",
      "[4]\ttrain-mlogloss:2.2042\tval-mlogloss:2.28715\n",
      "[5]\ttrain-mlogloss:2.11638\tval-mlogloss:2.21133\n",
      "[6]\ttrain-mlogloss:2.03799\tval-mlogloss:2.15155\n",
      "[7]\ttrain-mlogloss:1.96828\tval-mlogloss:2.09571\n",
      "[8]\ttrain-mlogloss:1.90473\tval-mlogloss:2.04013\n",
      "[9]\ttrain-mlogloss:1.84744\tval-mlogloss:1.99022\n",
      "[10]\ttrain-mlogloss:1.79351\tval-mlogloss:1.94516\n",
      "[11]\ttrain-mlogloss:1.74622\tval-mlogloss:1.90364\n",
      "[12]\ttrain-mlogloss:1.69986\tval-mlogloss:1.86328\n",
      "[13]\ttrain-mlogloss:1.65765\tval-mlogloss:1.82695\n",
      "[14]\ttrain-mlogloss:1.61949\tval-mlogloss:1.79345\n",
      "[15]\ttrain-mlogloss:1.58177\tval-mlogloss:1.76408\n",
      "[16]\ttrain-mlogloss:1.54737\tval-mlogloss:1.73608\n",
      "[17]\ttrain-mlogloss:1.51506\tval-mlogloss:1.7094\n",
      "[18]\ttrain-mlogloss:1.48489\tval-mlogloss:1.68581\n",
      "[19]\ttrain-mlogloss:1.45596\tval-mlogloss:1.66122\n",
      "[20]\ttrain-mlogloss:1.42857\tval-mlogloss:1.64065\n",
      "[21]\ttrain-mlogloss:1.40341\tval-mlogloss:1.62139\n",
      "[22]\ttrain-mlogloss:1.37897\tval-mlogloss:1.60023\n",
      "[23]\ttrain-mlogloss:1.35525\tval-mlogloss:1.5818\n",
      "[24]\ttrain-mlogloss:1.3324\tval-mlogloss:1.56229\n",
      "[25]\ttrain-mlogloss:1.31078\tval-mlogloss:1.54596\n",
      "[26]\ttrain-mlogloss:1.29042\tval-mlogloss:1.53162\n",
      "[27]\ttrain-mlogloss:1.27094\tval-mlogloss:1.51588\n",
      "[28]\ttrain-mlogloss:1.25321\tval-mlogloss:1.50186\n",
      "[29]\ttrain-mlogloss:1.23631\tval-mlogloss:1.48813\n",
      "[30]\ttrain-mlogloss:1.22004\tval-mlogloss:1.47502\n",
      "[31]\ttrain-mlogloss:1.20416\tval-mlogloss:1.46215\n",
      "[32]\ttrain-mlogloss:1.18892\tval-mlogloss:1.44911\n",
      "[33]\ttrain-mlogloss:1.17443\tval-mlogloss:1.43788\n",
      "[34]\ttrain-mlogloss:1.16037\tval-mlogloss:1.42708\n",
      "[35]\ttrain-mlogloss:1.14673\tval-mlogloss:1.41586\n",
      "[36]\ttrain-mlogloss:1.13385\tval-mlogloss:1.40489\n",
      "[37]\ttrain-mlogloss:1.12186\tval-mlogloss:1.39569\n",
      "[38]\ttrain-mlogloss:1.11069\tval-mlogloss:1.3875\n",
      "[39]\ttrain-mlogloss:1.09932\tval-mlogloss:1.37802\n",
      "[40]\ttrain-mlogloss:1.08831\tval-mlogloss:1.36901\n",
      "[41]\ttrain-mlogloss:1.07755\tval-mlogloss:1.36019\n",
      "[42]\ttrain-mlogloss:1.06757\tval-mlogloss:1.35258\n",
      "[43]\ttrain-mlogloss:1.05774\tval-mlogloss:1.34468\n",
      "[44]\ttrain-mlogloss:1.04881\tval-mlogloss:1.33717\n",
      "[45]\ttrain-mlogloss:1.04005\tval-mlogloss:1.33023\n",
      "[46]\ttrain-mlogloss:1.03166\tval-mlogloss:1.32388\n",
      "[47]\ttrain-mlogloss:1.02296\tval-mlogloss:1.31709\n",
      "[48]\ttrain-mlogloss:1.015\tval-mlogloss:1.31061\n",
      "[49]\ttrain-mlogloss:1.00732\tval-mlogloss:1.30461\n"
     ]
    }
   ],
   "source": [
    "param = {'objective': 'multi:softprob', \n",
    "         'eta': 0.05, \n",
    "         'max_depth': 8, \n",
    "         'silent': 1, \n",
    "         'num_class': len(target_cols),\n",
    "         'eval_metric': 'mlogloss',\n",
    "         'min_child_weight': 1,\n",
    "         'subsample': 0.7,\n",
    "         'colsample_bytree': 0.7,\n",
    "         'seed': 0}\n",
    "num_rounds = 50\n",
    "\n",
    "dtrain = xgb.DMatrix(x_train.values, y_train.values)\n",
    "dval = xgb.DMatrix(x_val.values, y_val.values)\n",
    "model = xgb.train(param, dtrain, num_rounds, evals=[(dtrain, 'train'), (dval, 'val')], verbose_eval=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction from my model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(xgb.DMatrix(x_test.values))\n",
    "\n",
    "df_preds = pd.DataFrame(preds, index=x_test.index, columns=target_cols)\n",
    "# Remove already bought products \n",
    "df_preds[x_test[target_cols]==1] = 0 \n",
    "preds = df_preds.values\n",
    "preds = np.argsort(preds, axis=1)\n",
    "preds = np.fliplr(preds)[:, :7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write out prediction results from my model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = x_test.loc[:, 'ncodpers'].values\n",
    "final_preds = [' '.join([target_cols[k] for k in pred]) for pred in preds]\n",
    "\n",
    "out_df = pd.DataFrame({'ncodpers': test_id, 'added_products': final_preds})\n",
    "out_df.to_csv('eda_4_22.csv.gz', compression='gzip', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
