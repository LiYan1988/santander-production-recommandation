{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering in RAM-Limited Data, Part 5\n",
    "\n",
    "#### CV for mean encoding of `target_combine`\n",
    "\n",
    "#### CV@2015-12-28:\n",
    "- benchmark: val = 1.62857\n",
    "- with only `ind_actividad_client_combine`, `tiprel_1mes_combine`, `target_combine`, mlogloss=1.57141\n",
    "- with `ind_actividad_client_combine`, `tiprel_1mes_combine`, `target_combine`, `n_products` and patterns: val = 1.31122\n",
    "    - Private score: 0.0302475, public score: 0.0299266\n",
    "\n",
    "- with all above and mean encoding of target indicator and target #products: mlogloss=1.30756\n",
    "    - Private score: 0.0302597, public score: 0.0299519"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from santander_helper import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 2015-05-28 data\n",
      "Loading 2015-06-28 data\n",
      "Products in 2015-06-28\n",
      "Products in 2015-05-28\n",
      "New products added in 2015-06-28\n",
      "Join customer features and previous month products for 2015-06-28\n",
      "Concatenate this and previous months ind_activadad_cliente\n",
      "Concatenate this and previous months tiprel_1mes\n",
      "Combine all products for each customer\n",
      "\n",
      "Start counting patterns:\n",
      "Encoding pattern...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 640825/640825 [01:42<00:00, 6249.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding pattern...\n",
      "Counting pattern...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 634760/634760 [03:13<00:00, 3286.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare target\n",
      "Time used: 6.167 min\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = create_train_test('2015-06-28', target_flag=True, pattern_flag=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 2015-11-28 data\n",
      "Loading 2015-12-28 data\n",
      "Products in 2015-12-28\n",
      "Products in 2015-11-28\n",
      "New products added in 2015-12-28\n",
      "Join customer features and previous month products for 2015-12-28\n",
      "Concatenate this and previous months ind_activadad_cliente\n",
      "Concatenate this and previous months tiprel_1mes\n",
      "Combine all products for each customer\n",
      "\n",
      "Start counting patterns:\n",
      "Encoding pattern...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 912728/912728 [02:22<00:00, 6398.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding pattern...\n",
      "Counting pattern...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 893990/893990 [04:29<00:00, 3318.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare target\n",
      "Time used: 8.612 min\n"
     ]
    }
   ],
   "source": [
    "x_val, y_val = create_train_test('2015-12-28', max_lag=5, target_flag=True, pattern_flag=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 2016-05-28 data\n",
      "Loading 2016-06-28 data\n",
      "Products in 2016-06-28\n",
      "Products in 2016-05-28\n",
      "New products added in 2016-06-28\n",
      "Join customer features and previous month products for 2016-06-28\n",
      "Concatenate this and previous months ind_activadad_cliente\n",
      "Concatenate this and previous months tiprel_1mes\n",
      "Combine all products for each customer\n",
      "\n",
      "Start counting patterns:\n",
      "Encoding pattern...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 938423/938423 [02:28<00:00, 6321.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding pattern...\n",
      "Counting pattern...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 930436/930436 [04:41<00:00, 3300.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time used: 7.568 min\n"
     ]
    }
   ],
   "source": [
    "x_test = create_train_test('2016-06-28', max_lag=5, target_flag=False, pattern_flag=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model\n",
    "\n",
    "- benchmark: val = 1.62857\n",
    "- with only `ind_actividad_client_combine`, `tiprel_1mes_combine`, `target_combine`, mlogloss=1.57141\n",
    "- with `ind_actividad_client_combine`, `tiprel_1mes_combine`, `target_combine`, `n_products` and patterns: val = 1.31122\n",
    "- with all above and mean encoding of target indicator and target #products: mlogloss=1.30756\n",
    "- with all above and mean encoding of each product: mlogloss=1.29115"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:2.70903\tval-mlogloss:2.73873\n",
      "[1]\ttrain-mlogloss:2.53678\tval-mlogloss:2.59098\n",
      "[2]\ttrain-mlogloss:2.40034\tval-mlogloss:2.46699\n",
      "[3]\ttrain-mlogloss:2.28557\tval-mlogloss:2.36497\n",
      "[4]\ttrain-mlogloss:2.18614\tval-mlogloss:2.27827\n",
      "[5]\ttrain-mlogloss:2.09942\tval-mlogloss:2.20174\n",
      "[6]\ttrain-mlogloss:2.02198\tval-mlogloss:2.13291\n",
      "[7]\ttrain-mlogloss:1.95192\tval-mlogloss:2.07303\n",
      "[8]\ttrain-mlogloss:1.88901\tval-mlogloss:2.01858\n",
      "[9]\ttrain-mlogloss:1.83189\tval-mlogloss:1.96977\n",
      "[10]\ttrain-mlogloss:1.77926\tval-mlogloss:1.92354\n",
      "[11]\ttrain-mlogloss:1.73043\tval-mlogloss:1.88093\n",
      "[12]\ttrain-mlogloss:1.68511\tval-mlogloss:1.84279\n",
      "[13]\ttrain-mlogloss:1.64311\tval-mlogloss:1.8066\n",
      "[14]\ttrain-mlogloss:1.60385\tval-mlogloss:1.77342\n",
      "[15]\ttrain-mlogloss:1.56708\tval-mlogloss:1.74457\n",
      "[16]\ttrain-mlogloss:1.53271\tval-mlogloss:1.7145\n",
      "[17]\ttrain-mlogloss:1.50018\tval-mlogloss:1.68711\n",
      "[18]\ttrain-mlogloss:1.46977\tval-mlogloss:1.66147\n",
      "[19]\ttrain-mlogloss:1.4415\tval-mlogloss:1.6371\n",
      "[20]\ttrain-mlogloss:1.41427\tval-mlogloss:1.61369\n",
      "[21]\ttrain-mlogloss:1.38874\tval-mlogloss:1.5916\n",
      "[22]\ttrain-mlogloss:1.36435\tval-mlogloss:1.57202\n",
      "[23]\ttrain-mlogloss:1.34147\tval-mlogloss:1.55416\n",
      "[24]\ttrain-mlogloss:1.31951\tval-mlogloss:1.53658\n",
      "[25]\ttrain-mlogloss:1.29866\tval-mlogloss:1.51918\n",
      "[26]\ttrain-mlogloss:1.2787\tval-mlogloss:1.5031\n",
      "[27]\ttrain-mlogloss:1.25978\tval-mlogloss:1.488\n",
      "[28]\ttrain-mlogloss:1.24195\tval-mlogloss:1.47291\n",
      "[29]\ttrain-mlogloss:1.2252\tval-mlogloss:1.46011\n",
      "[30]\ttrain-mlogloss:1.20906\tval-mlogloss:1.44656\n",
      "[31]\ttrain-mlogloss:1.19346\tval-mlogloss:1.43566\n",
      "[32]\ttrain-mlogloss:1.17861\tval-mlogloss:1.42307\n",
      "[33]\ttrain-mlogloss:1.16431\tval-mlogloss:1.41197\n",
      "[34]\ttrain-mlogloss:1.15064\tval-mlogloss:1.40201\n",
      "[35]\ttrain-mlogloss:1.13754\tval-mlogloss:1.39146\n",
      "[36]\ttrain-mlogloss:1.12507\tval-mlogloss:1.38132\n",
      "[37]\ttrain-mlogloss:1.11307\tval-mlogloss:1.37202\n",
      "[38]\ttrain-mlogloss:1.10174\tval-mlogloss:1.36375\n",
      "[39]\ttrain-mlogloss:1.09057\tval-mlogloss:1.35583\n",
      "[40]\ttrain-mlogloss:1.08004\tval-mlogloss:1.34769\n",
      "[41]\ttrain-mlogloss:1.06992\tval-mlogloss:1.33899\n",
      "[42]\ttrain-mlogloss:1.06015\tval-mlogloss:1.33098\n",
      "[43]\ttrain-mlogloss:1.05077\tval-mlogloss:1.32446\n",
      "[44]\ttrain-mlogloss:1.0417\tval-mlogloss:1.31785\n",
      "[45]\ttrain-mlogloss:1.03295\tval-mlogloss:1.3114\n",
      "[46]\ttrain-mlogloss:1.02457\tval-mlogloss:1.30494\n",
      "[47]\ttrain-mlogloss:1.01659\tval-mlogloss:1.29828\n",
      "[48]\ttrain-mlogloss:1.00879\tval-mlogloss:1.29306\n",
      "[49]\ttrain-mlogloss:1.00128\tval-mlogloss:1.28729\n",
      "[50]\ttrain-mlogloss:0.994131\tval-mlogloss:1.28261\n",
      "[51]\ttrain-mlogloss:0.987171\tval-mlogloss:1.27697\n",
      "[52]\ttrain-mlogloss:0.980399\tval-mlogloss:1.27161\n",
      "[53]\ttrain-mlogloss:0.973975\tval-mlogloss:1.26741\n",
      "[54]\ttrain-mlogloss:0.967577\tval-mlogloss:1.26336\n",
      "[55]\ttrain-mlogloss:0.961576\tval-mlogloss:1.25876\n",
      "[56]\ttrain-mlogloss:0.955912\tval-mlogloss:1.25385\n",
      "[57]\ttrain-mlogloss:0.950357\tval-mlogloss:1.24964\n",
      "[58]\ttrain-mlogloss:0.944837\tval-mlogloss:1.24585\n",
      "[59]\ttrain-mlogloss:0.939421\tval-mlogloss:1.24185\n",
      "[60]\ttrain-mlogloss:0.934351\tval-mlogloss:1.23786\n",
      "[61]\ttrain-mlogloss:0.929492\tval-mlogloss:1.23466\n",
      "[62]\ttrain-mlogloss:0.924638\tval-mlogloss:1.23109\n",
      "[63]\ttrain-mlogloss:0.920032\tval-mlogloss:1.22811\n",
      "[64]\ttrain-mlogloss:0.915393\tval-mlogloss:1.22545\n",
      "[65]\ttrain-mlogloss:0.910921\tval-mlogloss:1.22293\n",
      "[66]\ttrain-mlogloss:0.906655\tval-mlogloss:1.21986\n",
      "[67]\ttrain-mlogloss:0.902486\tval-mlogloss:1.2167\n",
      "[68]\ttrain-mlogloss:0.898373\tval-mlogloss:1.21409\n",
      "[69]\ttrain-mlogloss:0.894329\tval-mlogloss:1.21155\n",
      "[70]\ttrain-mlogloss:0.890446\tval-mlogloss:1.20873\n",
      "[71]\ttrain-mlogloss:0.886664\tval-mlogloss:1.20642\n",
      "[72]\ttrain-mlogloss:0.883055\tval-mlogloss:1.2042\n",
      "[73]\ttrain-mlogloss:0.879641\tval-mlogloss:1.20196\n",
      "[74]\ttrain-mlogloss:0.876311\tval-mlogloss:1.19973\n",
      "[75]\ttrain-mlogloss:0.872864\tval-mlogloss:1.19758\n",
      "[76]\ttrain-mlogloss:0.869505\tval-mlogloss:1.19536\n",
      "[77]\ttrain-mlogloss:0.866238\tval-mlogloss:1.19338\n",
      "[78]\ttrain-mlogloss:0.863198\tval-mlogloss:1.1916\n",
      "[79]\ttrain-mlogloss:0.860093\tval-mlogloss:1.19\n",
      "[80]\ttrain-mlogloss:0.857135\tval-mlogloss:1.18801\n",
      "[81]\ttrain-mlogloss:0.854297\tval-mlogloss:1.18613\n",
      "[82]\ttrain-mlogloss:0.851505\tval-mlogloss:1.18447\n",
      "[83]\ttrain-mlogloss:0.848782\tval-mlogloss:1.18318\n",
      "[84]\ttrain-mlogloss:0.846043\tval-mlogloss:1.18165\n",
      "[85]\ttrain-mlogloss:0.843622\tval-mlogloss:1.18031\n",
      "[86]\ttrain-mlogloss:0.841009\tval-mlogloss:1.17874\n",
      "[87]\ttrain-mlogloss:0.838583\tval-mlogloss:1.17769\n",
      "[88]\ttrain-mlogloss:0.835984\tval-mlogloss:1.17632\n",
      "[89]\ttrain-mlogloss:0.833736\tval-mlogloss:1.17512\n",
      "[90]\ttrain-mlogloss:0.831512\tval-mlogloss:1.17406\n",
      "[91]\ttrain-mlogloss:0.829159\tval-mlogloss:1.17277\n",
      "[92]\ttrain-mlogloss:0.827003\tval-mlogloss:1.17135\n",
      "[93]\ttrain-mlogloss:0.824698\tval-mlogloss:1.17001\n",
      "[94]\ttrain-mlogloss:0.822514\tval-mlogloss:1.16875\n",
      "[95]\ttrain-mlogloss:0.820416\tval-mlogloss:1.16782\n",
      "[96]\ttrain-mlogloss:0.818427\tval-mlogloss:1.16682\n",
      "[97]\ttrain-mlogloss:0.816377\tval-mlogloss:1.16596\n",
      "[98]\ttrain-mlogloss:0.814389\tval-mlogloss:1.16498\n",
      "[99]\ttrain-mlogloss:0.812474\tval-mlogloss:1.16405\n",
      "[100]\ttrain-mlogloss:0.810521\tval-mlogloss:1.16339\n",
      "[101]\ttrain-mlogloss:0.808711\tval-mlogloss:1.16239\n",
      "[102]\ttrain-mlogloss:0.806891\tval-mlogloss:1.16151\n",
      "[103]\ttrain-mlogloss:0.805028\tval-mlogloss:1.16063\n",
      "[104]\ttrain-mlogloss:0.803224\tval-mlogloss:1.15995\n",
      "[105]\ttrain-mlogloss:0.801488\tval-mlogloss:1.15933\n",
      "[106]\ttrain-mlogloss:0.799769\tval-mlogloss:1.1587\n",
      "[107]\ttrain-mlogloss:0.797997\tval-mlogloss:1.15779\n",
      "[108]\ttrain-mlogloss:0.796462\tval-mlogloss:1.15722\n",
      "[109]\ttrain-mlogloss:0.79468\tval-mlogloss:1.15651\n",
      "[110]\ttrain-mlogloss:0.793178\tval-mlogloss:1.15584\n",
      "[111]\ttrain-mlogloss:0.791519\tval-mlogloss:1.15536\n",
      "[112]\ttrain-mlogloss:0.79005\tval-mlogloss:1.15465\n",
      "[113]\ttrain-mlogloss:0.788569\tval-mlogloss:1.15429\n",
      "[114]\ttrain-mlogloss:0.787078\tval-mlogloss:1.15397\n",
      "[115]\ttrain-mlogloss:0.785577\tval-mlogloss:1.15367\n",
      "[116]\ttrain-mlogloss:0.78432\tval-mlogloss:1.15344\n",
      "[117]\ttrain-mlogloss:0.782894\tval-mlogloss:1.15309\n",
      "[118]\ttrain-mlogloss:0.78137\tval-mlogloss:1.15254\n",
      "[119]\ttrain-mlogloss:0.779975\tval-mlogloss:1.15199\n",
      "[0]\ttrain-mlogloss:2.70847\tval-mlogloss:2.73741\n",
      "[1]\ttrain-mlogloss:2.53612\tval-mlogloss:2.57988\n",
      "[2]\ttrain-mlogloss:2.39903\tval-mlogloss:2.45672\n",
      "[3]\ttrain-mlogloss:2.2854\tval-mlogloss:2.35698\n",
      "[4]\ttrain-mlogloss:2.18577\tval-mlogloss:2.27911\n",
      "[5]\ttrain-mlogloss:2.09901\tval-mlogloss:2.20672\n",
      "[6]\ttrain-mlogloss:2.02168\tval-mlogloss:2.14279\n",
      "[7]\ttrain-mlogloss:1.952\tval-mlogloss:2.08276\n",
      "[8]\ttrain-mlogloss:1.88862\tval-mlogloss:2.02785\n",
      "[9]\ttrain-mlogloss:1.83099\tval-mlogloss:1.98321\n",
      "[10]\ttrain-mlogloss:1.7783\tval-mlogloss:1.93716\n",
      "[11]\ttrain-mlogloss:1.7299\tval-mlogloss:1.89439\n",
      "[12]\ttrain-mlogloss:1.68498\tval-mlogloss:1.85595\n",
      "[13]\ttrain-mlogloss:1.64311\tval-mlogloss:1.81934\n",
      "[14]\ttrain-mlogloss:1.60377\tval-mlogloss:1.78579\n",
      "[15]\ttrain-mlogloss:1.56679\tval-mlogloss:1.75549\n",
      "[16]\ttrain-mlogloss:1.53228\tval-mlogloss:1.72529\n",
      "[17]\ttrain-mlogloss:1.50005\tval-mlogloss:1.69692\n",
      "[18]\ttrain-mlogloss:1.46951\tval-mlogloss:1.67058\n",
      "[19]\ttrain-mlogloss:1.44118\tval-mlogloss:1.64885\n",
      "[20]\ttrain-mlogloss:1.41426\tval-mlogloss:1.62582\n",
      "[21]\ttrain-mlogloss:1.3886\tval-mlogloss:1.60693\n",
      "[22]\ttrain-mlogloss:1.36427\tval-mlogloss:1.58681\n",
      "[23]\ttrain-mlogloss:1.34123\tval-mlogloss:1.56628\n",
      "[24]\ttrain-mlogloss:1.31939\tval-mlogloss:1.54771\n",
      "[25]\ttrain-mlogloss:1.29859\tval-mlogloss:1.52975\n",
      "[26]\ttrain-mlogloss:1.27894\tval-mlogloss:1.51391\n",
      "[27]\ttrain-mlogloss:1.26034\tval-mlogloss:1.49766\n",
      "[28]\ttrain-mlogloss:1.2423\tval-mlogloss:1.48261\n",
      "[29]\ttrain-mlogloss:1.22498\tval-mlogloss:1.469\n",
      "[30]\ttrain-mlogloss:1.20856\tval-mlogloss:1.45589\n"
     ]
    }
   ],
   "source": [
    "param = {'objective': 'multi:softprob', \n",
    "         'eta': 0.05, \n",
    "         'max_depth': 8, \n",
    "         'silent': 1, \n",
    "         'num_class': len(target_cols),\n",
    "         'eval_metric': 'mlogloss',\n",
    "         'min_child_weight': 1,\n",
    "         'subsample': 0.7,\n",
    "         'colsample_bytree': 0.7,\n",
    "         'seed': 0}\n",
    "num_rounds = 120\n",
    "\n",
    "dtrain = xgb.DMatrix(x_train.values, y_train.values)\n",
    "dval = xgb.DMatrix(x_val.values, y_val.values)\n",
    "\n",
    "train_history = {}\n",
    "np.random.seed(0)\n",
    "for n in range(10):\n",
    "    train_history[n] = {}\n",
    "    param['seed'] = np.random.randint(10**6)\n",
    "    model = xgb.train(param, dtrain, num_rounds, evals=[(dtrain, 'train'), (dval, 'val')], \n",
    "        verbose_eval=True, evals_result=train_history[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction from my model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(xgb.DMatrix(x_test.values))\n",
    "\n",
    "df_preds = pd.DataFrame(preds, index=x_test.index, columns=target_cols)\n",
    "# Remove already bought products \n",
    "df_preds[x_test[target_cols]==1] = 0 \n",
    "preds = df_preds.values\n",
    "preds = np.argsort(preds, axis=1)\n",
    "preds = np.fliplr(preds)[:, :7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write out prediction results from my model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = x_test.loc[:, 'ncodpers'].values\n",
    "final_preds = [' '.join([target_cols[k] for k in pred]) for pred in preds]\n",
    "\n",
    "out_df = pd.DataFrame({'ncodpers': test_id, 'added_products': final_preds})\n",
    "out_df.to_csv('eda_4_19.csv.gz', compression='gzip', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.Series(x_train.columns).to_csv('x_train_cols.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
