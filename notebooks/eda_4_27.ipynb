{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering and CV based Winners' Solutions\n",
    "\n",
    "continued from eda_4_26\n",
    "\n",
    "New in this notebook:\n",
    "- average of products for each (customer, product) pair\n",
    "- exponent weighted average of products each (customer, product) pair\n",
    "- time since presence of products, distance to the first 1\n",
    "- time to the last positive flank (01)\n",
    "- time to the last negative flank (10)\n",
    "\n",
    "To-do: \n",
    "- mean encoding of products grouped by combinations of: canal_entrada, segmento, cod_prov\n",
    "- Time since change and lags for a few non-product features: \n",
    "    - segmento\n",
    "    - ind_actividad_cliente\n",
    "    - cod_prov\n",
    "    - canal_entrada\n",
    "    - indrel_1mes\n",
    "    - tiprel_1mes\n",
    "\n",
    "\n",
    "Features:\n",
    "- before eda_4_25\n",
    "    - customer info in the second month\n",
    "    - products in the first month\n",
    "    - combination of first and second month `ind_actividad_cliente`\n",
    "    - combination of first and second month `tiprel_1mes`\n",
    "    - combination of first month product by using binary number (`target_combine`)\n",
    "    - encoding `target_combine` with \n",
    "        - mean number of new products\n",
    "        - mean number of customers with new products\n",
    "        - mean number of customers with each new products\n",
    "    - Count patterns in the last `max_lag` months\n",
    "    - Number of month to the last time the customer purchase each product\n",
    "        - CV@2015-12-28: mlogloss=1.29349\n",
    "        - Private score: 0.0302475, public score: 0.0299266\n",
    "- eda_4_25\n",
    "    - Use all available history data\n",
    "        - E.g., for 2016-05-28 train data, use all previous months, for 2015-02-28, use 1 lag month. \n",
    "        - Need to create test set that use the same amount of previous months for each training data set. \n",
    "        - This is from [the second winner's solution](https://www.kaggle.com/c/santander-product-recommendation/discussion/26824), his bold part in paragraph 4.\n",
    "    - Combine models trained on 2016-05-28 and 2015-06-28:\n",
    "        - Private score: 0.0304583, public score: 0.0300839\n",
    "        - This is to catch both seasonality and trend, presented in 2015-06-28 and 2016-05-28, respectively. \n",
    "        - This idea is mentioned by many winners, like [11-th winner](https://www.kaggle.com/c/santander-product-recommendation/discussion/26823) and [14-th winner](https://www.kaggle.com/c/santander-product-recommendation/discussion/26808)\n",
    "\n",
    "- eda_4_27\n",
    "    - put 2015-06-28 and 2016-05-28 in the same data set, with the same lag=5\n",
    "        - Private score:0.0303096, public score: 0.0299867\n",
    "        - Different as [11-th winner's discussion](https://www.kaggle.com/c/santander-product-recommendation/discussion/26823)\n",
    "            > We tested this by adding 50% of May-16 data to our June model and sure enough, we went from 0.0301 to 0.0303. Then, we built separate models for Jun and May, but the ensemble didn’t work. We weren’t surprised because June data is better for seasonal products, and May data is better for trend products. And vice-versa, June data is bad for trend products and May data is bad for seasonal products. So, they sort of cancelled each other out.\n",
    "\n",
    "        - But my score is always worse than theirs, maybe this is the reason why we have different observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from santander_helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2015-01-28',\n",
       " '2015-02-28',\n",
       " '2015-03-28',\n",
       " '2015-04-28',\n",
       " '2015-05-28',\n",
       " '2015-06-28',\n",
       " '2015-07-28',\n",
       " '2015-08-28',\n",
       " '2015-09-28',\n",
       " '2015-10-28',\n",
       " '2015-11-28',\n",
       " '2015-12-28',\n",
       " '2016-01-28',\n",
       " '2016-02-28',\n",
       " '2016-03-28',\n",
       " '2016-04-28',\n",
       " '2016-05-28',\n",
       " '2016-06-28']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "month_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "month1 = '2016-04-28'\n",
    "max_lag = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_new = month_list.index(month1)+1\n",
    "month_end = month_list.index(month1)\n",
    "month_start = month_end-max_lag+1\n",
    "\n",
    "# Check if month_new is the last month\n",
    "if month_new<len(month_list)-1:\n",
    "    # Customers with new products in month_new\n",
    "    customer_product_pair = pd.read_hdf('../input/customer_product_pair.hdf', 'customer_product_pair')\n",
    "    ncodpers_list = customer_product_pair.loc[customer_product_pair.fecha_dato==month_list[month_new], \n",
    "        'ncodpers'].unique().tolist()\n",
    "\n",
    "# Load data for all the lag related months\n",
    "df = []\n",
    "for m in range(month_start, month_end+1):\n",
    "    df.append(pd.read_hdf('../input/data_month_{}.hdf'.format(month_list[m]), 'data_month'))\n",
    "\n",
    "# concatenate data\n",
    "df = pd.concat(df, ignore_index=True)\n",
    "\n",
    "df = df.loc[:, ['fecha_dato']+cat_cols+target_cols]\n",
    "if month_new<len(month_list)-1:\n",
    "    # select customers if this is not test set\n",
    "    df = df.loc[df.ncodpers.isin(ncodpers_list), :]\n",
    "\n",
    "# set ncodpers and fecha_dato as index\n",
    "df.set_index(['ncodpers', 'fecha_dato'], inplace=True)\n",
    "\n",
    "# unstack to make month as columns\n",
    "df = df.unstack(level=-1, fill_value=np.nan)\n",
    "\n",
    "# Arithmetic /exponent weighted average of products for each (customer, product) pair \n",
    "\n",
    "# Group data by features\n",
    "group0 = df.fillna(0.0).groupby(axis=1, level=0)\n",
    "\n",
    "# Average of products for each (customer, product) pair\n",
    "mean_product = pd.DataFrame()\n",
    "mean_product['ncodpers'] = df.index.tolist() # Note: orders of ncodpers in df and ncodpers_list are different! \n",
    "for k in target_cols:\n",
    "    mean_product[k+'_lag_mean'] = group0.get_group(k).mean(axis=1).values\n",
    "\n",
    "mean_product.set_index('ncodpers', inplace=True)\n",
    "\n",
    "# Exponent average of products for each (customer, product) pair\n",
    "mean_exp_product = pd.DataFrame()\n",
    "mean_exp_product['ncodpers'] = df.index.tolist() # Note: orders of ncodpers in df and ncodpers_list are different! \n",
    "mean_exp_alpha1 = 0.1\n",
    "mean_exp_weight1 = np.float_power(1-mean_exp_alpha1, np.arange(0, max_lag))\n",
    "mean_exp_weight1 = mean_exp_weight1[::-1]/np.sum(mean_exp_weight1)\n",
    "mean_exp_alpha2 = 0.5\n",
    "mean_exp_weight2 = np.float_power(1-mean_exp_alpha2, np.arange(0, max_lag))\n",
    "mean_exp_weight2 = mean_exp_weight2[::-1]/np.sum(mean_exp_weight2)\n",
    "for k in target_cols:\n",
    "    mean_exp_product[k+'_lag_exp_mean1'] = np.average(group0.get_group(k).values, axis=1, weights=mean_exp_weight1) #group0.get_group(k).apply(np.average, axis=1, weights=mean_exp_weight1).values\n",
    "    mean_exp_product[k+'_lag_exp_mean2'] = np.average(group0.get_group(k).values, axis=1, weights=mean_exp_weight2) # group0.get_group(k).apply(np.average, axis=1, weights=mean_exp_weight2).values\n",
    "    \n",
    "mean_exp_product.set_index('ncodpers', inplace=True)\n",
    "\n",
    "distance_positive_flank = pd.DataFrame()\n",
    "distance_positive_flank['ncodpers'] = df.index.tolist()\n",
    "for k in target_cols:\n",
    "    distance_positive_flank[k+'_dist_pos_flank'] = dist_pos_flank(group0.get_group(k))\n",
    "    \n",
    "distance_positive_flank.set_index('ncodpers', inplace=True)\n",
    "\n",
    "distance_negative_flank = pd.DataFrame()\n",
    "distance_negative_flank['ncodpers'] = df.index.tolist()\n",
    "for k in target_cols:\n",
    "    distance_negative_flank[k+'_dist_neg_flank'] = dist_neg_flank(group0.get_group(k))\n",
    "    \n",
    "distance_negative_flank.set_index('ncodpers', inplace=True)\n",
    "\n",
    "distance_first_one = pd.DataFrame()\n",
    "distance_first_one['ncodpers'] = df.index.tolist()\n",
    "for k in target_cols:\n",
    "    distance_first_one[k+'_dist_first_one'] = dist_first_one(group0.get_group(k))\n",
    "    \n",
    "distance_first_one.set_index('ncodpers', inplace=True)\n",
    "\n",
    "def dist_last_one(x):\n",
    "    x = 1-x\n",
    "    return x.iloc[:, ::-1].cummin(axis=1).sum(axis=1).values\n",
    "\n",
    "# count number of concatenating zeros before the second/current month\n",
    "distance_last_one = pd.DataFrame()\n",
    "distance_last_one['ncodpers'] = df.index.tolist()\n",
    "for k in target_cols:\n",
    "    distance_last_one[k+'_dist_last_one'] = dist_last_one(group0.get_group(k))\n",
    "\n",
    "distance_last_one.set_index('ncodpers', inplace=True)\n",
    "\n",
    "history = distance_last_one.join((distance_first_one, distance_negative_flank, \n",
    "    distance_positive_flank, mean_exp_product, mean_product))   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distance to positive flank\n",
    "def dist_pos_flank(x):\n",
    "    x = x.values[:, ::-1]\n",
    "    x = np.hstack((x, np.ones((x.shape[0], 1)), np.zeros((x.shape[0], 1)) ))\n",
    "    x = np.diff(x, axis=1)\n",
    "    x = np.argmin(x, axis=1)\n",
    "    return x\n",
    "\n",
    "# distance to negative flank\n",
    "def dist_neg_flank(x):\n",
    "    x = x.values[:, ::-1]\n",
    "    x = np.hstack((x, np.zeros((x.shape[0], 1)), np.ones((x.shape[0], 1)) ))\n",
    "    x = np.diff(x, axis=1)\n",
    "    x = np.argmax(x, axis=1)\n",
    "    return x\n",
    "\n",
    "# Distance to the first 1\n",
    "def dist_first_one(x):\n",
    "    x = x.values\n",
    "    x = np.hstack( (x, np.ones((x.shape[0], 1)) ) )\n",
    "    x = x.shape[1]-2-np.argmax(x, axis=1)\n",
    "    return x\n",
    "\n",
    "def count_history(month1, max_lag):\n",
    "    '''Statistics about historical data'''\n",
    "    \n",
    "    if os.path.exists('../input/history_count_{}_{}.hdf'.format(month1, max_lag)):\n",
    "        df = pd.read_hdf('../input/history_count_{}_{}.hdf'.format(month1, max_lag), \n",
    "            'count_zeros')\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    month_new = month_list.index(month1)+1\n",
    "    month_end = month_list.index(month1)\n",
    "    month_start = month_end-max_lag+1\n",
    "    \n",
    "    # Check if month_new is the last month\n",
    "    if month_new<len(month_list)-1:\n",
    "        # Customers with new products in month_new\n",
    "        customer_product_pair = pd.read_hdf('../input/customer_product_pair.hdf', 'customer_product_pair')\n",
    "        ncodpers_list = customer_product_pair.loc[customer_product_pair.fecha_dato==month_list[month_new], \n",
    "            'ncodpers'].unique().tolist()\n",
    "\n",
    "    # Load data for all the lag related months\n",
    "    df = []\n",
    "    for m in range(month_start, month_end+1):\n",
    "        df.append(pd.read_hdf('../input/data_month_{}.hdf'.format(month_list[m]), 'data_month'))\n",
    "\n",
    "    # concatenate data\n",
    "    df = pd.concat(df, ignore_index=True)\n",
    "\n",
    "    df = df.loc[:, ['fecha_dato']+cat_cols+target_cols]\n",
    "    if month_new<len(month_list)-1:\n",
    "        # select customers if this is not test set\n",
    "        df = df.loc[df.ncodpers.isin(ncodpers_list), :]\n",
    "\n",
    "    # set ncodpers and fecha_dato as index\n",
    "    df.set_index(['ncodpers', 'fecha_dato'], inplace=True)\n",
    "\n",
    "    # unstack to make month as columns\n",
    "    df = df.unstack(level=-1, fill_value=np.nan)\n",
    "\n",
    "    # Arithmetic /exponent weighted average of products for each (customer, product) pair \n",
    "\n",
    "    # Group data by features\n",
    "    group0 = df.fillna(0.0).groupby(axis=1, level=0)\n",
    "\n",
    "    # Average of products for each (customer, product) pair\n",
    "    mean_product = pd.DataFrame()\n",
    "    mean_product['ncodpers'] = df.index.tolist() # Note: orders of ncodpers in df and ncodpers_list are different! \n",
    "    for k in target_cols:\n",
    "        mean_product[k+'_lag_mean'] = group0.get_group(k).mean(axis=1).values\n",
    "\n",
    "    mean_product.set_index('ncodpers', inplace=True)\n",
    "\n",
    "    # Exponent average of products for each (customer, product) pair\n",
    "    mean_exp_product = pd.DataFrame()\n",
    "    mean_exp_product['ncodpers'] = df.index.tolist() # Note: orders of ncodpers in df and ncodpers_list are different! \n",
    "    mean_exp_alpha1 = 0.1\n",
    "    mean_exp_weight1 = np.float_power(1-mean_exp_alpha1, np.arange(0, max_lag))\n",
    "    mean_exp_weight1 = mean_exp_weight1[::-1]/np.sum(mean_exp_weight1)\n",
    "    mean_exp_alpha2 = 0.5\n",
    "    mean_exp_weight2 = np.float_power(1-mean_exp_alpha2, np.arange(0, max_lag))\n",
    "    mean_exp_weight2 = mean_exp_weight2[::-1]/np.sum(mean_exp_weight2)\n",
    "    for k in target_cols:\n",
    "        mean_exp_product[k+'_lag_exp_mean1'] = np.average(group0.get_group(k).values, axis=1, weights=mean_exp_weight1) #group0.get_group(k).apply(np.average, axis=1, weights=mean_exp_weight1).values\n",
    "        mean_exp_product[k+'_lag_exp_mean2'] = np.average(group0.get_group(k).values, axis=1, weights=mean_exp_weight2) # group0.get_group(k).apply(np.average, axis=1, weights=mean_exp_weight2).values\n",
    "\n",
    "    mean_exp_product.set_index('ncodpers', inplace=True)\n",
    "\n",
    "    distance_positive_flank = pd.DataFrame()\n",
    "    distance_positive_flank['ncodpers'] = df.index.tolist()\n",
    "    for k in target_cols:\n",
    "        distance_positive_flank[k+'_dist_pos_flank'] = dist_pos_flank(group0.get_group(k))\n",
    "\n",
    "    distance_positive_flank.set_index('ncodpers', inplace=True)\n",
    "\n",
    "    distance_negative_flank = pd.DataFrame()\n",
    "    distance_negative_flank['ncodpers'] = df.index.tolist()\n",
    "    for k in target_cols:\n",
    "        distance_negative_flank[k+'_dist_neg_flank'] = dist_neg_flank(group0.get_group(k))\n",
    "\n",
    "    distance_negative_flank.set_index('ncodpers', inplace=True)\n",
    "\n",
    "    distance_first_one = pd.DataFrame()\n",
    "    distance_first_one['ncodpers'] = df.index.tolist()\n",
    "    for k in target_cols:\n",
    "        distance_first_one[k+'_dist_first_one'] = dist_first_one(group0.get_group(k))\n",
    "\n",
    "    distance_first_one.set_index('ncodpers', inplace=True)\n",
    "\n",
    "    def dist_last_one(x):\n",
    "        x = 1-x\n",
    "        return x.iloc[:, ::-1].cummin(axis=1).sum(axis=1).values\n",
    "\n",
    "    # count number of concatenating zeros before the second/current month\n",
    "    distance_last_one = pd.DataFrame()\n",
    "    distance_last_one['ncodpers'] = df.index.tolist()\n",
    "    for k in target_cols:\n",
    "        distance_last_one[k+'_dist_last_one'] = dist_last_one(group0.get_group(k))\n",
    "\n",
    "    distance_last_one.set_index('ncodpers', inplace=True)\n",
    "\n",
    "    history = distance_last_one.join((distance_first_one, distance_negative_flank, \n",
    "        distance_positive_flank, mean_exp_product, mean_product))\n",
    "    \n",
    "    history.to_hdf('../input/history_count_{}_{}.hdf'.format(month1, max_lag), 'count_zeros')\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "dh = count_history('2016-04-28', 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ind_cco_fin_ult1_dist_last_one</th>\n",
       "      <th>ind_cder_fin_ult1_dist_last_one</th>\n",
       "      <th>ind_cno_fin_ult1_dist_last_one</th>\n",
       "      <th>ind_ctju_fin_ult1_dist_last_one</th>\n",
       "      <th>ind_ctma_fin_ult1_dist_last_one</th>\n",
       "      <th>ind_ctop_fin_ult1_dist_last_one</th>\n",
       "      <th>ind_ctpp_fin_ult1_dist_last_one</th>\n",
       "      <th>ind_dela_fin_ult1_dist_last_one</th>\n",
       "      <th>ind_ecue_fin_ult1_dist_last_one</th>\n",
       "      <th>ind_fond_fin_ult1_dist_last_one</th>\n",
       "      <th>...</th>\n",
       "      <th>ind_fond_fin_ult1_lag_mean</th>\n",
       "      <th>ind_hip_fin_ult1_lag_mean</th>\n",
       "      <th>ind_nom_pens_ult1_lag_mean</th>\n",
       "      <th>ind_nomina_ult1_lag_mean</th>\n",
       "      <th>ind_plan_fin_ult1_lag_mean</th>\n",
       "      <th>ind_pres_fin_ult1_lag_mean</th>\n",
       "      <th>ind_reca_fin_ult1_lag_mean</th>\n",
       "      <th>ind_recibo_ult1_lag_mean</th>\n",
       "      <th>ind_tjcr_fin_ult1_lag_mean</th>\n",
       "      <th>ind_valo_fin_ult1_lag_mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ncodpers</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15889</th>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15929</th>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15952</th>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15988</th>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15993</th>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 133 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ind_cco_fin_ult1_dist_last_one  ind_cder_fin_ult1_dist_last_one  \\\n",
       "ncodpers                                                                    \n",
       "15889                                0.0                             16.0   \n",
       "15929                                0.0                             16.0   \n",
       "15952                                0.0                             16.0   \n",
       "15988                                0.0                             16.0   \n",
       "15993                               16.0                             16.0   \n",
       "\n",
       "          ind_cno_fin_ult1_dist_last_one  ind_ctju_fin_ult1_dist_last_one  \\\n",
       "ncodpers                                                                    \n",
       "15889                               16.0                             16.0   \n",
       "15929                               16.0                             16.0   \n",
       "15952                               16.0                             16.0   \n",
       "15988                               16.0                             16.0   \n",
       "15993                                0.0                             16.0   \n",
       "\n",
       "          ind_ctma_fin_ult1_dist_last_one  ind_ctop_fin_ult1_dist_last_one  \\\n",
       "ncodpers                                                                     \n",
       "15889                                16.0                             16.0   \n",
       "15929                                16.0                             16.0   \n",
       "15952                                16.0                             16.0   \n",
       "15988                                16.0                             16.0   \n",
       "15993                                16.0                             16.0   \n",
       "\n",
       "          ind_ctpp_fin_ult1_dist_last_one  ind_dela_fin_ult1_dist_last_one  \\\n",
       "ncodpers                                                                     \n",
       "15889                                 0.0                             16.0   \n",
       "15929                                 0.0                             16.0   \n",
       "15952                                16.0                              2.0   \n",
       "15988                                16.0                             16.0   \n",
       "15993                                16.0                              0.0   \n",
       "\n",
       "          ind_ecue_fin_ult1_dist_last_one  ind_fond_fin_ult1_dist_last_one  \\\n",
       "ncodpers                                                                     \n",
       "15889                                16.0                             16.0   \n",
       "15929                                 0.0                             16.0   \n",
       "15952                                16.0                             16.0   \n",
       "15988                                16.0                             16.0   \n",
       "15993                                 0.0                             16.0   \n",
       "\n",
       "                     ...              ind_fond_fin_ult1_lag_mean  \\\n",
       "ncodpers             ...                                           \n",
       "15889                ...                                     0.0   \n",
       "15929                ...                                     0.0   \n",
       "15952                ...                                     0.0   \n",
       "15988                ...                                     0.0   \n",
       "15993                ...                                     0.0   \n",
       "\n",
       "          ind_hip_fin_ult1_lag_mean  ind_nom_pens_ult1_lag_mean  \\\n",
       "ncodpers                                                          \n",
       "15889                           0.0                         0.0   \n",
       "15929                           0.0                         0.0   \n",
       "15952                           0.0                         0.0   \n",
       "15988                           0.0                         0.0   \n",
       "15993                           0.0                         0.0   \n",
       "\n",
       "          ind_nomina_ult1_lag_mean  ind_plan_fin_ult1_lag_mean  \\\n",
       "ncodpers                                                         \n",
       "15889                          0.0                         0.0   \n",
       "15929                          0.0                         0.0   \n",
       "15952                          0.0                         0.0   \n",
       "15988                          0.0                         0.0   \n",
       "15993                          0.0                         0.0   \n",
       "\n",
       "          ind_pres_fin_ult1_lag_mean  ind_reca_fin_ult1_lag_mean  \\\n",
       "ncodpers                                                           \n",
       "15889                            0.0                         0.0   \n",
       "15929                            0.0                         0.0   \n",
       "15952                            0.0                         1.0   \n",
       "15988                            0.0                         0.0   \n",
       "15993                            0.0                         1.0   \n",
       "\n",
       "          ind_recibo_ult1_lag_mean  ind_tjcr_fin_ult1_lag_mean  \\\n",
       "ncodpers                                                         \n",
       "15889                       0.0000                      0.4375   \n",
       "15929                       0.5625                      1.0000   \n",
       "15952                       0.9375                      0.0000   \n",
       "15988                       0.0000                      0.5000   \n",
       "15993                       1.0000                      0.5625   \n",
       "\n",
       "          ind_valo_fin_ult1_lag_mean  \n",
       "ncodpers                              \n",
       "15889                            1.0  \n",
       "15929                            1.0  \n",
       "15952                            0.0  \n",
       "15988                            0.0  \n",
       "15993                            0.0  \n",
       "\n",
       "[5 rows x 133 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dh.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_new = month_list.index(month1)+1\n",
    "month_end = month_list.index(month1)\n",
    "month_start = month_end-max_lag+1\n",
    "\n",
    "# Check if month_new is the last month\n",
    "if month_new<len(month_list)-1:\n",
    "    # Customers with new products in month_new\n",
    "    customer_product_pair = pd.read_hdf('../input/customer_product_pair.hdf', 'customer_product_pair')\n",
    "    ncodpers_list = customer_product_pair.loc[customer_product_pair.fecha_dato==month_list[month_new], \n",
    "        'ncodpers'].unique().tolist()\n",
    "\n",
    "# Load data for all the lag related months\n",
    "df = []\n",
    "for m in range(month_start, month_end+1):\n",
    "    df.append(pd.read_hdf('../input/data_month_{}.hdf'.format(month_list[m]), 'data_month'))\n",
    "\n",
    "# concatenate data\n",
    "df = pd.concat(df, ignore_index=True)\n",
    "df = df.loc[:, ['ncodpers', 'fecha_dato']+target_cols]\n",
    "if month_new<len(month_list)-1:\n",
    "    # select customers if this is not test set\n",
    "    df = df.loc[df.ncodpers.isin(ncodpers_list), :]\n",
    "# set ncodpers and fecha_dato as index\n",
    "df.set_index(['ncodpers', 'fecha_dato'], inplace=True)\n",
    "# unstack to make month as columns\n",
    "df = df.unstack(level=-1, fill_value=0)\n",
    "\n",
    "# count number of concatenating zeros before the second/current month\n",
    "df = df.groupby(level=0, axis=1).progress_apply(lambda x: (1-x).iloc[:, ::-1].cummin(axis=1).sum(axis=1))\n",
    "df.columns = [k+'_zc' for k in df.columns]\n",
    "\n",
    "gc.collect()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
